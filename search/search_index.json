{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About","text":"Abdellatif BELMADY Casablanca, Morocco ML/AI Engineer | Centralien Engineer  Buy Me a Coffee Export Resume  About <p>Hello! I\u2019m Abdellatif BELMADY, a proud graduate of Ecole Centrale Casablanca, holding a degree in data science and digitalization. With a firm belief in the transformative potential of technology, I am passionate about harnessing the power of data to drive positive change. My fascination lies in utilizing data science techniques to unravel complex problems and make meaningful improvements in people's lives. I strongly advocate for the value of hard work and dedication as crucial ingredients for success. In the words of renowned author Stephen King \u201cTalent is cheaper than table salt. What separates the talented individual from the successful one is a lot of hard work.\u201d I am dedicated to continuous learning, growth, and applying my skills to make a significant impact in the field of data science.       Experience - <p>Data Scientist | AI Engineer Jan 2024 - PresentThe Game Changer Company - Full Time</p> <p>\ud835\udc03\ud835\udc1a\ud835\udc2d\ud835\udc1a \ud835\udc12\ud835\udc1c\ud835\udc22\ud835\udc1e\ud835\udc27\ud835\udc1c\ud835\udc1e \ud835\udc0c\ud835\udc22\ud835\udc2c\ud835\udc2c\ud835\udc22\ud835\udc28\ud835\udc27\ud835\udc2c:</p> <ul> <li>Developed a multi-stage AI agent (LangGraph, GPT-4o-mini) to automate project initiation. The agent generates actionable tasks, identifies dependencies, creates schedules, allocates resources, assesses risks, and visualizes the project plan through automatically generated, detailed Gantt charts.         </li> <li>Creating Dashboards Using the \ud835\udc03\ud835\udc1a\ud835\udc2c\ud835\udc21 Framework with \ud835\udc0f\ud835\udc25\ud835\udc28\ud835\udc2d\ud835\udc25\ud835\udc32 for the Company Games.         </li> <li>Developed a conversational AI for hackathon students using Langchain, Groq API, and Llama 3.1 model. Integrated ChromaDB as a vector store and deployed via Docker with RESTful API endpoints.         </li> <li>Implemented a local LLM solution using Open WebUI, Ollama, and Stable Diffusion for image generation.         </li> <li>Developed QuizPhere, a full-stack quiz generation platform powered by Generative AI using Groq Llama 3.2. The app generates both text-based quiz content and collects relevant images via DuckDuckGo Search for a complete quiz experience. Supports multiple quiz types, including True/False, Multiple Choice, and Puzzle formats, using LangChain, FastAPI, PostgreSQL, and React.         </li> </ul> <p>\ud835\udc02\ud835\udc28\ud835\udc26\ud835\udc29\ud835\udc2e\ud835\udc2d\ud835\udc1e\ud835\udc2b \ud835\udc15\ud835\udc22\ud835\udc2c\ud835\udc22\ud835\udc28\ud835\udc27 \ud835\udc0c\ud835\udc22\ud835\udc2c\ud835\udc2c\ud835\udc22\ud835\udc28\ud835\udc27\ud835\udc2c:</p> <ul> <li>Developed a Flask application for \ud835\udc05\ud835\udc1a\ud835\udc1c\ud835\udc1e \ud835\udc11\ud835\udc1e\ud835\udc1c\ud835\udc28\ud835\udc20\ud835\udc27\ud835\udc22\ud835\udc2d\ud835\udc22\ud835\udc28\ud835\udc27, enhancing security measures by sending email alerts (including screenshots) upon detecting unauthorized entry into a room.         <li>Spearheaded the development of a Flask application for \ud835\udc05\ud835\udc1a\ud835\udc1c\ud835\udc22\ud835\udc1a\ud835\udc25 \ud835\udc00\ud835\udc2d\ud835\udc2d\ud835\udc2b\ud835\udc22\ud835\udc1b\ud835\udc2e\ud835\udc2d\ud835\udc1e \ud835\udc00\ud835\udc27\ud835\udc1a\ud835\udc25\ud835\udc32\ud835\udc2c\ud835\udc22\ud835\udc2c, enabling precise classification of gender, accurate prediction of age, and comprehensive emotion analysis.         <li>Pioneered a Flask application for \ud835\udc0e\ud835\udc1b\ud835\udc23\ud835\udc1e\ud835\udc1c\ud835\udc2d \ud835\udc02\ud835\udc28\ud835\udc2e\ud835\udc27\ud835\udc2d\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc2d\ud835\udc21\ud835\udc2b\ud835\udc28\ud835\udc2e\ud835\udc20\ud835\udc21 \ud835\udc2b\ud835\udc1e\ud835\udc20\ud835\udc22\ud835\udc28\ud835\udc27\ud835\udc2c, facilitating efficient monitoring and management of assets within specified areas.         </li> <li>Developed a real-time people detection and counting algorithm optimized for deployment on the \ud835\udc0d\ud835\udc2f\ud835\udc22\ud835\udc1d\ud835\udc22\ud835\udc1a \ud835\udc09\ud835\udc1e\ud835\udc2d\ud835\udc2c\ud835\udc28\ud835\udc27 \ud835\udc0d\ud835\udc1a\ud835\udc27\ud835\udc28 \ud835\udc1f\ud835\udc28\ud835\udc2b \ud835\udc1e\ud835\udc1d\ud835\udc20\ud835\udc1e \ud835\udc1c\ud835\udc28\ud835\udc26\ud835\udc29\ud835\udc2e\ud835\udc2d\ud835\udc22\ud835\udc27\ud835\udc20.         </li> <p>CEO and Founder Jan 2023 - PresentSmart Correction - Part Time</p> <p>As the founder and CEO of Smart Correction, I have had the privilege of guiding this company from its exciting beginnings. Our mission at Smart Correction is to transform education by providing intelligent and personalized assistance to French and Moroccan students.</p> About Smart Correction: <p>Smart Correction is more than just an educational platform. It is a vision, a revolution in learning powered by artificial intelligence. Our dedicated team has worked tirelessly to create an educational experience that transcends boundaries and opens new opportunities for every student.</p> Key Achievements: <ul> <li>Successfully designed and launched the Smart Correction platform, offering instant assistance and accurate corrections.         <li>Established strategic partnerships with educational institutions to integrate our solution into the educational landscape.         <li>Implemented rigorous security measures to ensure user confidentiality.         <li>Actively promoted smart and personalized education, with a commitment to continuous improvement.         </li> Impact on Education: <p>Smart Correction has already touched the lives of thousands of students, helping them excel in their studies and prepare optimally for their exams. Our vision is to create a lasting impact on learning, making Smart Correction a benchmark in the field of smart education.</p> <p>Join us in this educational adventure. Together, let's build a future where every student has access to quality, personalized, and effective education.</p> Try It Now <p>CEO and Founder Jan 2022 - PresentOther Ways - Part Time</p> <p>Today, the presence and installation of cameras are indispensable in large organizations and across various sectors. However, traditional camera systems often lag behind the advancements in the digital and intelligent world. At OtherWays, we offer a range of services leveraging intelligent cameras integrated with cutting-edge technologies. Our solutions go beyond traditional surveillance by providing advanced capabilities tailored to your needs, such as:       <ul> <li>Detection of persons authorized to access a room, enhancing security measures and access control.         <li>Tracking and analysis of people movement, providing valuable insights for crowd management and optimizing space utilization.         <li>Detection and counting of people, enabling accurate footfall analysis and facilitating crowd control measures.         <li>Detection of the presence/absence of employees at their workstations, allowing for efficient workforce management and improving productivity.         </li>        These examples represent just a glimpse of our service offerings. At OtherWays, we understand that each organization has unique requirements, and we tailor our solutions to meet your specific needs. Whether it's facial recognition, object tracking, or customized analytics, we can provide tailored solutions to enhance your operations. Our team is committed to delivering innovative and intelligent camera solutions that maximize the value of your investment.        <p>Deep Learning Data Scientist InternshipApr 2023 - Sept 2023SOLEFARMA - Internship <ul> <li>Implemented a Deep Learning approach for Foot-Type Classification Using Heterogeneous Pressure Data.         <li>Developed a methodology to collect both image and numerical data for the project.         <li>Fine-tuned VGG16 and InceptionV3 models to process the image data effectively.         <li>Fine-tuned K-NN and CART models to process the numerical data efficiently.         <li>Employed a stacking ensemble learning technique to enhance the final model's performance.         <li>Successfully deployed the final model on the OVH Cloud platform.         </li> <p>Computer Vision Developer Internship Apr 2022 - Jul 20226 PERFORM - Internship <ul> <li>Collected images (using the Imageye extention) to build a comprehensive dataset for computer vision tasks.          <li>Conducted image annotation using labelImg.exe to create accurate ground truth labels for training purposes.         <li>Trained deep learning models utilizing the YOLO version 4 algorithm.  for object detection and recognition.         <li>Focused on the detection of surgical instruments, mask wearing, medical caps, and earrings in medical images.         <li>Collaborated with a multidisciplinary team to refine the models and improve their performance.         <li>Evaluated the models' accuracy, precision, and recall, and fine-tuned them for optimal results.         <li>Documented the development process, including methodologies, challenges, and solutions.         </li> <p>During this internship, I gained hands-on experience in computer vision techniques, including dataset collection, annotation, and training of deep learning models. I developed expertise in detecting and recognizing surgical instruments, as well as detecting mask wearing, medical caps, and earrings in medical images. This experience enhanced my skills in image processing, object detection, and model evaluation.</p> <p>Data Analyst InternshipAug 2021 - Sept 2021VCR-Sodalmu - Internship <ul> <li>Developed an Excel application.  using VBA to manage inventory efficiently.         <li>Implemented a machine learning model to identify and address waste issues in the production line.         <li>Collaborated with the team to collect and analyze data, ensuring accurate model training.         <li>Presented findings and recommendations to improve production efficiency and reduce waste.         <li>Gained hands-on experience in data preprocessing, feature engineering, and model evaluation.         <li>Demonstrated strong problem-solving skills and attention to detail in resolving technical challenges.         </li> <p>Overall, this internship provided me with valuable insights into the practical application of data science techniques in a real-world setting. I developed skills in Excel application development, machine learning implementation, data analysis, and problem-solving, which will contribute to my growth and success as a data scientist.</p>  Education - <p>Data Science and digitalizationSept 2020 - PresentEcole Centrale Casablanca Morocco, Casablanca</p><p> </p> <p>Physics Chemistry Engineering ScienceSept 2018 - Apr 2020Preparatory Classes Errazi Morocco, El Jadida</p>  Honors &amp; Awards - <p>TechInnov Days Poster Session, 2nd Place (Poster)Sept 2022 - PresentEcole Centrale Casablanca Morocco, Casablanca</p><p> </p> <p>Centrale Coding Competition, 2nd Place (Certification)Nov 2021 - Dec 2021Ecole Centrale Casablanca Morocco, Casablanca</p><p> </p>  Where I'm Located -  Community Involvement - <p>TechInnov Days, Organizer memberSept 2022 - PresentEcole Centrale Casablanca Morocco, Casablanca</p><p> </p> <p>Spring School Data Science, Organizer member (Certification)Apr 2022 - PresentEcole Centrale Casablanca Morocco, Casablanca</p><p> </p> <p>Rotaract Association, Active memberAug 2020 - July 2021Ecole Centrale Casablanca Morocco, Casablanca</p><p> </p> <p>CentraleComm' Association, Active memberAug 2020 - July 2021Ecole Centrale Casablanca Morocco, Casablanca</p><p> </p> <p>Enactus Association, Active memberAug 2020 - Jan 2021Ecole Centrale Casablanca Morocco, Casablanca</p><p> </p> <p> @abdellatifbelmady On  Instagram -  What I'm Listening To - <p>"},{"location":"Tutorials/Computer%20Vision%20Algorithms/","title":"Computer Vision","text":"<ul> <li> <p>YOLO-NAS</p> <p>Get started  Getting started</p> </li> </ul>"},{"location":"Tutorials/Computer%20Vision%20Algorithms/AI_Vision_Jetson-inference_Setup/","title":"Jetson-inference Setup Guide","text":""},{"location":"Tutorials/Computer%20Vision%20Algorithms/AI_Vision_Jetson-inference_Setup/#introduction","title":"Introduction","text":"<p>This guide will walk you through the process of setting up and compiling the Jetson Inference project, which is a collection of tools and libraries for real-time video analytics on NVIDIA Jetson platforms.</p> <p>https://github.com/dusty-nv/jetson-inference</p> <p>You have two options to setting up the Jetson Inference Project:</p> <ul> <li> <p> Option 1: Run the Docker Container</p> </li> <li> <p> Option 2: Build the project from source</p> </li> </ul>"},{"location":"Tutorials/Computer%20Vision%20Algorithms/AI_Vision_Jetson-inference_Setup/#run-the-docker-container","title":"Run the Docker Container","text":"<p>First, you should clone the files in the project.</p> <pre><code>git clone --recursive https://github.com/dusty-nv/jetson-inference\n</code></pre> <p>By going into jetson-inference directory that created, you must run the container.</p> <pre><code>cd jetson-inference \n</code></pre> <pre><code>docker/run.sh \n</code></pre> <p>Docker container will automatically run and pull all the files, it will take few minutes depending on the network. This is the first setup and will only be done once. </p> <p>Then, you must build the container.</p> <pre><code>docker/build.sh \n</code></pre> <p>Then you are good.</p>"},{"location":"Tutorials/Computer%20Vision%20Algorithms/AI_Vision_Jetson-inference_Setup/#build-the-project-from-source","title":"Build the project from source","text":""},{"location":"Tutorials/Computer%20Vision%20Algorithms/AI_Vision_Jetson-inference_Setup/#before-starting","title":"Before starting","text":"<p>Before you begin, the following packages have to be installed:</p> <ul> <li>Git: For cloning the repository.</li> <li>CMake: For building the project.</li> <li>Python3 and Python3-dev: For building the Python bindings.</li> <li>Numpy: A library for the Python programming language, adding support for arrays and matrices.</li> </ul> <p>First, update your package list:</p> <pre><code>sudo apt-get update\n</code></pre> <p>Then, install Git and CMake:</p> <pre><code>sudo apt-get install git cmake\n</code></pre> <p>Install the necessary development packages:</p> <pre><code>sudo apt-get install libpython3-dev python3-numpy\n</code></pre>"},{"location":"Tutorials/Computer%20Vision%20Algorithms/AI_Vision_Jetson-inference_Setup/#clone-the-repository","title":"Clone the Repository","text":"<p>Navigate to your chosen directory and clone the project:</p> <pre><code>git clone https://github.com/dusty-nv/jetson-inference\n</code></pre> <p>By going into jetson-inference directory that created, you must run the container.</p> <pre><code>cd jetson-inference\n</code></pre> <pre><code>git submodule update \u2013init \n</code></pre> <p>Next, to download all the necessary files, and build the project create a folder called <code>build</code> and run cmake. </p> <pre><code>cd jetson-inference\n</code></pre> <pre><code>mkdir build \n</code></pre> <pre><code>cd build \n</code></pre> <pre><code>cmake ../  \n</code></pre> <p>Then, Model-Downloader tool will run automatically on the screen. This project comes with various pre-trained network models, you can choose which one(s) to download.</p> <p></p> <p>You can also re-run Model-Downloader tool later using the following command.</p> <pre><code>cd jetson-inference/tools\n</code></pre> <pre><code>./download-models.sh \n</code></pre> <p>Then, PyTorch Installer will appear on the screen. PyTorch is used to re-train networks and we will not need it in this project, so you can skip this part.</p> <p></p> <p>To compile the project at the end, run the following commands while in the build directory:</p> <pre><code>cd jetson-inference/build\n</code></pre> <pre><code>make \n</code></pre> <pre><code>sudo make install \n</code></pre> <pre><code>sudo ldconfig\n</code></pre> <p>Then we are good.</p>"},{"location":"Tutorials/Computer%20Vision%20Algorithms/AI_Vision_Jetson-inference_Setup/#run-the-project","title":"Run the project","text":"<p>After uccessfully setting up the Jetson Inference project, you can now start using it by executing the command:</p> <pre><code>docker/run.sh \n</code></pre> <p>To exist, just execute the command:</p> <pre><code>exit\n</code></pre> <p>And that's it! You have successfully set up and compiled the Jetson Inference project. You can now use the provided tools and libraries for real-time video analytics on your NVIDIA Jetson platform.</p>"},{"location":"Tutorials/Computer%20Vision%20Algorithms/AI_Vision_NJN_Set_Up/","title":"Jetson Nano Preparation Guide","text":"<p>This guide will walk you through the process of initializing and preparing your Jetson Nano for usage.</p>"},{"location":"Tutorials/Computer%20Vision%20Algorithms/AI_Vision_NJN_Set_Up/#prerequisites","title":"Prerequisites","text":"<ul> <li>Jetson Nano</li> <li>Mouse, Keyboard, Screen, and a 5V power adapter (included)</li> <li>32GB micro SD card</li> <li>Balena Etcher: balenaEtcher</li> <li>SD Formatter: SD Formatter</li> <li>Jetson Nano SDK: Jetson Nano SDK img</li> </ul>"},{"location":"Tutorials/Computer%20Vision%20Algorithms/AI_Vision_NJN_Set_Up/#steps-to-prepare-jetson-nano","title":"Steps to Prepare Jetson Nano","text":"<ol> <li> <p>Format the SD Card: Insert the SD card into your computer and format it using the SD Formatter tool.</p> </li> <li> <p>Flash the Jetson SDK: Use the Balena Etcher tool to flash the Jetson Nano SDK into the SD card.</p> </li> <li> <p>Insert the SD Card into Jetson Nano: Safely eject the SD card from your computer and insert it into the Jetson Nano.</p> </li> <li> <p>Connect Peripherals: Connect the mouse, keyboard, and screen to the Jetson Nano.</p> </li> <li> <p>Power On: Plug the power adapter into the Jetson Nano. It should power on automatically.</p> </li> <li> <p>Accept EULA: Upon booting, accept the NVIDIA Jetson software End User License Agreement (EULA).</p> </li> <li> <p>Configure System: Select your system language, keyboard layout, and time zone.</p> </li> <li> <p>Create User Account: Create a username, password, and computer name for your Jetson Nano.</p> </li> <li> <p>Allocate APP Partition Size: Select the maximum recommended size for the APP partition.</p> </li> <li> <p>First Commands:      For best practices, begin by executing these commands:</p> <pre><code>sudo apt update\n</code></pre> <pre><code>sudo apt install python3-pip\n</code></pre> <pre><code>sudo pip3 install -U jetson-stats\n</code></pre> <p>To ensure the changes take effect, you need to reboot the system:</p> <pre><code>sudo reboot\n</code></pre> <pre><code>jtop\n</code></pre> </li> </ol> <p>By following these steps, you will have successfully initialized and prepared your Jetson Nano for usage.</p>"},{"location":"Tutorials/Computer%20Vision%20Algorithms/AI_Vision_Root_File_System_to_SD_Card/","title":"Change Root File System to SD Card Directly","text":"<p>In this guide, we will explain how to move your root file system on EMMC flash to SD card storage directly.</p>"},{"location":"Tutorials/Computer%20Vision%20Algorithms/AI_Vision_Root_File_System_to_SD_Card/#how-to-format-the-sd-card-as-ext4","title":"How to format the SD card as ext4","text":"<p>First, connect your SD card to SD card slot and connect the basic interfaces (Ethernet, HDMI, keyboard, mouse) then power on.</p> <p>Open a terminal and type these commands below:</p> <pre><code>sudo jetson_clocks\ngnome-disks\n</code></pre> <p></p> <p>The first command allows the Jetson module\u2019s whole sources to use. The next command opens GNOME Disks application below.</p> <p></p> <p>Format the whole disk before creating the storage.</p> <p></p> <p></p> <p></p> <p>Then, create a new partition from SD card storage.</p> <p></p> <p></p> <p>Format the disk as ext4 format (partition size is up to you but must be min current file system\u2019s size).</p> <p></p> <p>After creating the partition, check it\u2019s name (/dev/mmcblk1p1).</p> <p></p>"},{"location":"Tutorials/Computer%20Vision%20Algorithms/AI_Vision_Root_File_System_to_SD_Card/#how-to-copy-the-root-file-system","title":"How to copy the root file system?","text":"<p>Download the script file from here and extract it. Then, run it with this command below:</p> <pre><code>sudo ./change_rootfs_storage_direct-emmc_to_sdmmc.sh {EXTERNAL_STORAGE}\n</code></pre> <p>In our setup, we typed this command below:</p> <pre><code>sudo ./change_rootfs_storage_direct-emmc_to_sdmmc.sh /dev/mmcblk1p1\n</code></pre> <p></p> <p>A few times later, the whole file system copied and the root path changed. </p> <p></p> <p>It\u2019s time to reboot the Jetson module. Reboot it and check the Root File System copied successfully.</p>"},{"location":"Tutorials/Computer%20Vision%20Algorithms/AI_Vision_Root_File_System_to_SD_Card/#how-to-assign-sd-card-as-root-file-system","title":"How to assign SD card as root file system?","text":"<p>Open a terminal and type this command to check the root mounted from SD card below:</p> <pre><code>df -h\n</code></pre> <p></p> <p>After rebooting you can see that the new storage is assigned as root file system.</p>"},{"location":"Tutorials/Computer%20Vision%20Algorithms/AI_Vision_Use_More_Memory/","title":"Jetson Nano \u2013 Use More Memory!","text":""},{"location":"Tutorials/Computer%20Vision%20Algorithms/AI_Vision_Use_More_Memory/#introduction","title":"Introduction","text":"<p>The NVIDIA Jetson Nano Developer Kit has 4 GB of main memory. This may not enough memory for running many of the large deep learning models, or compiling very large programs. Let\u2019s fix that! We are going to install a swapfile.</p>"},{"location":"Tutorials/Computer%20Vision%20Algorithms/AI_Vision_Use_More_Memory/#installation","title":"Installation","text":"<p>On the JetsonHacksNano account on Github, there is a repository named installSwapFile. Clone the repository, and then switch over to the repository directory:</p> <pre><code>git clone https://github.com/JetsonHacksNano/installSwapfile\n</code></pre> <pre><code>cd installSwapfile\n</code></pre> <p>Run :</p> <pre><code>./installSwapfile.sh\n</code></pre> <p>and a 6 GB swapfile will be installed at /mnt/swapfile.</p> <p>Warning</p> <p>You will need to have enough extra room on your device to install the swapfile.</p> <p>For the 4 GB Jetson Nano, the 6 GB swapfile is what Ubuntu recommends assuming that you are using hibernation. Otherwise 2 GB should do.</p> <p>Reboot the system so the changes take effect :</p> <pre><code>sudo reboot\n</code></pre>"},{"location":"Tutorials/Computer%20Vision%20Algorithms/yolonas/","title":"YOLO-NAS","text":""},{"location":"Tutorials/Computer%20Vision%20Algorithms/yolonas/#introduction","title":"Introduction","text":"<p>A Next-Generation, Object Detection Foundational Model generated by Deci\u2019s Neural Architecture Search Technology.</p> <p>Deci is thrilled to announce the release of a new object detection model, YOLO-NAS - a game-changer in the world of object detection, providing superior real-time object detection capabilities and production-ready performance. Deci's mission is to provide AI teams with tools to remove development barriers and attain efficient inference performance more quickly.</p> <p> <p></p> <p></p> <p>The new YOLO-NAS delivers state-of-the-art (SOTA) performance with the unparalleled accuracy-speed performance, outperforming other models such as YOLOv5, YOLOv6, YOLOv7 and YOLOv8.</p> <p>Deci's proprietary Neural Architecture Search technology, AutoNAC\u2122, generated the YOLO-NAS model. The AutoNAC\u2122 engine lets you input any task, data characteristics (access to data is not required), inference environment and performance targets, and then guides you to find the optimal architecture that delivers the best balance between accuracy and inference speed for your specific application. In addition to being data and hardware aware, the AutoNAC engine considers other components in the inference stack, including compilers and quantization.</p> <p>In terms of pure numbers, YOLO-NAS is ~0.5 mAP point more accurate and 10-20% faster than equivalent variants of YOLOv8 and YOLOv7.</p> Model mAP Latency (ms) YOLO-NAS S 47.5 3.21 YOLO-NAS M 51.55 5.85 YOLO-NAS L 52.22 7.87 YOLO-NAS S INT-8 47.03 2.36 YOLO-NAS M INT-8 51.0 3.78 YOLO-NAS L INT-8 52.1 4.78 <p>mAP numbers in table reported for Coco 2017 Val dataset and latency benchmarked for 640x640 images on Nvidia T4 GPU.</p> <p>YOLO-NAS's architecture employs quantization-aware blocks and selective quantization for optimized performance. When converted to its INT8 quantized version, YOLO-NAS experiences a smaller precision drop (0.51, 0.65, and 0.45 points of mAP for S, M, and L variants) compared to other models that lose 1-2 mAP points during quantization. These techniques culminate in innovative architecture with superior object detection capabilities and top-notch performance.</p>"},{"location":"Tutorials/Computer%20Vision%20Algorithms/yolonas/#configuration","title":"Configuration","text":"<p>Note</p> <p>After installation is complete (it make take a few minutes), you'll need to restart the runtime after installation completes.</p> <pre><code>%%capture\n!pip install super-gradients==3.1.0\n!pip install imutils\n!pip install roboflow\n!pip install pytube --upgrade\n</code></pre>"},{"location":"Tutorials/Computer%20Vision%20Algorithms/yolonas/#supergradients","title":"SuperGradients","text":"<p>SuperGradients is a PyTorch based training library.</p> <p>It provides a uniform interface for the most common computer vision use cases: </p> <ul> <li> <p>Classification</p> </li> <li> <p>Detection</p> </li> <li> <p>Segmentation</p> </li> <li> <p>Pose estimation</p> </li> </ul> <p>There are nearly 40 pretrained models in our model zoo. You can see the pretrained models available to you by following this link.</p> <p>This notebook will focus on using SuperGradients with YOLO-NAS. If you're interested in seeing how SG is used for image classification, you can check out this templated notebook that will make it easy to get started.</p>"},{"location":"Tutorials/Computer%20Vision%20Algorithms/yolonas/#inference-with-yolonas-pretrained-model","title":"Inference with YOLONAS Pretrained Model","text":"<p>Before jumping into the section on fine-tuning, I wanted to show you the power of YOLONAS out of the box. </p> <p>Start by instantiating a pretrained model. YOLONAS comes in three flavors: <code>yolo_nas_s</code>, <code>yolo_nas_m</code>, and <code>yolo_nas_l</code>.</p> <p>You'll use <code>yolo_nas_l</code> throughout this notebook. Because you should always go big, or go home. </p> <p>It's a good life philosophy.</p> <p><pre><code>from super_gradients.training import models\n\nyolo_nas_l = models.get(\"yolo_nas_l\", pretrained_weights=\"coco\")\n</code></pre> You can run the following cell if you're interested in the architecture:</p> <pre><code>!pip install torchinfo\nfrom torchinfo import summary\n\nsummary(model=yolo_nas_l, \n        input_size=(16, 3, 640, 640),\n        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n        col_width=20,\n        row_settings=[\"var_names\"]\n)\n</code></pre>"},{"location":"Tutorials/Computer%20Vision%20Algorithms/yolonas/#inference-on-an-image","title":"Inference on an image","text":"<p>Once the model has been instantiated all you have to do is call the <code>predict</code> method. </p> <p>This method operates on: * PIL Image * Numpy Image * A path to image file  * A path to video file  * A path to folder with images * URL (Image only)</p> <p>Allowing you to perform inference with ease.</p> <p>Note predict also has an argument called <code>conf</code>, which is the threshold for a detection. You change this value as you like, for example <code>model.predict(\"path/to/asset\",conf=0.25)</code></p> <p>Let's perform inference on the following image:</p> <p></p> <pre><code>url = \"https://previews.123rf.com/images/freeograph/freeograph2011/freeograph201100150/158301822-group-of-friends-gathering-around-table-at-home.jpg\"\nyolo_nas_l.predict(url, conf=0.25).show()\n</code></pre> Output <p></p>"},{"location":"Tutorials/Computer%20Vision%20Algorithms/yolonas/#inference-on-video","title":"Inference on video","text":"<p>The following code will display and download stock footage video from YouTube. Here's a link to a playlist that has a lot of stock video clips which are 2mins in length or less.</p> <p>Find a video you like and use YOLONAS to perform some inference on it!</p> <p>All you have to do is get the <code>video_id</code>, and replace the line <code>video_id = 'aE8I7bDf62M'</code> in the cell below with your chosen video's id.</p> <p>The <code>video_id</code> is everything that comes after <code>https://www.youtube.com/watch?v=</code>. For the video below, the full url was <code>https://www.youtube.com/watch?v=aE8I7bDf62M</code>, and thus the video id is <code>aE8I7bDf62M</code>.</p> <pre><code># Import the YouTubeVideo class from IPython.display\nfrom IPython.display import YouTubeVideo\n\n# Define the YouTube video ID\nvideo_id = 'aE8I7bDf62M'  # Replace YOUR_VIDEO_ID with the actual video ID\n\n# Create a YouTubeVideo object with the specified video ID\nvideo = YouTubeVideo(video_id)\n\n# Display the video\ndisplay(video)\n</code></pre> <p><pre><code>%%capture\n# Define the URL of the YouTube video\nvideo_url = f'https://www.youtube.com/watch?v={video_id}'  \n\n# Download the video in mp4 format\n!pip install -U \"git+https://github.com/ytdl-org/youtube-dl.git\"\n!python -m youtube_dl -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4' \"$video_url\"\n\n# Print a success message\nprint('Video downloaded successfully')\n\ninput_video_path = f\"/content/EXTREME SPORTS X DIVERSE-{video_id}.mp4\"\noutput_video_path = \"detections.mp4\"\n</code></pre> Now, you'll peform inference on the video</p> <pre><code>import torch\ndevice = 'cuda' if torch.cuda.is_available() else \"cpu\"\n</code></pre> <pre><code>yolo_nas_l.to(device).predict(input_video_path).save(output_video_path)\n</code></pre> <p>Inference via webcam</p> <p>Check the documentation for inference via webcam.</p>"},{"location":"Tutorials/Computer%20Vision%20Algorithms/yolonas/#fine-tuning-yolonas-on-custom-dataset","title":"Fine-tuning YOLONAS on custom dataset","text":"<p>The trainer The first thing you need to define in SuperGradients is the Trainer.</p> <p>The trainer is in charge of training, evaluation, saving checkpoints, etc. If you're interested in seeing the source code for the trainer, you can do so here.</p> <p>There's two important arguments to the trainer: 1. <code>ckpt_root_dir</code> - this is the directory where results from all your experiments will be saved</p> <ol> <li><code>experiment_name</code> - all checkpoints, logs, and tensorboards will be saved in a directory with the name you specify here. </li> </ol> <p>In the code below, you'll instantiate the trainer with just a single GPU (since that's what Google Colab provides).</p> <pre><code>from super_gradients.training import Trainer\n\nCHECKPOINT_DIR = '/content/drive/MyDrive/YOLO-NAS/checkpoints'\ntrainer = Trainer(experiment_name='my_first_yolonas_run', ckpt_root_dir=CHECKPOINT_DIR)\n</code></pre>"},{"location":"Tutorials/Computer%20Vision%20Algorithms/yolonas/#fine-tuning-yolonas-on-custom-dataset_1","title":"Fine-tuning YOLONAS on custom dataset","text":"<p>SuperGradients is fully compatible with PyTorch Datasets and Dataloaders, so you can use your dataloaders as is. </p> <p>There are several well-known datasets for object detection, for example: </p> <ul> <li>COCO</li> <li>Pascal</li> <li>YOLODarkNet</li> <li>YOLOv5</li> </ul> <p>SuperGradients provides ready-to-use dataloaders for these datasets. If you're interested in learning more about working with <code>COCOFormatDetectionDataset</code> and the more general <code>DetectionDataset</code> check out the SuperGradients documentation on this topic</p> <p>You can learn more about working with SuperGradients datasets, dataloaders, and configuration files here.</p> <p>SuperGradients supports a number of dataset formats, you can learn more about that here.</p> <p>For this example you'll use the the U.S. Coins Dataset from RoboFlow with the dataset in YOLOv5 format.</p> <p>Some datasets you might want to try: - HuggingFace competition: Ship detection</p> <ul> <li> <p>Aquarium dataset on RoboFlow</p> </li> <li> <p>Vehicles-OpenImages Dataset on RoboFlow</p> </li> <li> <p>Winegrape detection</p> </li> <li> <p>Low light object detection</p> </li> <li> <p>Infrafred person detection</p> </li> <li> <p>Pothole detection</p> </li> <li> <p>100k Labeled Road Images | Day, Night</p> </li> <li> <p>Deep Fashion dataset</p> </li> <li> <p>Playing card detection</p> </li> <li> <p>Anaomoly detection in videos</p> </li> <li> <p>Underwater fish recognition</p> </li> <li> <p>Document layout detection</p> </li> <li> <p>Trash Annotations in Context</p> </li> </ul> <p><pre><code>from roboflow import Roboflow\nrf = Roboflow(api_key=\"&lt;your-roboflow-key-here&gt;\")\nproject = rf.workspace(\"atathamuscoinsdataset\").project(\"u.s.-coins-dataset-a.tatham\")\ndataset = project.version(5).download(\"yolov5\")\n</code></pre> Start by importing the required modules, which will help you create SuperGradients dataloaders.</p> <p><pre><code>from super_gradients.training import dataloaders\nfrom super_gradients.training.dataloaders.dataloaders import coco_detection_yolo_format_train, coco_detection_yolo_format_val\n</code></pre> You'll need to load your dataset parameters into a dictionary, specifically defining:</p> <ul> <li>path to the parent directory where your data lives</li> <li>the child directory names for training, validation, and test (if you have testing set) images and labels</li> <li>class names</li> </ul> <p><pre><code>dataset_params = {\n    'data_dir':'/content/U.S.-Coins-Dataset---A.Tatham-5',\n    'train_images_dir':'train/images',\n    'train_labels_dir':'train/labels',\n    'val_images_dir':'valid/images',\n    'val_labels_dir':'valid/labels',\n    'test_images_dir':'test/images',\n    'test_labels_dir':'test/labels',\n    'classes': ['Dime', 'Nickel', 'Penny', 'Quarter']\n}\n</code></pre> You pass the values for <code>dataset_params</code> into the <code>dataset_params</code> argument as shown below.</p> <p>You can also pass PyTorch DataLoaders arguments when instantiating your dataset. Here you'll set <code>batch_size=16</code> and <code>num_workers=2</code>.</p> <p>Repeat this for the validation and testing datasets, note that for training and testing data we use <code>coco_detection_yolo_format_val</code> to instantiate the dataloader.</p> <p>The dataloaders will print warnings when an annotation does not conform to the expected format. This particular dataset has many such annotations, thus the warnings will be muted.</p> <p><pre><code>from IPython.display import clear_output\n\ntrain_data = coco_detection_yolo_format_train(\n    dataset_params={\n        'data_dir': dataset_params['data_dir'],\n        'images_dir': dataset_params['train_images_dir'],\n        'labels_dir': dataset_params['train_labels_dir'],\n        'classes': dataset_params['classes']\n    },\n    dataloader_params={\n        'batch_size':16,\n        'num_workers':2\n    }\n)\n\nval_data = coco_detection_yolo_format_val(\n    dataset_params={\n        'data_dir': dataset_params['data_dir'],\n        'images_dir': dataset_params['val_images_dir'],\n        'labels_dir': dataset_params['val_labels_dir'],\n        'classes': dataset_params['classes']\n    },\n    dataloader_params={\n        'batch_size':16,\n        'num_workers':2\n    }\n)\n\ntest_data = coco_detection_yolo_format_val(\n    dataset_params={\n        'data_dir': dataset_params['data_dir'],\n        'images_dir': dataset_params['test_images_dir'],\n        'labels_dir': dataset_params['test_labels_dir'],\n        'classes': dataset_params['classes']\n    },\n    dataloader_params={\n        'batch_size':16,\n        'num_workers':2\n    }\n)\n\nclear_output()\n</code></pre> Now inspect the dataset defined earlier. SuperGradients added <code>transforms</code> for you. You're free to experiment with these transformations as you please. You can also add in your own transformations from <code>torchvision.transforms</code>, <code>albumentations</code> or a custom tranformaton.</p> <pre><code>train_data.dataset.transforms\n</code></pre> <p>The transforms are in a dictionary, so you'll need to slice it to modify.</p> <p>For example...</p> <pre><code>train_data.dataset.dataset_params['transforms'][1]\n</code></pre> <pre><code>train_data.dataset.dataset_params['transforms'][1]['DetectionRandomAffine']['degrees'] = 10.42\n</code></pre> <p>You can plot a batch of training data with their augmentations applied to see what they look like:</p> <pre><code>train_data.dataset.plot()\n</code></pre> Output <p></p>"},{"location":"Tutorials/Computer%20Vision%20Algorithms/yolonas/#fine-tuning-yolonas-on-custom-dataset_2","title":"Fine-tuning YOLONAS on custom dataset","text":"<p>You saw how to instantiate the model for inference earlier. </p> <p>Below is how to instantiate the model for finetuning. Note you need to add the <code>num_classes</code> argument here.</p> <p>Note, for this tutorial you're using <code>yolo_nas_l</code>, but SuperGradients has two other flavors of YOLONAS available to you: <code>yolo_nas_s</code> and <code>yolo_nas_m</code>.</p> <pre><code>from super_gradients.training import models\nmodel = models.get('yolo_nas_l', \n                   num_classes=len(dataset_params['classes']), \n                   pretrained_weights=\"coco\"\n                   )\n</code></pre>"},{"location":"Tutorials/Computer%20Vision%20Algorithms/yolonas/#define-metrics-and-training-parameters","title":"Define metrics and training parameters","text":"<p>You need to define the training parameters for your training run. </p> <p>Full details about the training parameters can be found here.</p> <p>There are a few ***mandatory* arguments that you must define for training params**</p> <ul> <li> <p><code>max_epochs</code> - Max number of training epochs</p> </li> <li> <p><code>loss</code> - the loss function you want to use</p> </li> <li> <p><code>optimizer</code> - Optimizer you will be using</p> </li> <li> <p><code>train_metrics_list</code> - Metrics to log during training</p> </li> <li> <p><code>valid_metrics_list</code> - Metrics to log during training</p> </li> <li> <p><code>metric_to_watch</code> - metric which the model checkpoint will be saved according to</p> </li> </ul> <p>You can choose from a variety of <code>optimizer</code>'s such as: Adam, AdamW, SGD, Lion, or RMSProps. If you choose to change the defualt parameters of these optimizrs you pass them into <code>optimizer_params</code>. </p> <p>Integrations with experiment monitoring tools SuperGradients has native integrations with Tensorboard, Weights and Biases, ClearML, and DagsHub. </p> <p>If your favorite monitoring tool is not supported by SuperGradients, you can simply implement a class inheriting from BaseSGLogger that you will then pass to the training parameters.</p> <p>If you're interested in monitoring experiments, you can learn more in the docs.</p> <p>SuperGradients offers a number of training tricks right out of the box, such as:</p> <ul> <li>Exponential moving average</li> <li>Zero weight decay on bias and batch normalizatiom</li> <li>Weight averaging</li> <li>Batch accumulation</li> <li>Precise BatchNorm</li> </ul> <p>You can read more details about these training tricks here.</p> <p>If you're interested in building a using a custom metric with SuperGradients you can learn how here.</p> <p>Note you will have to set number of classes in two places below: <code>PPYoloELoss</code> and <code>DetectionMetrics_050</code>.</p> <p>You probably noticed that we make use of a post prediction callback, for details on how phase callbacks work in SuperGradients check out our documentation.</p> <p>Note</p> <p>I've enabled <code>silent_mode</code> so the notebook doesn't get longer than it already is. You should disable it so you can see what SuperGradients outputs during training.</p> <pre><code>from super_gradients.training.losses import PPYoloELoss\nfrom super_gradients.training.metrics import DetectionMetrics_050\nfrom super_gradients.training.models.detection_models.pp_yolo_e import PPYoloEPostPredictionCallback\n\ntrain_params = {\n    # ENABLING SILENT MODE\n    'silent_mode': True,\n    \"average_best_models\":True,\n    \"warmup_mode\": \"linear_epoch_step\",\n    \"warmup_initial_lr\": 1e-6,\n    \"lr_warmup_epochs\": 3,\n    \"initial_lr\": 5e-4,\n    \"lr_mode\": \"cosine\",\n    \"cosine_final_lr_ratio\": 0.1,\n    \"optimizer\": \"Adam\",\n    \"optimizer_params\": {\"weight_decay\": 0.0001},\n    \"zero_weight_decay_on_bias_and_bn\": True,\n    \"ema\": True,\n    \"ema_params\": {\"decay\": 0.9, \"decay_type\": \"threshold\"},\n    # ONLY TRAINING FOR 10 EPOCHS FOR THIS EXAMPLE NOTEBOOK\n    \"max_epochs\": 10,\n    \"mixed_precision\": True,\n    \"loss\": PPYoloELoss(\n        use_static_assigner=False,\n        # NOTE: num_classes needs to be defined here\n        num_classes=len(dataset_params['classes']),\n        reg_max=16\n    ),\n    \"valid_metrics_list\": [\n        DetectionMetrics_050(\n            score_thres=0.1,\n            top_k_predictions=300,\n            # NOTE: num_classes needs to be defined here\n            num_cls=len(dataset_params['classes']),\n            normalize_targets=True,\n            post_prediction_callback=PPYoloEPostPredictionCallback(\n                score_threshold=0.01,\n                nms_top_k=1000,\n                max_predictions=300,\n                nms_threshold=0.7\n            )\n        )\n    ],\n    \"metric_to_watch\": 'mAP@0.50'\n}\n</code></pre>"},{"location":"Tutorials/Computer%20Vision%20Algorithms/yolonas/#training-the-model","title":"Training the model","text":"<p>You've covered a lot of ground so far:</p> <ul> <li> <p> Instantiated the trainer</p> </li> <li> <p> Defined your dataset parameters and dataloaders</p> </li> <li> <p> Instantiated a model</p> </li> <li> <p> Set up your training parameters</p> </li> </ul> <p>Now, its time to train a model</p> <p>Training a model using a SuperGradients is done using the <code>trainer</code>.</p> <p>It's as easy as...</p> <p>trainer.train(model=model,                training_params=train_params,                train_loader=train_data,                valid_loader=val_data)</p>"},{"location":"Tutorials/Computer%20Vision%20Algorithms/yolonas/#get-the-best-trained-model","title":"Get the best trained model","text":"<p>Now that training is complete, you need to get the best trained model.</p> <p>You used checkpoint averaging so the following code will use weights averaged across training runs. </p> <p>If you want to use the best weights, or weights from the last epoch you'd use one of the following in the code below:</p> <ul> <li> <p>best weights: <code>checkpoint_path = checkpoints/my_first_yolonas_run/ckpt_best.pth</code></p> </li> <li> <p>last weights: <code>checkpoint_path = checkpoints/my_first_yolonas_run/ckpt_latest.pth</code></p> </li> </ul> <pre><code>best_model = models.get('yolo_nas_l',\n                        num_classes=len(dataset_params['classes']),\n                        checkpoint_path=\"checkpoints/my_first_yolonas_run/average_model.pth\")\n</code></pre>"},{"location":"Tutorials/Computer%20Vision%20Algorithms/yolonas/#evaluating-the-best-trained-model-on-the-test-set","title":"Evaluating the best trained model on the test set","text":"<pre><code>trainer.test(model=best_model,\n            test_loader=test_data,\n            test_metrics_list=DetectionMetrics_050(score_thres=0.1, \n                                                   top_k_predictions=300, \n                                                   num_cls=len(dataset_params['classes']), \n                                                   normalize_targets=True, \n                                                   post_prediction_callback=PPYoloEPostPredictionCallback(score_threshold=0.01, \n                                                                                                          nms_top_k=1000, \n                                                                                                          max_predictions=300,                                                                              \n                                                                                                          nms_threshold=0.7)\n                                                  ))\n</code></pre>"},{"location":"Tutorials/Computer%20Vision%20Algorithms/yolonas/#predicting-with-the-best-model","title":"Predicting with the best model","text":"<p>The next line will perform detection on the following image. Note, we didn't have a class for the half dollar coin. So it will likely get classified as something else.</p> <p></p> <p>The results aren't too bad after just a few epochs!</p> <pre><code>img_url = 'https://www.mynumi.net/media/catalog/product/cache/2/image/9df78eab33525d08d6e5fb8d27136e95/s/e/serietta_usa_2_1/www.mynumi.net-USASE5AD160-31.jpg'\nbest_model.predict(img_url).show()\n</code></pre>"},{"location":"Tutorials/Computer%20Vision%20Algorithms/yolonas/#post-training-quantization-ptq-and-quantization-aware-training-qat","title":"Post training quantization (PTQ) and quantization aware training (QAT)","text":"<p>SuperGradients offers PTQ and QAT out of the box. That's beyond the scope of this introductory tutorial. It is, in my opinion, a truly awesome feature. </p> <p>Not many training libaries offer this out of the box.  You can learn more about PTQ and QAT here.</p> <p>An example specific to YOLONAS can be found here.</p>"},{"location":"Tutorials/Generative%20AI/","title":"Generative AI","text":"<p>In this section, I will share tutorials about leveraging generative AI to create innovative solutions. Generative AI has the potential to revolutionize various industries, from art and design to healthcare and finance. Through these tutorials, you will learn the fundamentals of generative AI and how to apply them to real-world problems.</p>"},{"location":"Tutorials/Generative%20AI/host_llm_locally/","title":"Host LLM Locally","text":""},{"location":"Tutorials/Generative%20AI/host_llm_locally/#installing-wsl","title":"Installing WSL","text":"<p>To get started, you'll need to install WSL. Run the following command in your Windows terminal:</p> <pre><code>wsl --install\n</code></pre> <p>This will install WSL and launch a new window with the Ubuntu distribution.</p>"},{"location":"Tutorials/Generative%20AI/host_llm_locally/#connecting-to-a-wsl-instance","title":"Connecting to a WSL Instance","text":"<p>To connect to an existing WSL instance, run the following command:</p> <pre><code>wsl -d Ubuntu\n</code></pre>"},{"location":"Tutorials/Generative%20AI/host_llm_locally/#installing-ollama","title":"Installing Ollama","text":"<p>Ollama is a popular tool for working with local LLMs.</p>"},{"location":"Tutorials/Generative%20AI/host_llm_locally/#monitoring-gpu-performance","title":"Monitoring GPU Performance","text":"<p>Run the following command to view your GPU's performance:</p> <pre><code>watch -n 0.5 nvidia-smi\n</code></pre> <p>This will display an update every 0.5 seconds.</p>"},{"location":"Tutorials/Generative%20AI/host_llm_locally/#installing-docker","title":"Installing Docker","text":"<ul> <li>Update your package list:</li> </ul> <pre><code>sudo apt-get update\n</code></pre> <ul> <li>Install the necessary packages:</li> </ul> <pre><code>sudo apt-get install ca-certificates curl\n</code></pre> <ul> <li>Install Docker's official GPG key:</li> </ul> <pre><code>curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc\n</code></pre> <ul> <li>Add the Docker repository to your package list:</li> </ul> <pre><code>echo \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu $(. /etc/os-release &amp;&amp; echo \"$VERSION_CODENAME\") stable\" | tee /etc/apt/sources.list.d/docker.list\n</code></pre> <ul> <li>Update your package list:</li> </ul> <pre><code>sudo apt-get update\n</code></pre> <ul> <li>Install Docker:</li> </ul> <pre><code>sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n</code></pre>"},{"location":"Tutorials/Generative%20AI/host_llm_locally/#running-open-webui","title":"Running Open WebUI","text":"<pre><code>docker run -d --network=host -v open-webui:/app/backend/data -e OLLAMA_BASE_URL=http://127.0.0.1:11434 --name open-webui --restart always ghcr.io/open-webui/open-webui:main\n</code></pre>"},{"location":"Tutorials/Generative%20AI/host_llm_locally/#accessing-open-webui-running-on-a-wsl-instance-from-outside-the-host-computer","title":"Accessing Open WebUI running on a WSL instance from outside the host computer","text":"<ul> <li>Port forwarding using Powershell in Admin mode:</li> </ul> <pre><code>netsh interface portproxy add v4tov4 listenport=8080 listenaddress=0.0.0.0 connectport=8080 connectaddress=[WSL_IP]\n</code></pre> <ul> <li>Retrieve WSL_IP, in a ubuntu terminal run this command:</li> </ul> <pre><code>ip addr show eth0 | grep -oP '(?&lt;=inet\\s)\\d+(\\.\\d+){3}'\n</code></pre> <ul> <li>Punch a hole in Firewall to allow this port to be reached from outside:</li> </ul> <pre><code>New-NetFirewallRule -DisplayName \"Allow WSL2 Port\" -Description \"To allow Open WebUI through the firewall.\" -Direction Inbound -Action Allow -Protocol TCP -LocalPort 8080\n</code></pre>"},{"location":"Tutorials/Generative%20AI/host_llm_locally/#installing-stable-diffusion","title":"Installing Stable Diffusion","text":""},{"location":"Tutorials/Generative%20AI/host_llm_locally/#prerequisites","title":"Prerequisites","text":"<ul> <li>Pyenv: Install Pyenv and its prerequisites using the following command:</li> </ul> <pre><code>sudo apt install -y make build-essential libssl-dev zlib1g-dev libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev libncursesw5-dev xz-utils tk-dev libffi-dev liblzma-dev git\n</code></pre> <ul> <li>Pyenv: Run the following command to install Pyenv:</li> </ul> <pre><code>curl https://pyenv.run | bash\n</code></pre> <ul> <li>Add to the Path:</li> </ul> <pre><code>echo 'export PATH=\"$HOME/.pyenv/bin:$PATH\"' &gt;&gt; ~/.bash_profile\necho 'eval \"$(pyenv init --path)\"' &gt;&gt; ~/.bash_profile\necho 'eval \"$(pyenv init -)\"' &gt;&gt; ~/.bash_profile\nsource ~/.bashrc\n</code></pre> <ul> <li>Python 3.10: Install Python 3.10 using Pyenv:</li> </ul> <pre><code>pyenv install 3.10\n</code></pre> <ul> <li>Make it global: Make sure to use the global shell:</li> </ul> <pre><code>pyenv global 3.10\n</code></pre>"},{"location":"Tutorials/Generative%20AI/host_llm_locally/#installing-stable-diffusion_1","title":"Installing Stable Diffusion","text":"<ol> <li>Download the webui.sh script from here, or by this command:</li> </ol> <pre><code>wget https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh\n</code></pre> <ol> <li>Run the following command to make the script executable:</li> </ol> <pre><code>chmod +x webui.sh\n</code></pre> <ol> <li>Run the following command to start Stable Diffusion:</li> </ol> <pre><code>./webui.sh --listen --api\n</code></pre> <p>Note: This is just a basic setup guide and may require additional steps or configurations depending on your specific use case.</p>"},{"location":"Tutorials/Generative%20AI/lightrag/","title":"LightRAG Documentation","text":""},{"location":"Tutorials/Generative%20AI/lightrag/#installation","title":"Installation","text":""},{"location":"Tutorials/Generative%20AI/lightrag/#install-from-source","title":"Install from source","text":"<pre><code>cd LightRAG\npip install -e .\n</code></pre>"},{"location":"Tutorials/Generative%20AI/lightrag/#quick-start","title":"Quick Start","text":"<ol> <li>Download the demo text \"A Christmas Carol by Charles Dickens\":</li> </ol> <pre><code>curl https://raw.githubusercontent.com/gusye1234/nano-graphrag/main/tests/mock_data.txt &gt; ./book.txt\n</code></pre> <ol> <li>Create a new file <code>lightrag.py</code> in your project directory and add the following code:</li> </ol> <pre><code>from lightrag import LightRAG, QueryParam\nfrom lightrag.llm import gpt_4o_mini_complete\nimport os\n\nos.environ[\"OPENAI_API_KEY\"] = \"\"\n\nWORKING_DIR = \"./dickens\"\n\nif not os.path.exists(WORKING_DIR):\n    os.mkdir(WORKING_DIR)\n\nrag = LightRAG(\n    working_dir=WORKING_DIR,\n    llm_model_func=gpt_4o_mini_complete  # Use gpt_4o_mini_complete LLM model\n    # llm_model_func=gpt_4o_complete  # Optionally, use a stronger model\n)\n\nwith open(\"./book.txt\", encoding='utf-8') as f:\n    rag.insert(f.read())\n\n# Perform naive search\nprint(rag.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"naive\")))\n\n# Perform local search\nprint(rag.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"local\")))\n\n# Perform global search\nprint(rag.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"global\")))\n\n# Perform hybrid search\nprint(rag.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"hybrid\")))\n</code></pre> <ol> <li>Run the script:</li> </ol> <pre><code>python lightrag.py\n</code></pre>"},{"location":"Tutorials/Generative%20AI/lightrag/#using-hugging-face-models","title":"Using Hugging Face Models","text":"<p>To use Hugging Face models with LightRAG, configure it as follows:</p> <pre><code>from lightrag.llm import hf_model_complete, hf_embedding\nfrom transformers import AutoModel, AutoTokenizer\n\n# Initialize LightRAG with Hugging Face model\nrag = LightRAG(\n    working_dir=WORKING_DIR,\n    llm_model_func=hf_model_complete,  # Use Hugging Face complete model for text generation\n    llm_model_name='meta-llama/Llama-3.1-8B-Instruct',  # Model name from Hugging Face\n    # Use Hugging Face embedding function\n    embedding_func=EmbeddingFunc(\n        embedding_dim=384,\n        max_token_size=5000,\n        func=lambda texts: hf_embedding(\n            texts, \n            tokenizer=AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\"),\n            embed_model=AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n        )\n    ),\n)\n</code></pre>"},{"location":"Tutorials/Generative%20AI/lightrag/#advanced-usage","title":"Advanced Usage","text":""},{"location":"Tutorials/Generative%20AI/lightrag/#batch-insert","title":"Batch Insert","text":"<p>Insert multiple texts at once:</p> <pre><code>rag.insert([\"TEXT1\", \"TEXT2\", ...])\n</code></pre>"},{"location":"Tutorials/Generative%20AI/lightrag/#incremental-insert","title":"Incremental Insert","text":"<p>Insert new documents into an existing LightRAG instance:</p> <pre><code>rag = LightRAG(working_dir=\"./dickens\")\n\nwith open(\"./newText.txt\") as f:\n    rag.insert(f.read())\n</code></pre>"},{"location":"Tutorials/Generative%20AI/lightrag/#evaluation","title":"Evaluation","text":""},{"location":"Tutorials/Generative%20AI/lightrag/#dataset","title":"Dataset","text":"<p>The dataset used in LightRAG can be downloaded from TommyChien/UltraDomain.</p>"},{"location":"Tutorials/Generative%20AI/lightrag/#generate-query","title":"Generate Query","text":"<p>LightRAG uses the following prompt to generate high-level queries. The corresponding code is located in <code>example/generate_query.py</code>.</p> <pre><code>Given the following description of a dataset:\n\n{description}\n\nPlease identify 5 potential users who would engage with this dataset. For each user, list 5 tasks they would perform with this dataset. Then, for each (user, task) combination, generate 5 questions that require a high-level understanding of the entire dataset.\n\nOutput the results in the following structure:\n- User 1: [user description]\n    - Task 1: [task description]\n        - Question 1:\n        - Question 2:\n        - Question 3:\n        - Question 4:\n        - Question 5:\n    - Task 2: [task description]\n        ...\n    - Task 5: [task description]\n- User 2: [user description]\n    ...\n- User 5: [user description]\n    ...\n</code></pre>"},{"location":"Tutorials/Generative%20AI/lightrag/#batch-eval","title":"Batch Eval","text":"<p>To evaluate the performance of two RAG systems on high-level queries, LightRAG uses the following prompt. The specific code is available in <code>example/batch_eval.py</code>.</p> <pre><code>---Role---\nYou are an expert tasked with evaluating two answers to the same question based on three criteria: **Comprehensiveness**, **Diversity**, and **Empowerment**.\n\n---Goal---\nYou will evaluate two answers to the same question based on three criteria: **Comprehensiveness**, **Diversity**, and **Empowerment**. \n\n- **Comprehensiveness**: How much detail does the answer provide to cover all aspects and details of the question?\n- **Diversity**: How varied and rich is the answer in providing different perspectives and insights on the question?\n- **Empowerment**: How well does the answer help the reader understand and make informed judgments about the topic?\n\nFor each criterion, choose the better answer (either Answer 1 or Answer 2) and explain why. Then, select an overall winner based on these three categories.\n\nHere is the question:\n{query}\n\nHere are the two answers:\n\n**Answer 1:**\n{answer1}\n\n**Answer 2:**\n{answer2}\n\nEvaluate both answers using the three criteria listed above and provide detailed explanations for each criterion.\n\nOutput your evaluation in the following JSON format:\n\n{\n    \"Comprehensiveness\": {\n        \"Winner\": \"[Answer 1 or Answer 2]\",\n        \"Explanation\": \"[Provide explanation here]\"\n    },\n    \"Diversity\": {\n        \"Winner\": \"[Answer 1 or Answer 2]\",\n        \"Explanation\": \"[Provide explanation here]\"\n    },\n    \"Empowerment\": {\n        \"Winner\": \"[Answer 1 or Answer 2]\",\n        \"Explanation\": \"[Provide explanation here]\"\n    },\n    \"Overall Winner\": {\n        \"Winner\": \"[Answer 1 or Answer 2]\",\n        \"Explanation\": \"[Summarize why this answer is the overall winner based on the three criteria]\"\n    }\n}\n</code></pre>"},{"location":"Tutorials/Libraries/","title":"Libraries","text":"<ul> <li> <p> NumPy</p> <p>Install <code>NumPy</code> with <code>pip</code> and get up  Getting started</p> </li> </ul> <ul> <li> <p> Pandas</p> <p>Install <code>Pandas</code> with <code>pip</code> and get up  Getting started</p> </li> </ul>"},{"location":"Tutorials/Libraries/numpy/","title":"NumPy","text":"<p>NumPy is the fundamental library for scientific computing with Python. NumPy is centered around a powerful N-dimensional array object, and it also contains useful linear algebra, Fourier transform, and random number functions.</p>"},{"location":"Tutorials/Libraries/numpy/#creating-arrays","title":"Creating Arrays","text":"<p>Now let's import <code>numpy</code>. Most people import it as <code>np</code>:</p> <pre><code>import numpy as np\n</code></pre>"},{"location":"Tutorials/Libraries/numpy/#npzeros","title":"np.zeros","text":"<p>The <code>zeros</code> function creates an array containing any number of zeros:</p> <pre><code>np.zeros(5)\n</code></pre> Output <p>array([0., 0., 0., 0., 0.])</p> <p>It's just as easy to create a 2D array (ie. a matrix) by providing a tuple with the desired number of rows and columns. For example, here's a 3x4 matrix:</p> <pre><code>np.zeros((3,4))\n</code></pre> Output <p>array([[0., 0., 0., 0.],        [0., 0., 0., 0.],        [0., 0., 0., 0.]])</p>"},{"location":"Tutorials/Libraries/numpy/#some-vocabulary","title":"Some vocabulary","text":"<ul> <li> <p>In NumPy, each dimension is called an axis.</p> </li> <li> <p>The number of axes is called the rank.</p> <ul> <li> <p>For example, the above 3x4 matrix is an array of rank 2 (it is 2-dimensional).</p> </li> <li> <p>The first axis has length 3, the second has length 4.</p> </li> </ul> </li> <li> <p>An array's list of axis lengths is called the shape of the array.</p> <ul> <li> <p>For example, the above matrix's shape is <code>(3, 4)</code>.</p> </li> <li> <p>The rank is equal to the shape's length.</p> </li> </ul> </li> <li> <p>The size of an array is the total number of elements, which is the product of all axis lengths (eg. 3*4=12)</p> </li> </ul> <pre><code>a = np.zeros((3,4))\na\n</code></pre> Output <p>array([[0., 0., 0., 0.],        [0., 0., 0., 0.],        [0., 0., 0., 0.]])</p> <pre><code>a.shape\n</code></pre> Output <p>(3, 4)</p> <pre><code>a.ndim  # equal to len(a.shape)\n</code></pre> Output <p>2</p> <pre><code>a.size\n</code></pre> Output <p>12</p>"},{"location":"Tutorials/Libraries/numpy/#n-dimensional-arrays","title":"N-dimensional arrays","text":"<p>You can also create an N-dimensional array of arbitrary rank. For example, here's a 3D array (rank=3), with shape <code>(2,3,4)</code>:</p> <pre><code>np.zeros((2,3,4))\n</code></pre> Output <p>array([[[0., 0., 0., 0.],         [0., 0., 0., 0.],         [0., 0., 0., 0.]],</p> <pre><code>   [[0., 0., 0., 0.],\n    [0., 0., 0., 0.],\n    [0., 0., 0., 0.]]])\n</code></pre>"},{"location":"Tutorials/Libraries/numpy/#array-type","title":"Array type","text":"<p>NumPy arrays have the type <code>ndarrays</code>:</p> <pre><code>type(np.zeros((3,4)))\n</code></pre> Output <p>numpy.ndarray</p>"},{"location":"Tutorials/Libraries/numpy/#npones","title":"np.ones","text":"<p>Many other NumPy functions create ndarrays.</p> <p>Here's a 3x4 matrix full of ones:</p> <pre><code>np.ones((3,4))\n</code></pre> Output <p>array([[1., 1., 1., 1.],        [1., 1., 1., 1.],        [1., 1., 1., 1.]])</p>"},{"location":"Tutorials/Libraries/numpy/#npfull","title":"np.full","text":"<p>Creates an array of the given shape initialized with the given value. Here's a 3x4 matrix full of <code>\u03c0</code>.</p> <pre><code>np.full((3,4), np.pi)\n</code></pre> Output <p>array([[3.14159265, 3.14159265, 3.14159265, 3.14159265],        [3.14159265, 3.14159265, 3.14159265, 3.14159265],        [3.14159265, 3.14159265, 3.14159265, 3.14159265]])</p>"},{"location":"Tutorials/Libraries/numpy/#npempty","title":"np.empty","text":"<p>An uninitialized 2x3 array (its content is not predictable, as it is whatever is in memory at that point):</p> <pre><code>np.empty((2,3))\n</code></pre> Output <p>array([[0., 0., 0.],        [0., 0., 0.]])</p>"},{"location":"Tutorials/Libraries/numpy/#nparray","title":"np.array","text":"<p>Of course you can initialize an <code>ndarray</code> using a regular python array. Just call the <code>array</code> function:</p> <pre><code>np.array([[1,2,3,4], [10, 20, 30, 40]])\n</code></pre> Output <p>array([[ 1,  2,  3,  4],        [10, 20, 30, 40]])</p>"},{"location":"Tutorials/Libraries/numpy/#nparange","title":"np.arange","text":"<p>You can create an <code>ndarray</code> using NumPy's <code>arange</code> function, which is similar to python's built-in <code>range</code> function:</p> <pre><code>np.arange(1, 5)\n</code></pre> Output <p>array([1, 2, 3, 4])</p> <p>It also works with floats:</p> <pre><code>np.arange(1.0, 5.0)\n</code></pre> Output <p>array([1., 2., 3., 4.])</p> <p>Of course you can provide a step parameter:</p> <pre><code>np.arange(1, 5, 0.5)\n</code></pre> Output <p>array([1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5])</p> <p>However, when dealing with floats, the exact number of elements in the array is not always predictible. For example, consider this:</p> <pre><code>print(np.arange(0, 5/3, 1/3)) # depending on floating point errors, the max value is 4/3 or 5/3.\nprint(np.arange(0, 5/3, 0.333333333))\nprint(np.arange(0, 5/3, 0.333333334))\n</code></pre> Output <p>[0.         0.33333333 0.66666667 1.         1.33333333 1.66666667] [0.         0.33333333 0.66666667 1.         1.33333333 1.66666667] [0.         0.33333333 0.66666667 1.         1.33333334]</p>"},{"location":"Tutorials/Libraries/numpy/#nplinspace","title":"np.linspace","text":"<p>For this reason, it is generally preferable to use the <code>linspace</code> function instead of <code>arange</code> when working with floats. The <code>linspace</code> function returns an array containing a specific number of points evenly distributed between two values (note that the maximum value is included, contrary to <code>arange</code>):</p> <pre><code>print(np.linspace(0, 5/3, 6))\n</code></pre> Output <p>[0.         0.33333333 0.66666667 1.         1.33333333 1.66666667]</p>"},{"location":"Tutorials/Libraries/numpy/#nprand-and-nprandn","title":"np.rand and np.randn","text":"<p>A number of functions are available in NumPy's <code>random</code> module to create <code>ndarray</code>s initialized with random values. For example, here is a 3x4 matrix initialized with random floats between 0 and 1 (uniform distribution):</p> <pre><code>np.random.rand(3,4)\n</code></pre> Output <p>array([[0.07951522, 0.82516403, 0.54524215, 0.46662691],        [0.12016334, 0.74912183, 0.183234  , 0.105027  ],        [0.22051959, 0.26931151, 0.02739192, 0.4721405 ]])</p> <p>Here's a 3x4 matrix containing random floats sampled from a univariate normal distribution (Gaussian distribution) of mean 0 and variance 1:</p> <pre><code>np.random.randn(3,4)\n</code></pre> Output <p>array([[ 0.09545957,  0.14828368, -0.91504156, -0.36224068],        [ 0.55434999,  0.41143633,  0.84385243, -0.3652369 ],        [ 1.48071803, -1.45297797,  1.24551713,  0.4508626 ]])</p> <p>To give you a feel of what these distributions look like, let's use matplotlib (see the matplotlib tutorial for more details):</p> <pre><code>%matplotlib inline\nimport matplotlib.pyplot as plt\n</code></pre> <pre><code>plt.hist(np.random.rand(100000), density=True, bins=100, histtype=\"step\", color=\"blue\", label=\"rand\")\nplt.hist(np.random.randn(100000), density=True, bins=100, histtype=\"step\", color=\"red\", label=\"randn\")\nplt.axis([-2.5, 2.5, 0, 1.1])\nplt.legend(loc = \"upper left\")\nplt.title(\"Random distributions\")\nplt.xlabel(\"Value\")\nplt.ylabel(\"Density\")\nplt.show()\n</code></pre> Output <p></p>"},{"location":"Tutorials/Libraries/numpy/#npfromfunction","title":"np.fromfunction","text":"<p>You can also initialize an <code>ndarray</code> using a function:</p> <pre><code>def my_function(z, y, x):\n    return x + 10 * y + 100 * z\n\nnp.fromfunction(my_function, (3, 2, 10))\n</code></pre> Output <p>array([[[  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.],         [ 10.,  11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.]],</p> <pre><code>   [[100., 101., 102., 103., 104., 105., 106., 107., 108., 109.],\n    [110., 111., 112., 113., 114., 115., 116., 117., 118., 119.]],\n\n   [[200., 201., 202., 203., 204., 205., 206., 207., 208., 209.],\n    [210., 211., 212., 213., 214., 215., 216., 217., 218., 219.]]])\n</code></pre> <p>NumPy first creates three <code>ndarrays</code> (one per dimension), each of shape <code>(3, 2, 10)</code>. Each array has values equal to the coordinate along a specific axis. For example, all elements in the <code>z</code> array are equal to their z-coordinate:</p> <pre><code>[[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n\n [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n  [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n\n [[ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.]\n  [ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.]]]\n</code></pre> <p>So the terms <code>x</code>, <code>y</code> and <code>z</code> in the expression <code>x + 10 * y + 100 * z</code> above are in fact <code>ndarrays</code> (we will discuss arithmetic operations on arrays below). The point is that the function <code>my_function</code> is only called once, instead of once per element. This makes initialization very efficient.</p>"},{"location":"Tutorials/Libraries/numpy/#array-data","title":"Array data","text":""},{"location":"Tutorials/Libraries/numpy/#dtyp","title":"dtyp","text":"<p>NumPy's <code>ndarrays</code> are also efficient in part because all their elements must have the same type (usually numbers). You can check what the data type is by looking at the <code>dtype</code> attribute:</p> <pre><code>c = np.arange(1, 5)\nprint(c.dtype, c)\n</code></pre> Output <p>int64 [1 2 3 4]</p> <pre><code>c = np.arange(1.0, 5.0)\nprint(c.dtype, c)\n</code></pre> Output <p>float64 [ 1.  2.  3.  4.]</p> <p>Instead of letting NumPy guess what data type to use, you can set it explicitly when creating an array by setting the <code>dtype</code> parameter:</p> Output <p>complex64 [ 1.+0.j  2.+0.j  3.+0.j  4.+0.j]</p> <p>Available data types include <code>int8</code>, <code>int16</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>|<code>16</code>|<code>32</code>|<code>64</code>, <code>float16</code>|<code>32</code>|<code>64</code> and <code>complex64</code>|<code>128</code>. Check out the documentation for the full list.</p>"},{"location":"Tutorials/Libraries/numpy/#itemsize","title":"itemsize","text":"<p>The <code>itemsize</code> attribute returns the size (in bytes) of each item:</p> <pre><code>e = np.arange(1, 5, dtype=np.complex64)\ne.itemsize\n</code></pre> Output <p>8</p>"},{"location":"Tutorials/Libraries/numpy/#data-buffe","title":"data buffe","text":"<p>An array's data is actually stored in memory as a flat (one dimensional) byte buffer. It is available via the <code>data</code> attribute (you will rarely need it, though).</p> <pre><code>f = np.array([[1,2],[1000, 2000]], dtype=np.int32)\nf.data\n</code></pre> Output <p> <p>In python 2, <code>f.data</code> is a buffer. In python 3, it is a memoryview.</p> <pre><code>if (hasattr(f.data, \"tobytes\")):\n    data_bytes = f.data.tobytes() # python 3\nelse:\n    data_bytes = memoryview(f.data).tobytes() # python 2\n\ndata_bytes\n</code></pre> Output <p>'\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\xe8\\x03\\x00\\x00\\xd0\\x07\\x00\\x00'</p> <p>Several <code>ndarrays</code> can share the same data buffer, meaning that modifying one will also modify the others. We will see an example in a minute.</p>"},{"location":"Tutorials/Libraries/numpy/#reshaping-an-array","title":"Reshaping an array","text":""},{"location":"Tutorials/Libraries/numpy/#in-place","title":"In place","text":"<p>Changing the shape of an <code>ndarray</code> is as simple as setting its <code>shape</code> attribute. However, the array's size must remain the same.</p> <pre><code>g = np.arange(24)\nprint(g)\nprint(\"Rank:\", g.ndim)\n</code></pre> Output <p>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23] Rank: 1</p> <pre><code>g.shape = (6, 4)\nprint(g)\nprint(\"Rank:\", g.ndim)\n</code></pre> Output <p>[[ 0  1  2  3]  [ 4  5  6  7]  [ 8  9 10 11]  [12 13 14 15]  [16 17 18 19]  [20 21 22 23]] Rank: 2</p> <pre><code>g.shape = (2, 3, 4)\nprint(g)\nprint(\"Rank:\", g.ndim)\n</code></pre> Output <p>[[[ 0  1  2  3]   [ 4  5  6  7]   [ 8  9 10 11]]</p> <p>[[12 13 14 15]   [16 17 18 19]   [20 21 22 23]]] Rank: 3</p>"},{"location":"Tutorials/Libraries/numpy/#reshape","title":"reshape","text":"<p>The <code>reshape</code> function returns a new <code>ndarray</code> object pointing at the same data. This means that modifying one array will also modify the other.</p> <pre><code>g2 = g.reshape(4,6)\nprint(g2)\nprint(\"Rank:\", g2.ndim)\n</code></pre> Output <p>[[ 0  1  2  3  4  5]  [ 6  7  8  9 10 11]  [12 13 14 15 16 17]  [18 19 20 21 22 23]] Rank: 2</p> <p>Set item at row 1, col 2 to 999 (more about indexing below).</p> <pre><code>g2[1, 2] = 999\ng2\n</code></pre> Output <p>array([[  0,   1,   2,   3,   4,   5],        [  6,   7, 999,   9,  10,  11],        [ 12,  13,  14,  15,  16,  17],        [ 18,  19,  20,  21,  22,  23]])</p> <p>The corresponding element in <code>g</code> has been modified.</p> Output <p>array([[[  0,   1,   2,   3],         [  4,   5,   6,   7],         [999,   9,  10,  11]],</p> <pre><code>   [[ 12,  13,  14,  15],\n    [ 16,  17,  18,  19],\n    [ 20,  21,  22,  23]]])\n</code></pre>"},{"location":"Tutorials/Libraries/numpy/#ravel","title":"ravel","text":"<p>Finally, the <code>ravel</code> function returns a new one-dimensional <code>ndarray</code> that also points to the same data:</p> <pre><code>g.ravel()\n</code></pre> Output <p>array([  0,   1,   2,   3,   4,   5,   6,   7, 999,   9,  10,  11,  12,         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23])</p>"},{"location":"Tutorials/Libraries/numpy/#arithmetic-operations","title":"Arithmetic operations","text":"<p>All the usual arithmetic operators (<code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>, <code>//</code>, <code>**</code>, etc.) can be used with <code>ndarray</code>s. They apply elementwise:</p> <pre><code>a = np.array([14, 23, 32, 41])\nb = np.array([5,  4,  3,  2])\nprint(\"a + b  =\", a + b)\nprint(\"a - b  =\", a - b)\nprint(\"a * b  =\", a * b)\nprint(\"a / b  =\", a / b)\nprint(\"a // b  =\", a // b)\nprint(\"a % b  =\", a % b)\nprint(\"a ** b =\", a ** b)\n</code></pre> Output <p>a + b  = [19 27 35 43] a - b  = [ 9 19 29 39] a * b  = [70 92 96 82] a / b  = [  2.8          5.75        10.66666667  20.5       ] a // b  = [ 2  5 10 20] a % b  = [4 3 2 1] a ** b = [537824 279841  32768   1681]</p> <p>Note that the multiplication is not a matrix multiplication. We will discuss matrix operations below.</p> <p>The arrays must have the same shape. If they do not, NumPy will apply the broadcasting rules.</p>"},{"location":"Tutorials/Libraries/numpy/#broadcasting","title":"Broadcasting","text":"<p>In general, when NumPy expects arrays of the same shape but finds that this is not the case, it applies the so-called broadcasting rules:</p>"},{"location":"Tutorials/Libraries/numpy/#first-rule","title":"First rule","text":"<p>If the arrays do not have the same rank, then a 1 will be prepended to the smaller ranking arrays until their ranks match.</p> <pre><code>h = np.arange(5).reshape(1, 1, 5)\nh\n</code></pre> Output <p>array([[[0, 1, 2, 3, 4]]])</p> <p>Now let's try to add a 1D array of shape <code>(5,)</code> to this 3D array of shape <code>(1,1,5)</code>. Applying the first rule of broadcasting!</p> <pre><code>h + [10, 20, 30, 40, 50]  # same as: h + [[[10, 20, 30, 40, 50]]]\n</code></pre> Output <p>array([[[10, 21, 32, 43, 54]]])</p>"},{"location":"Tutorials/Libraries/numpy/#second-rule","title":"Second rule","text":"<p>Arrays with a 1 along a particular dimension act as if they had the size of the array with the largest shape along that dimension. The value of the array element is repeated along that dimension.</p> <pre><code>k = np.arange(6).reshape(2, 3)\nk\n</code></pre> Output <p>array([[0, 1, 2],        [3, 4, 5]])</p> <p>Let's try to add a 2D array of shape <code>(2,1)</code> to this 2D <code>ndarray</code> of shape <code>(2, 3)</code>. NumPy will apply the second rule of broadcasting:</p> <pre><code>k + [[100], [200]]  # same as: k + [[100, 100, 100], [200, 200, 200]]\n</code></pre> Output <p>array([[100, 101, 102],        [203, 204, 205]])</p> <p>Combining rules 1 &amp; 2, we can do this:</p> <pre><code>k + [100, 200, 300]  # after rule 1: [[100, 200, 300]], and after rule 2: [[100, 200, 300], [100, 200, 300]]\n</code></pre> Output <p>array([[100, 201, 302],        [103, 204, 305]])</p> <p>And also, very simply:</p> <pre><code>k + 1000  # same as: k + [[1000, 1000, 1000], [1000, 1000, 1000]]\n</code></pre> Output <p>array([[1000, 1001, 1002],        [1003, 1004, 1005]])</p>"},{"location":"Tutorials/Libraries/numpy/#third-rule","title":"Third rule","text":"<p>After rules 1 &amp; 2, the sizes of all arrays must match.</p> <pre><code>try:\n    k + [33, 44]\nexcept ValueError as e:\n    print(e)\n</code></pre> Output <p>operands could not be broadcast together with shapes (2,3) (2,) </p> <p>Broadcasting rules are used in many NumPy operations, not just arithmetic operations, as we will see below. For more details about broadcasting, check out the documentation.</p>"},{"location":"Tutorials/Libraries/numpy/#upcasting","title":"Upcasting","text":"<p>When trying to combine arrays with different <code>dtype</code>s, NumPy will upcast to a type capable of handling all possible values (regardless of what the actual values are).</p> <pre><code>k1 = np.arange(0, 5, dtype=np.uint8)\nprint(k1.dtype, k1)\n</code></pre> Output <p>uint8 [0 1 2 3 4]</p> <pre><code>k2 = k1 + np.array([5, 6, 7, 8, 9], dtype=np.int8)\nprint(k2.dtype, k2)\n</code></pre> Output <p>int16 [ 5  7  9 11 13]</p> <p>Note that <code>int16</code> is required to represent all possible <code>int8</code> and <code>uint8</code> values (from -128 to 255), even though in this case a uint8 would have sufficed.</p> <pre><code>k3 = k1 + 1.5\nprint(k3.dtype, k3)\n</code></pre> Output <p>float64 [ 1.5  2.5  3.5  4.5  5.5]</p>"},{"location":"Tutorials/Libraries/numpy/#conditional-operators","title":"Conditional operators","text":"<p>The conditional operators also apply elementwise:</p> <pre><code>m = np.array([20, -5, 30, 40])\nm &lt; [15, 16, 35, 36]\n</code></pre> Output <p>array([False,  True,  True, False], dtype=bool)</p> <p>And using broadcasting:</p> <pre><code>m &lt; 25  # equivalent to m &lt; [25, 25, 25, 25]\n</code></pre> Output <p>array([ True,  True, False, False], dtype=bool)</p> <p>This is most useful in conjunction with boolean indexing (discussed below).</p> <pre><code>m[m &lt; 25]\n</code></pre> Output <p>array([20, -5])</p>"},{"location":"Tutorials/Libraries/numpy/#mathematical-and-statistical-functions","title":"Mathematical and statistical functions","text":"<p>Many mathematical and statistical functions are available for <code>ndarray</code>s.</p>"},{"location":"Tutorials/Libraries/numpy/#ndarray-methods","title":"ndarray methods","text":"<p>Some functions are simply <code>ndarray</code> methods, for example:</p> <pre><code>a = np.array([[-2.5, 3.1, 7], [10, 11, 12]])\nprint(a)\nprint(\"mean =\", a.mean())\n</code></pre> Output <p>[[ -2.5   3.1   7. ]  [ 10.   11.   12. ]] mean = 6.76666666667</p> <p>Note that this computes the mean of all elements in the <code>ndarray</code>, regardless of its shape.</p> <p>Here are a few more useful <code>ndarray</code> methods:</p> <pre><code>for func in (a.min, a.max, a.sum, a.prod, a.std, a.var):\n    print(func.__name__, \"=\", func())\n</code></pre> Output <p>min = -2.5 max = 12.0 sum = 40.6 prod = -71610.0 std = 5.08483584352 var = 25.8555555556</p> <p>These functions accept an optional argument <code>axis</code> which lets you ask for the operation to be performed on elements along the given axis. For example:</p> <pre><code>c=np.arange(24).reshape(2,3,4)\nc\n</code></pre> Output <p>array([[[ 0,  1,  2,  3],         [ 4,  5,  6,  7],         [ 8,  9, 10, 11]],</p> <pre><code>   [[12, 13, 14, 15],\n    [16, 17, 18, 19],\n    [20, 21, 22, 23]]])\n</code></pre> <pre><code>c.sum(axis=0)  # sum across matrices\n</code></pre> Output <p>array([[12, 14, 16, 18],        [20, 22, 24, 26],        [28, 30, 32, 34]])</p> <pre><code>c.sum(axis=1)  # sum across rows\n</code></pre> Output <p>array([[12, 15, 18, 21],        [48, 51, 54, 57]])</p> <p>You can also sum over multiple axes:</p> <pre><code>c.sum(axis=(0,2))  # sum across matrices and columns\n</code></pre> Output <p>array([ 60,  92, 124])</p> <pre><code>0+1+2+3 + 12+13+14+15, 4+5+6+7 + 16+17+18+19, 8+9+10+11 + 20+21+22+23\n</code></pre> Output <p>(60, 92, 124)</p>"},{"location":"Tutorials/Libraries/numpy/#universal-functions","title":"Universal functions","text":"<p>NumPy also provides fast elementwise functions called universal functions, or ufunc. They are vectorized wrappers of simple functions. For example <code>square</code> returns a new <code>ndarray</code> which is a copy of the original <code>ndarray</code> except that each element is squared:</p> <pre><code>a = np.array([[-2.5, 3.1, 7], [10, 11, 12]])\nnp.square(a)\n</code></pre> Output <p>array([[   6.25,    9.61,   49.  ],        [ 100.  ,  121.  ,  144.  ]])</p> <p>Here are a few more useful unary ufuncs:</p> <pre><code>print(\"Original ndarray\")\nprint(a)\nfor func in (np.abs, np.sqrt, np.exp, np.log, np.sign, np.ceil, np.modf, np.isnan, np.cos):\n    print(\"\\n\", func.__name__)\n    print(func(a))\n</code></pre> Output <p>Original ndarray [[ -2.5   3.1   7. ]  [ 10.   11.   12. ]]</p> <p>absolute [[  2.5   3.1   7. ]  [ 10.   11.   12. ]]</p> <p>sqrt [[        nan  1.76068169  2.64575131]  [ 3.16227766  3.31662479  3.46410162]]</p> <p>exp [[  8.20849986e-02   2.21979513e+01   1.09663316e+03]  [  2.20264658e+04   5.98741417e+04   1.62754791e+05]]</p> <p>log [[        nan  1.13140211  1.94591015]  [ 2.30258509  2.39789527  2.48490665]]</p> <p>sign [[-1.  1.  1.]  [ 1.  1.  1.]]</p> <p>ceil [[ -2.   4.   7.]  [ 10.  11.  12.]]</p> <p>modf (array([[-0.5,  0.1,  0. ],        [ 0. ,  0. ,  0. ]]), array([[ -2.,   3.,   7.],        [ 10.,  11.,  12.]]))</p> <p>isnan [[False False False]  [False False False]]</p> <p>cos [[-0.80114362 -0.99913515  0.75390225]  [-0.83907153  0.0044257   0.84385396]] -c:5: RuntimeWarning: invalid value encountered in sqrt -c:5: RuntimeWarning: invalid value encountered in log</p>"},{"location":"Tutorials/Libraries/numpy/#binary-ufuncs","title":"Binary ufuncs","text":"<p>There are also many binary ufuncs, that apply elementwise on two <code>ndarray</code>s. Broadcasting rules are applied if the arrays do not have the same shape:</p> <pre><code>a = np.array([1, -2, 3, 4])\nb = np.array([2, 8, -1, 7])\nnp.add(a, b)  # equivalent to a + b\n</code></pre> Output <p>array([ 3,  6,  2, 11])</p> <pre><code>np.greater(a, b)  # equivalent to a &gt; b\n</code></pre> Output <p>array([False, False,  True, False], dtype=bool)</p> <pre><code>np.maximum(a, b)\n</code></pre> Output <p>array([2, 8, 3, 7])</p> <pre><code>np.copysign(a, b)\n</code></pre> Output <p>array([ 1.,  2., -3.,  4.])</p>"},{"location":"Tutorials/Libraries/numpy/#array-indexing","title":"Array indexing","text":""},{"location":"Tutorials/Libraries/numpy/#one-dimensional-arrays","title":"One-dimensional arrays","text":"<p>One-dimensional NumPy arrays can be accessed more or less like regular python arrays:</p> <pre><code>a = np.array([1, 5, 3, 19, 13, 7, 3])\na[3]\n</code></pre> Output <p>19</p> <pre><code>a[2:5]\n</code></pre> Output <p>array([ 3, 19, 13])</p> <pre><code>a[2:-1]\n</code></pre> Output <p>array([ 3, 19, 13,  7])</p> <pre><code>a[:2]\n</code></pre> Output <p>array([1, 5])</p> <pre><code>a[2::2]\n</code></pre> Output <p>array([ 3, 13,  3])</p> <pre><code>a[::-1]\n</code></pre> Output <p>array([ 3,  7, 13, 19,  3,  5,  1])</p> <p>Of course, you can modify elements:</p> <pre><code>a[3]=999\na\n</code></pre> Output <p>array([  1,   5,   3, 999,  13,   7,   3])</p> <p>You can also modify an <code>ndarray</code> slice:</p> <pre><code>a[2:5] = [997, 998, 999]\na\n</code></pre> Output <p>array([  1,   5, 997, 998, 999,   7,   3])</p>"},{"location":"Tutorials/Libraries/numpy/#differences-with-regular-python-arrays","title":"Differences with regular python arrays","text":"<p>Contrary to regular python arrays, if you assign a single value to an <code>ndarray</code> slice, it is copied across the whole slice, thanks to broadcasting rules discussed above.</p> <pre><code>a[2:5] = -1\na\n</code></pre> Output <p>array([ 1,  5, -1, -1, -1,  7,  3])</p> <p>Also, you cannot grow or shrink <code>ndarrays</code> this way:</p> <pre><code>try:\n    a[2:5] = [1,2,3,4,5,6]  # too long\nexcept ValueError as e:\n    print(e)\n</code></pre> Output <p>cannot copy sequence with size 6 to array axis with dimension 3</p> <p>You cannot delete elements either:</p> <pre><code>try:\n    del a[2:5]\nexcept ValueError as e:\n    print(e)\n</code></pre> Output <p>cannot delete array elements</p> <p>Last but not least, <code>ndarray</code> slices are actually views on the same data buffer. This means that if you create a slice and modify it, you are actually going to modify the original <code>ndarray</code> as well!</p> <pre><code>a_slice = a[2:6]\na_slice[1] = 1000\na  # the original array was modified!\n</code></pre> Output <p>array([   1,    5,   -1, 1000,   -1,    7,    3])</p> <pre><code>a[3] = 2000\na_slice  # similarly, modifying the original array modifies the slice!\n</code></pre> Output <p>array([  -1, 2000,   -1,    7])</p> <p>If you want a copy of the data, you need to use the <code>copy</code> method:</p> <pre><code>another_slice = a[2:6].copy()\nanother_slice[1] = 3000\na  # the original array is untouched\n</code></pre> Output <p>array([   1,    5,   -1, 2000,   -1,    7,    3])</p> <pre><code>a[3] = 4000\nanother_slice  # similary, modifying the original array does not affect the slice copy\n</code></pre> Output <p>array([  -1, 3000,   -1,    7])</p>"},{"location":"Tutorials/Libraries/numpy/#multi-dimensional-arrays","title":"Multi-dimensional arrays","text":"<p>Multi-dimensional arrays can be accessed in a similar way by providing an index or slice for each axis, separated by commas:</p> <pre><code>b = np.arange(48).reshape(4, 12)\nb\n</code></pre> Output <p>array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11],        [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23],        [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35],        [36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]])</p> <pre><code>b[1, 2]  # row 1, col 2\n</code></pre> Output <p>14</p> <pre><code>b[1, :]  # row 1, all columns\n</code></pre> Output <p>array([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23])</p> <pre><code>b[:, 1]  # all rows, column 1\n</code></pre> Output <p>array([ 1, 13, 25, 37])</p> <p>Caution</p> <p>note the subtle difference between these two expressions:</p> <pre><code>b[1, :]\n</code></pre> Output <p>array([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23])</p> <pre><code>b[1:2, :]\n</code></pre> Output <p>array([[12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]])</p> <p>The first expression returns row 1 as a 1D array of shape <code>(12,)</code>, while the second returns that same row as a 2D array of shape <code>(1, 12)</code>.</p>"},{"location":"Tutorials/Libraries/numpy/#fancy-indexing","title":"Fancy indexing","text":"<p>You may also specify a list of indices that you are interested in. This is referred to as fancy indexing.</p> <pre><code>b[(0,2), 2:5]  # rows 0 and 2, columns 2 to 4 (5-1)\n</code></pre> Output <p>array([[ 2,  3,  4],        [26, 27, 28]])</p> <pre><code>b[:, (-1, 2, -1)]  # all rows, columns -1 (last), 2 and -1 (again, and in this order)\n</code></pre> Output <p>array([[11,  2, 11],        [23, 14, 23],        [35, 26, 35],        [47, 38, 47]])</p> <p>If you provide multiple index arrays, you get a 1D <code>ndarray</code> containing the values of the elements at the specified coordinates.</p> <pre><code>b[(-1, 2, -1, 2), (5, 9, 1, 9)]  # returns a 1D array with b[-1, 5], b[2, 9], b[-1, 1] and b[2, 9] (again)\n</code></pre> Output <p>array([41, 33, 37, 33])</p>"},{"location":"Tutorials/Libraries/numpy/#higher-dimensions","title":"Higher dimensions","text":"<p>Everything works just as well with higher dimensional arrays, but it's useful to look at a few examples:</p> <pre><code>c = b.reshape(4,2,6)\nc\n</code></pre> Output <p>array([[[ 0,  1,  2,  3,  4,  5],         [ 6,  7,  8,  9, 10, 11]],</p> <pre><code>   [[12, 13, 14, 15, 16, 17],\n    [18, 19, 20, 21, 22, 23]],\n\n   [[24, 25, 26, 27, 28, 29],\n    [30, 31, 32, 33, 34, 35]],\n\n   [[36, 37, 38, 39, 40, 41],\n    [42, 43, 44, 45, 46, 47]]])\n</code></pre> <pre><code>c[2, 1, 4]  # matrix 2, row 1, col 4\n</code></pre> Output <p>34</p> <pre><code>c[2, :, 3]  # matrix 2, all rows, col 3\n</code></pre> Output <p>array([27, 33])</p> <p>If you omit coordinates for some axes, then all elements in these axes are returned:</p> <pre><code>c[2, 1]  # Return matrix 2, row 1, all columns.  This is equivalent to c[2, 1, :]\n</code></pre> Output <p>array([30, 31, 32, 33, 34, 35])</p>"},{"location":"Tutorials/Libraries/numpy/#ellipsis","title":"Ellipsis (...)","text":"<p>You may also write an ellipsis (<code>...</code>) to ask that all non-specified axes be entirely included.</p> <pre><code>c[2, ...]  #  matrix 2, all rows, all columns.  This is equivalent to c[2, :, :]\n</code></pre> Output <p>array([[24, 25, 26, 27, 28, 29],        [30, 31, 32, 33, 34, 35]])</p> <pre><code>c[2, 1, ...]  # matrix 2, row 1, all columns.  This is equivalent to c[2, 1, :]\n</code></pre> Output <p>array([30, 31, 32, 33, 34, 35])</p> <pre><code>c[2, ..., 3]  # matrix 2, all rows, column 3.  This is equivalent to c[2, :, 3]\n</code></pre> Output <p>array([27, 33])</p> <pre><code>c[..., 3]  # all matrices, all rows, column 3.  This is equivalent to c[:, :, 3]\n</code></pre> Output <p>array([[ 3,  9],        [15, 21],        [27, 33],        [39, 45]])</p>"},{"location":"Tutorials/Libraries/numpy/#boolean-indexing","title":"Boolean indexing","text":"<p>You can also provide an <code>ndarray</code> of boolean values on one axis to specify the indices that you want to access.</p> <pre><code>b = np.arange(48).reshape(4, 12)\nb\n</code></pre> Output <p>array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11],        [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23],        [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35],        [36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]])</p> <pre><code>rows_on = np.array([True, False, True, False])\nb[rows_on, :]  # Rows 0 and 2, all columns. Equivalent to b[(0, 2), :]\n</code></pre> Output <p>array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11],        [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]])</p> <pre><code>cols_on = np.array([False, True, False] * 4)\nb[:, cols_on]  # All rows, columns 1, 4, 7 and 10\n</code></pre> Output <p>array([[ 1,  4,  7, 10],        [13, 16, 19, 22],        [25, 28, 31, 34],        [37, 40, 43, 46]])</p>"},{"location":"Tutorials/Libraries/numpy/#npix_","title":"np.ix_","text":"<p>You cannot use boolean indexing this way on multiple axes, but you can work around this by using the <code>ix_</code> function:</p> <pre><code>b[np.ix_(rows_on, cols_on)]\n</code></pre> Output <p>array([[ 1,  4,  7, 10],        [25, 28, 31, 34]])</p> <pre><code>np.ix_(rows_on, cols_on)\n</code></pre> Output <p>(array([[0],         [2]]), array([[ 1,  4,  7, 10]]))</p> <p>If you use a boolean array that has the same shape as the <code>ndarray</code>, then you get in return a 1D array containing all the values that have <code>True</code> at their coordinate. This is generally used along with conditional operators:</p> <pre><code>b[b % 3 == 1]\n</code></pre> Output <p>array([ 1,  4,  7, 10, 13, 16, 19, 22, 25, 28, 31, 34, 37, 40, 43, 46])</p>"},{"location":"Tutorials/Libraries/numpy/#iterating","title":"Iterating","text":"<p>Iterating over <code>ndarrays</code> is very similar to iterating over regular python arrays. Note that iterating over multidimensional arrays is done with respect to the first axis.</p> <pre><code>c = np.arange(24).reshape(2, 3, 4)  # A 3D array (composed of two 3x4 matrices)\nc\n</code></pre> Output <p>array([[[ 0,  1,  2,  3],         [ 4,  5,  6,  7],         [ 8,  9, 10, 11]],</p> <pre><code>   [[12, 13, 14, 15],\n    [16, 17, 18, 19],\n    [20, 21, 22, 23]]])\n</code></pre> <pre><code>for m in c:\n    print(\"Item:\")\n    print(m)\n</code></pre> Output <p>Item: [[ 0  1  2  3]  [ 4  5  6  7]  [ 8  9 10 11]] Item: [[12 13 14 15]  [16 17 18 19]  [20 21 22 23]]</p> <pre><code>for i in range(len(c)):  # Note that len(c) == c.shape[0]\n    print(\"Item:\")\n    print(c[i])\n</code></pre> Output <p>Item: [[ 0  1  2  3]  [ 4  5  6  7]  [ 8  9 10 11]] Item: [[12 13 14 15]  [16 17 18 19]  [20 21 22 23]]</p> <p>If you want to iterate on all elements in the <code>ndarray</code>, simply iterate over the <code>flat</code> attribute:</p> <pre><code>for i in c.flat:\n    print(\"Item:\", i)\n</code></pre> Output <p>Item: 0 Item: 1 Item: 2 Item: 3 Item: 4 Item: 5 Item: 6 Item: 7 Item: 8 Item: 9 Item: 10 Item: 11 Item: 12 Item: 13 Item: 14 Item: 15 Item: 16 Item: 17 Item: 18 Item: 19 Item: 20 Item: 21 Item: 22 Item: 23</p>"},{"location":"Tutorials/Libraries/numpy/#stacking-arrays","title":"Stacking arrays","text":"<p>It is often useful to stack together different arrays. NumPy offers several functions to do just that. Let's start by creating a few arrays.</p> <pre><code>q1 = np.full((3,4), 1.0)\nq1\n</code></pre> Output <p>array([[ 1.,  1.,  1.,  1.],        [ 1.,  1.,  1.,  1.],        [ 1.,  1.,  1.,  1.]])</p> <pre><code>q2 = np.full((4,4), 2.0)\nq2\n</code></pre> Output <p>array([[ 2.,  2.,  2.,  2.],        [ 2.,  2.,  2.,  2.],        [ 2.,  2.,  2.,  2.],        [ 2.,  2.,  2.,  2.]])</p> <pre><code>q3 = np.full((3,4), 3.0)\nq3\n</code></pre> Output <p>array([[ 3.,  3.,  3.,  3.],        [ 3.,  3.,  3.,  3.],        [ 3.,  3.,  3.,  3.]])</p>"},{"location":"Tutorials/Libraries/numpy/#vstack","title":"vstack","text":"<p>Now let's stack them vertically using <code>vstack</code>:</p> <pre><code>q4 = np.vstack((q1, q2, q3))\nq4\n</code></pre> Output <p>array([[ 1.,  1.,  1.,  1.],        [ 1.,  1.,  1.,  1.],        [ 1.,  1.,  1.,  1.],        [ 2.,  2.,  2.,  2.],        [ 2.,  2.,  2.,  2.],        [ 2.,  2.,  2.,  2.],        [ 2.,  2.,  2.,  2.],        [ 3.,  3.,  3.,  3.],        [ 3.,  3.,  3.,  3.],        [ 3.,  3.,  3.,  3.]])</p> <pre><code>q4.shape\n</code></pre> Output <p>(10, 4)</p> <p>This was possible because q1, q2 and q3 all have the same shape (except for the vertical axis, but that's ok since we are stacking on that axis).</p>"},{"location":"Tutorials/Libraries/numpy/#hstack","title":"hstack","text":"<p>We can also stack arrays horizontally using <code>hstack</code>:</p> <pre><code>q5 = np.hstack((q1, q3))\nq5\n</code></pre> Output <p>array([[ 1.,  1.,  1.,  1.,  3.,  3.,  3.,  3.],        [ 1.,  1.,  1.,  1.,  3.,  3.,  3.,  3.],        [ 1.,  1.,  1.,  1.,  3.,  3.,  3.,  3.]])</p> <pre><code>q5.shape\n</code></pre> Output <p>(3, 8)</p> <p>This is possible because q1 and q3 both have 3 rows. But since q2 has 4 rows, it cannot be stacked horizontally with q1 and q3:</p> <pre><code>try:\n    q5 = np.hstack((q1, q2, q3))\nexcept ValueError as e:\n    print(e)\n</code></pre> Output <p>all the input array dimensions except for the concatenation axis must match exactly</p>"},{"location":"Tutorials/Libraries/numpy/#concatenate","title":"concatenate","text":"<p>The <code>concatenate</code> function stacks arrays along any given existing axis.</p> <pre><code>q7 = np.concatenate((q1, q2, q3), axis=0)  # Equivalent to vstack\nq7\n</code></pre> Output <p>array([[ 1.,  1.,  1.,  1.],        [ 1.,  1.,  1.,  1.],        [ 1.,  1.,  1.,  1.],        [ 2.,  2.,  2.,  2.],        [ 2.,  2.,  2.,  2.],        [ 2.,  2.,  2.,  2.],        [ 2.,  2.,  2.,  2.],        [ 3.,  3.,  3.,  3.],        [ 3.,  3.,  3.,  3.],        [ 3.,  3.,  3.,  3.]])</p> <pre><code>q7.shape\n</code></pre> Output <p>(10, 4)</p> <p>As you might guess, <code>hstack</code> is equivalent to calling <code>concatenate</code> with <code>axis=1</code>.</p>"},{"location":"Tutorials/Libraries/numpy/#stack","title":"stack","text":"<p>The <code>stack</code> function stacks arrays along a new axis. All arrays have to have the same shape.</p> <pre><code>q8 = np.stack((q1, q3))\nq8\n</code></pre> Output <p>array([[[ 1.,  1.,  1.,  1.],         [ 1.,  1.,  1.,  1.],         [ 1.,  1.,  1.,  1.]],</p> <pre><code>   [[ 3.,  3.,  3.,  3.],\n    [ 3.,  3.,  3.,  3.],\n    [ 3.,  3.,  3.,  3.]]])\n</code></pre> <pre><code>q8.shape\n</code></pre> Output <p>(2, 3, 4)</p>"},{"location":"Tutorials/Libraries/numpy/#splitting-arrays","title":"Splitting arrays","text":"<p>Splitting is the opposite of stacking. For example, let's use the <code>vsplit</code> function to split a matrix vertically.</p> <p>First let's create a 6x4 matrix:</p> <pre><code>r = np.arange(24).reshape(6,4)\nr\n</code></pre> Output <p>array([[ 0,  1,  2,  3],        [ 4,  5,  6,  7],        [ 8,  9, 10, 11],        [12, 13, 14, 15],        [16, 17, 18, 19],        [20, 21, 22, 23]])</p> <p>Now let's split it in three equal parts, vertically:</p> <pre><code>r1, r2, r3 = np.vsplit(r, 3)\nr1\n</code></pre> Output <p>array([[0, 1, 2, 3],        [4, 5, 6, 7]])</p> <pre><code>r2\n</code></pre> Output <p>array([[ 8,  9, 10, 11],        [12, 13, 14, 15]])</p> <pre><code>r3\n</code></pre> Output <p>array([[16, 17, 18, 19],        [20, 21, 22, 23]])</p> <p>There is also a <code>split</code> function which splits an array along any given axis. Calling <code>vsplit</code> is equivalent to calling <code>split</code> with <code>axis=0</code>. There is also an <code>hsplit</code> function, equivalent to calling <code>split</code> with <code>axis=1</code>:</p> <pre><code>r4, r5 = np.hsplit(r, 2)\nr4\n</code></pre> Output <p>array([[ 0,  1],        [ 4,  5],        [ 8,  9],        [12, 13],        [16, 17],        [20, 21]])</p> <pre><code>r5\n</code></pre> Output <p>array([[ 2,  3],        [ 6,  7],        [10, 11],        [14, 15],        [18, 19],        [22, 23]])</p>"},{"location":"Tutorials/Libraries/numpy/#transposing-arrays","title":"Transposing arrays","text":"<p>The <code>transpose</code> method creates a new view on an <code>ndarray</code>'s data, with axes permuted in the given order.</p> <p>For example, let's create a 3D array:</p> <pre><code>t = np.arange(24).reshape(4,2,3)\nt\n</code></pre> Output <p>array([[[ 0,  1,  2],         [ 3,  4,  5]],</p> <pre><code>   [[ 6,  7,  8],\n    [ 9, 10, 11]],\n\n   [[12, 13, 14],\n    [15, 16, 17]],\n\n   [[18, 19, 20],\n    [21, 22, 23]]])\n</code></pre> <p>Now let's create an <code>ndarray</code> such that the axes <code>0, 1, 2</code> (depth, height, width) are re-ordered to <code>1, 2, 0</code> (depth\u2192width, height\u2192depth, width\u2192height):</p> <pre><code>t1 = t.transpose((1,2,0))\nt1\n</code></pre> Output <p>array([[[ 0,  6, 12, 18],         [ 1,  7, 13, 19],         [ 2,  8, 14, 20]],</p> <pre><code>   [[ 3,  9, 15, 21],\n    [ 4, 10, 16, 22],\n    [ 5, 11, 17, 23]]])\n</code></pre> <pre><code>t1.shape\n</code></pre> Output <p>(2, 3, 4)</p> <p>By default, <code>transpose</code> reverses the order of the dimensions:</p> <pre><code>t2 = t.transpose()  # equivalent to t.transpose((2, 1, 0))\nt2\n</code></pre> Output <p>array([[[ 0,  6, 12, 18],         [ 3,  9, 15, 21]],</p> <pre><code>   [[ 1,  7, 13, 19],\n    [ 4, 10, 16, 22]],\n\n   [[ 2,  8, 14, 20],\n    [ 5, 11, 17, 23]]])\n</code></pre> <pre><code>t2.shape\n</code></pre> Output <p>(3, 2, 4)</p> <p>NumPy provides a convenience function <code>swapaxes</code> to swap two axes. For example, let's create a new view of <code>t</code> with depth and height swapped:</p> <pre><code>t3 = t.swapaxes(0,1)  # equivalent to t.transpose((1, 0, 2))\nt3\n</code></pre> Output <p>array([[[ 0,  1,  2],         [ 6,  7,  8],         [12, 13, 14],         [18, 19, 20]],</p> <pre><code>   [[ 3,  4,  5],\n    [ 9, 10, 11],\n    [15, 16, 17],\n    [21, 22, 23]]])\n</code></pre> <pre><code>t3.shape\n</code></pre> Output <p>(2, 4, 3)</p>"},{"location":"Tutorials/Libraries/numpy/#linear-algebra","title":"Linear algebra","text":"<p>NumPy 2D arrays can be used to represent matrices efficiently in python. We will just quickly go through some of the main matrix operations available. For more details about Linear Algebra, vectors and matrics, go through the Linear Algebra tutorial.</p>"},{"location":"Tutorials/Libraries/numpy/#matrix-transpose","title":"Matrix transpose","text":"<p>The <code>T</code> attribute is equivalent to calling <code>transpose()</code> when the rank is \u22652:</p> <pre><code>m1 = np.arange(10).reshape(2,5)\nm1\n</code></pre> Output <p>array([[0, 1, 2, 3, 4],        [5, 6, 7, 8, 9]])</p> <pre><code>m1.T\n</code></pre> Output <p>array([[0, 5],        [1, 6],        [2, 7],        [3, 8],        [4, 9]])</p> <p>The <code>T</code> attribute has no effect on rank 0 (empty) or rank 1 arrays:</p> <pre><code>m2 = np.arange(5)\nm2\n</code></pre> Output <p>array([0, 1, 2, 3, 4])</p> <pre><code>m2.T\n</code></pre> Output <p>array([0, 1, 2, 3, 4])</p> <p>We can get the desired transposition by first reshaping the 1D array to a single-row matrix (2D):</p> <pre><code>m2r = m2.reshape(1,5)\nm2r\n</code></pre> Output <p>array([[0, 1, 2, 3, 4]])</p> <pre><code>m2r.T\n</code></pre> Output <p>array([[0],       [1],       [2],       [3],       [4]])</p>"},{"location":"Tutorials/Libraries/numpy/#matrix-multiplication","title":"Matrix multiplication","text":"<p>Let's create two matrices and execute a matrix multiplication using the <code>dot()</code> method.</p> <pre><code>n1 = np.arange(10).reshape(2, 5)\nn1\n</code></pre> Output <p>array([[0, 1, 2, 3, 4],        [5, 6, 7, 8, 9]])</p> <pre><code>n2 = np.arange(15).reshape(5,3)\nn2\n</code></pre> Output <p>array([[ 0,  1,  2],        [ 3,  4,  5],        [ 6,  7,  8],        [ 9, 10, 11],        [12, 13, 14]])</p> <pre><code>n1.dot(n2)\n</code></pre> Output <p>array([[ 90, 100, 110],        [240, 275, 310]])</p> <p>Caution</p> <p>As mentionned previously, <code>n1*n2</code> is not a matric multiplication, it is an elementwise product (also called a Hadamard product).</p>"},{"location":"Tutorials/Libraries/numpy/#matrix-inverse-and-pseudo-inverse","title":"Matrix inverse and pseudo-inverse","text":"<p>Many of the linear algebra functions are available in the <code>numpy.linalg</code> module, in particular the <code>inv</code> function to compute a square matrix's inverse:</p> <pre><code>import numpy.linalg as linalg\n\nm3 = np.array([[1,2,3],[5,7,11],[21,29,31]])\nm3\n</code></pre> Output <p>array([[ 1,  2,  3],        [ 5,  7, 11],        [21, 29, 31]])</p> <pre><code>linalg.inv(m3)\n</code></pre> Output <p>array([[-2.31818182,  0.56818182,  0.02272727],        [ 1.72727273, -0.72727273,  0.09090909],        [-0.04545455,  0.29545455, -0.06818182]])</p> <p>You can also compute the pseudoinverse using <code>pinv</code>:</p> <pre><code>linalg.pinv(m3)\n</code></pre> Output <p>array([[-2.31818182,  0.56818182,  0.02272727],        [ 1.72727273, -0.72727273,  0.09090909],        [-0.04545455,  0.29545455, -0.06818182]])</p>"},{"location":"Tutorials/Libraries/numpy/#identity-matrix","title":"Identity matrix","text":"<p>The product of a matrix by its inverse returns the identiy matrix (with small floating point errors):</p> <pre><code>m3.dot(linalg.inv(m3))\n</code></pre> Output <p>array([[  1.00000000e+00,  -1.11022302e-16,  -6.93889390e-18],        [ -1.33226763e-15,   1.00000000e+00,  -5.55111512e-17],        [  2.88657986e-15,   0.00000000e+00,   1.00000000e+00]])</p> <p>You can create an identity matrix of size NxN by calling <code>eye</code>:</p> <pre><code>np.eye(3)\n</code></pre> Output <p>array([[ 1.,  0.,  0.],        [ 0.,  1.,  0.],        [ 0.,  0.,  1.]])</p>"},{"location":"Tutorials/Libraries/numpy/#qr-decomposition","title":"QR decomposition","text":"<p>The <code>qr</code> function computes the QR decomposition of a matrix:</p> <pre><code>q, r = linalg.qr(m3)\nq\n</code></pre> Output <p>array([[-0.04627448,  0.98786672,  0.14824986],        [-0.23137241,  0.13377362, -0.96362411],        [-0.97176411, -0.07889213,  0.22237479]])</p> <pre><code>r\n</code></pre> Output <p>array([[-21.61018278, -29.89331494, -32.80860727],        [  0.        ,   0.62427688,   1.9894538 ],        [  0.        ,   0.        ,  -3.26149699]])</p> <pre><code>q.dot(r)  # q.r equals m3\n</code></pre> Output <p>array([[  1.,   2.,   3.],        [  5.,   7.,  11.],        [ 21.,  29.,  31.]])</p>"},{"location":"Tutorials/Libraries/numpy/#determinant","title":"Determinant","text":"<p>The <code>det</code> function computes the matrix determinant:</p> <pre><code>linalg.det(m3)  # Computes the matrix determinant\n</code></pre> Output <p>43.999999999999972</p>"},{"location":"Tutorials/Libraries/numpy/#eigenvalues-and-eigenvectors","title":"Eigenvalues and eigenvectors","text":"<p>The <code>eig</code> function computes the eigenvalues and eigenvectors of a square matrix:</p> <pre><code>eigenvalues, eigenvectors = linalg.eig(m3)\neigenvalues # \u03bb\n</code></pre> Output <p>array([ 42.26600592,  -0.35798416,  -2.90802176])</p> <pre><code>eigenvectors # v\n</code></pre> Output <p>array([[-0.08381182, -0.76283526, -0.18913107],        [-0.3075286 ,  0.64133975, -0.6853186 ],        [-0.94784057, -0.08225377,  0.70325518]])</p> <pre><code>m3.dot(eigenvectors) - eigenvalues * eigenvectors  # m3.v - \u03bb*v = 0\n</code></pre> Output <p>array([[  8.88178420e-15,   2.49800181e-15,  -3.33066907e-16],        [  1.77635684e-14,  -1.66533454e-16,  -3.55271368e-15],        [  3.55271368e-14,   3.61516372e-15,  -4.44089210e-16]])</p>"},{"location":"Tutorials/Libraries/numpy/#singular-value-decomposition","title":"Singular Value Decomposition","text":"<p>The <code>svd</code> function takes a matrix and returns its singular value decomposition:</p> <pre><code>m4 = np.array([[1,0,0,0,2], [0,0,3,0,0], [0,0,0,0,0], [0,2,0,0,0]])\nm4\n</code></pre> Output <p>array([[1, 0, 0, 0, 2],        [0, 0, 3, 0, 0],        [0, 0, 0, 0, 0],        [0, 2, 0, 0, 0]])</p> <pre><code>U, S_diag, V = linalg.svd(m4)\nU\n</code></pre> Output <p>array([[ 0.,  1.,  0.,  0.],        [ 1.,  0.,  0.,  0.],        [ 0.,  0.,  0., -1.],        [ 0.,  0.,  1.,  0.]])</p> <pre><code>S_diag\n</code></pre> Output <p>array([ 3.        ,  2.23606798,  2.        ,  0.        ])</p> <p>The <code>svd</code> function just returns the values in the diagonal of \u03a3, but we want the full \u03a3 matrix, so let's create it:</p> <pre><code>S = np.zeros((4, 5))\nS[np.diag_indices(4)] = S_diag\nS  # \u03a3\n</code></pre> Output <p>array([[ 3.        ,  0.        ,  0.        ,  0.        ,  0.        ],        [ 0.        ,  2.23606798,  0.        ,  0.        ,  0.        ],        [ 0.        ,  0.        ,  2.        ,  0.        ,  0.        ],        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ]])</p> <pre><code>V\n</code></pre> Output <p>array([[-0.        ,  0.        ,  1.        , -0.        ,  0.        ],        [ 0.4472136 ,  0.        ,  0.        ,  0.        ,  0.89442719],        [-0.        ,  1.        ,  0.        , -0.        ,  0.        ],        [ 0.        ,  0.        ,  0.        ,  1.        ,  0.        ],        [-0.89442719,  0.        ,  0.        ,  0.        ,  0.4472136 ]])</p> <pre><code>U.dot(S).dot(V) # U.\u03a3.V == m4\n</code></pre> Output <p>array([[ 1.,  0.,  0.,  0.,  2.],        [ 0.,  0.,  3.,  0.,  0.],        [ 0.,  0.,  0.,  0.,  0.],        [ 0.,  2.,  0.,  0.,  0.]])</p>"},{"location":"Tutorials/Libraries/numpy/#diagonal-and-trace","title":"Diagonal and trace","text":"<pre><code>np.diag(m3)  # the values in the diagonal of m3 (top left to bottom right)\n</code></pre> Output <p>array([ 1,  7, 31])</p> <pre><code>np.trace(m3)  # equivalent to np.diag(m3).sum()\n</code></pre> Output <p>39</p>"},{"location":"Tutorials/Libraries/numpy/#solving-a-system-of-linear-scalar-equations","title":"Solving a system of linear scalar equations","text":"<p>The <code>solve</code> function solves a system of linear scalar equations, such as:</p> <ul> <li>2x + 6y = 6</li> <li>5x + 3y = -9</li> </ul> <pre><code>coeffs  = np.array([[2, 6], [5, 3]])\ndepvars = np.array([6, -9])\nsolution = linalg.solve(coeffs, depvars)\nsolution\n</code></pre> Output <p>array([-3.,  2.])</p> <p>Let's check the solution:</p> <pre><code>coeffs.dot(solution), depvars  # yep, it's the same\n</code></pre> Output <p>(array([ 6., -9.]), array([ 6, -9]))</p> <p>Looks good! Another way to check the solution:</p> <pre><code>np.allclose(coeffs.dot(solution), depvars)\n</code></pre> Output <p>True</p>"},{"location":"Tutorials/Libraries/numpy/#vectorization","title":"Vectorization","text":"<p>Instead of executing operations on individual array items, one at a time, your code is much more efficient if you try to stick to array operations. This is called vectorization. This way, you can benefit from NumPy's many optimizations.</p> <p>For example, let's say we want to generate a 768x1024 array based on the formula sin(xy/40.5). A bad option would be to do the math in python using nested loops:</p> <pre><code>import math\ndata = np.empty((768, 1024))\nfor y in range(768):\n    for x in range(1024):\n        data[y, x] = math.sin(x*y/40.5)  # BAD! Very inefficient.\n</code></pre> <p>Sure, this works, but it's terribly inefficient since the loops are taking place in pure python. Let's vectorize this algorithm. First, we will use NumPy's <code>meshgrid</code> function which generates coordinate matrices from coordinate vectors.</p> <pre><code>x_coords = np.arange(0, 1024)  # [0, 1, 2, ..., 1023]\ny_coords = np.arange(0, 768)   # [0, 1, 2, ..., 767]\nX, Y = np.meshgrid(x_coords, y_coords)\nX\n</code></pre> Output <p>array([[   0,    1,    2, ..., 1021, 1022, 1023],        [   0,    1,    2, ..., 1021, 1022, 1023],        [   0,    1,    2, ..., 1021, 1022, 1023],        ...,         [   0,    1,    2, ..., 1021, 1022, 1023],        [   0,    1,    2, ..., 1021, 1022, 1023],        [   0,    1,    2, ..., 1021, 1022, 1023]])</p> <pre><code>Y\n</code></pre> Output <p>array([[  0,   0,   0, ...,   0,   0,   0],        [  1,   1,   1, ...,   1,   1,   1],        [  2,   2,   2, ...,   2,   2,   2],        ...,         [765, 765, 765, ..., 765, 765, 765],        [766, 766, 766, ..., 766, 766, 766],        [767, 767, 767, ..., 767, 767, 767]])</p> <p>As you can see, both <code>X</code> and <code>Y</code> are 768x1024 arrays, and all values in <code>X</code> correspond to the horizontal coordinate, while all values in <code>Y</code> correspond to the the vertical coordinate.</p> <p>Now we can simply compute the result using array operations:</p> <pre><code>data = np.sin(X*Y/40.5)\n</code></pre> <p>Now we can plot this data using matplotlib's <code>imshow</code> function</p> <pre><code>import matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nfig = plt.figure(1, figsize=(7, 6))\nplt.imshow(data, cmap=cm.hot, interpolation=\"bicubic\")\nplt.show()\n</code></pre>"},{"location":"Tutorials/Libraries/numpy/#saving-and-loading","title":"Saving and loading","text":"<p>NumPy makes it easy to save and load <code>ndarray</code>s in binary or text format.</p>"},{"location":"Tutorials/Libraries/numpy/#binary-npy-format","title":"Binary <code>.npy</code> format","text":"<p>Let's create a random array and save it.</p> <pre><code>a = np.random.rand(2,3)\na\n</code></pre> Output <p>array([[ 0.41307972,  0.20933385,  0.32025581],        [ 0.19853514,  0.408001  ,  0.6038287 ]])</p> <pre><code>np.save(\"my_array\", a)\n</code></pre> <p>Done! Since the file name contains no file extension was provided, NumPy automatically added <code>.npy</code>. Let's take a peek at the file content:</p> <pre><code>with open(\"my_array.npy\", \"rb\") as f:\n    content = f.read()\n\ncontent\n</code></pre> Output <p>\"\\x93NUMPY\\x01\\x00F\\x00{'descr': '\\x12\\x7f\\xd4?x&lt;h\\x81\\x99i\\xc9?@\\xa4\\x027\\xb0\\x1c\\xda?&lt;P\\x05\\x8f\\x90R\\xe3?\" <p>To load this file into a NumPy array, simply call <code>load</code>:</p> <pre><code>a_loaded = np.load(\"my_array.npy\")\na_loaded\n</code></pre> Output <p>array([[ 0.41307972,  0.20933385,  0.32025581],        [ 0.19853514,  0.408001  ,  0.6038287 ]])</p>"},{"location":"Tutorials/Libraries/numpy/#text-format","title":"Text format","text":"<p>Let's try saving the array in text format:</p> <pre><code>np.savetxt(\"my_array.csv\", a)\n</code></pre> <p>Now let's look at the file content:</p> <pre><code>with open(\"my_array.csv\", \"rt\") as f:\n    print(f.read())\n</code></pre> Output <p>4.130797191668116319e-01 2.093338525574361952e-01 3.202558143634371968e-01 1.985351449843368865e-01 4.080009972772735694e-01 6.038286965726977762e-01</p> <p>This is a CSV file with tabs as delimiters. You can set a different delimiter:</p> <pre><code>np.savetxt(\"my_array.csv\", a, delimiter=\",\")\n</code></pre> <p>To load this file, just use <code>loadtxt</code>:</p> <pre><code>a_loaded = np.loadtxt(\"my_array.csv\", delimiter=\",\")\na_loaded\n</code></pre> Output <p>array([[ 0.41307972,  0.20933385,  0.32025581],        [ 0.19853514,  0.408001  ,  0.6038287 ]])</p>"},{"location":"Tutorials/Libraries/numpy/#zipped-npz-format","title":"Zipped <code>.npz</code> format","text":"<p>It is also possible to save multiple arrays in one zipped file:</p> <pre><code>b = np.arange(24, dtype=np.uint8).reshape(2, 3, 4)\nb\n</code></pre> Output <p>array([[[ 0,  1,  2,  3],         [ 4,  5,  6,  7],         [ 8,  9, 10, 11]],</p> <pre><code>   [[12, 13, 14, 15],\n    [16, 17, 18, 19],\n    [20, 21, 22, 23]]], dtype=uint8)\n</code></pre> <pre><code>np.savez(\"my_arrays\", my_a=a, my_b=b)\n</code></pre> <p>Again, let's take a peek at the file content. Note that the <code>.npz</code> file extension was automatically added.</p> <pre><code>with open(\"my_arrays.npz\", \"rb\") as f:\n    content = f.read()\n\nrepr(content)[:180] + \"[...]\"\n</code></pre> Output <p>u'\"PK\\x03\\x04\\x14\\x00\\x00\\x00\\x00\\x00x\\x94cH\\xb6\\x96\\xe4{h\\x00\\x00\\x00h\\x00\\x00\\x00\\x08\\x00\\x00\\x00my_b.npy\\x93NUMPY\\x01\\x00F\\x00{\\'descr\\': \\'|u1\\', \\'fortran_order\\': False, \\'shape\\': (2,[...]'</p> <p>You then load this file like so:</p> <pre><code>my_arrays = np.load(\"my_arrays.npz\")\nmy_arrays\n</code></pre> Output <p> <p>This is a dict-like object which loads the arrays lazily:</p> <pre><code>my_arrays.keys()\n</code></pre> Output <p>['my_b', 'my_a']</p> <pre><code>my_arrays[\"my_a\"]\n</code></pre> Output <p>array([[ 0.41307972,  0.20933385,  0.32025581],        [ 0.19853514,  0.408001  ,  0.6038287 ]])</p>"},{"location":"Tutorials/Libraries/numpy/#what-next","title":"What next?","text":"<p>Now you know all the fundamentals of NumPy, but there are many more options available. The best way to learn more is to experiment with NumPy, and go through the excellent reference documentation to find more functions and features you may be interested in.</p>"},{"location":"Tutorials/Libraries/pandas/","title":"Pandas","text":"<p>The <code>pandas</code> library provides high-performance, easy-to-use data structures and data analysis tools. The main data structure is the <code>DataFrame</code>, which you can think of as an in-memory 2D table (like a spreadsheet, with column names and row labels). Many features available in Excel are available programmatically, such as creating pivot tables, computing columns based on other columns, plotting graphs, etc. You can also group rows by column value, or join tables much like in SQL. Pandas is also great at handling time series.</p> <p>Prerequisites:</p> <ul> <li>NumPy \u2013 if you are not familiar with NumPy, we recommend that you go through the NumPy tutorial now.</li> </ul>"},{"location":"Tutorials/Libraries/pandas/#setup","title":"Setup","text":"<p>First, let's import <code>pandas</code>. People usually import it as <code>pd</code>:</p> <pre><code>import pandas as pd\n</code></pre>"},{"location":"Tutorials/Libraries/pandas/#series-objects","title":"Series objects","text":"<p>The <code>pandas</code> library contains these useful data structures:</p> <ul> <li> <p><code>Series</code> objects, that we will discuss now. A <code>Series</code> object is 1D array, similar to a column in a spreadsheet (with a column name and row labels).</p> </li> <li> <p><code>DataFrame</code> objects. This is a 2D table, similar to a spreadsheet (with column names and row labels).</p> </li> <li> <p><code>Panel</code> objects. You can see a <code>Panel</code> as a dictionary of <code>DataFrame</code>s. These are less used, so we will not discuss them here.</p> </li> </ul>"},{"location":"Tutorials/Libraries/pandas/#creating-a-series","title":"Creating a Series","text":"<p>Let's start by creating our first <code>Series</code> object!</p> <pre><code>s = pd.Series([2,-1,3,5])\ns\n</code></pre> Output <pre><code>0    2\n1   -1\n2    3\n3    5\ndtype: int64\n</code></pre>"},{"location":"Tutorials/Libraries/pandas/#similar-to-a-1d-ndarray","title":"Similar to a 1D ndarray","text":"<p><code>Series</code> objects behave much like one-dimensional NumPy <code>ndarray</code>s, and you can often pass them as parameters to NumPy functions:</p> <pre><code>import numpy as np\nnp.exp(s)\n</code></pre> Output <pre><code>0      7.389056\n1      0.367879\n2     20.085537\n3    148.413159\ndtype: float64\n</code></pre> <p>Arithmetic operations on <code>Series</code> are also possible, and they apply elementwise, just like for <code>ndarray</code>s:</p> <pre><code>s + [1000,2000,3000,4000]\n</code></pre> Output <pre><code>0    1002\n1    1999\n2    3003\n3    4005\ndtype: int64\n</code></pre> <p>Similar to NumPy, if you add a single number to a <code>Series</code>, that number is added to all items in the <code>Series</code>. This is called * broadcasting*:</p> <pre><code>s + 1000\n</code></pre> Output <pre><code>0    1002\n1     999\n2    1003\n3    1005\ndtype: int64\n</code></pre> <p>The same is true for all binary operations such as <code>*</code> or <code>/</code>, and even conditional operations:</p> <pre><code>s &lt; 0\n</code></pre> Output <pre><code>0    False\n1     True\n2    False\n3    False\ndtype: bool\n</code></pre>"},{"location":"Tutorials/Libraries/pandas/#index-labels","title":"Index labels","text":"<p>Each item in a <code>Series</code> object has a unique identifier called the index label. By default, it is simply the rank of the item in the <code>Series</code> (starting at <code>0</code>) but you can also set the index labels manually:</p> <pre><code>s2 = pd.Series([68, 83, 112, 68], index=[\"alice\", \"bob\", \"charles\", \"darwin\"])\ns2\n</code></pre> Output <pre><code>alice       68\nbob         83\ncharles    112\ndarwin      68\ndtype: int64\n</code></pre> <p>You can then use the <code>Series</code> just like a <code>dict</code>:</p> <pre><code>s2[\"bob\"]\n</code></pre> Output <p>83</p> <p>You can still access the items by integer location, like in a regular array:</p> <pre><code>s2[1]\n</code></pre> Output <p>83</p> <p>To make it clear when you are accessing by label or by integer location, it is recommended to always use the <code>loc</code> attribute when accessing by label, and the <code>iloc</code> attribute when accessing by integer location:</p> <pre><code>s2.loc[\"bob\"]\n</code></pre> Output <p>83</p> <pre><code>s2.iloc[1]\n</code></pre> Output <p>83</p> <p>Slicing a <code>Series</code> also slices the index labels:</p> <pre><code>s2.iloc[1:3]\n</code></pre> Output <pre><code>bob         83\ncharles    112\ndtype: int64\n</code></pre> <p>This can lead to unexpected results when using the default numeric labels, so be careful:</p> <pre><code>surprise = pd.Series([1000, 1001, 1002, 1003])\nsurprise\n</code></pre> Output <pre><code>0    1000\n1    1001\n2    1002\n3    1003\ndtype: int64\n</code></pre> <pre><code>surprise_slice = surprise[2:]\nsurprise_slice\n</code></pre> Output <pre><code>2    1002\n3    1003\ndtype: int64\n</code></pre> <p>Oh look! The first element has index label <code>2</code>. The element with index label <code>0</code> is absent from the slice:</p> <pre><code>try:\n    surprise_slice[0]\nexcept KeyError as e:\n    print(\"Key error:\", e)\n</code></pre> Output <p>Key error: 0</p> <p>But remember that you can access elements by integer location using the <code>iloc</code> attribute. This illustrates another reason why it's always better to use <code>loc</code> and <code>iloc</code> to access <code>Series</code> objects:</p> <pre><code>surprise_slice.iloc[0]\n</code></pre> Output <p>1002</p>"},{"location":"Tutorials/Libraries/pandas/#init-from-dict","title":"Init from dict","text":"<p>You can create a <code>Series</code> object from a <code>dict</code>. The keys will be used as index labels:</p> <pre><code>weights = {\"alice\": 68, \"bob\": 83, \"colin\": 86, \"darwin\": 68}\ns3 = pd.Series(weights)\ns3\n</code></pre> Output <pre><code>alice     68\nbob       83\ncolin     86\ndarwin    68\ndtype: int64\n</code></pre> <p>You can control which elements you want to include in the <code>Series</code> and in what order by explicitly specifying the desired <code>index</code>:</p> <pre><code>s4 = pd.Series(weights, index = [\"colin\", \"alice\"])\ns4\n</code></pre> Output <pre><code>colin    86\nalice    68\ndtype: int64\n</code></pre>"},{"location":"Tutorials/Libraries/pandas/#automatic-alignment","title":"Automatic alignment","text":"<p>When an operation involves multiple <code>Series</code> objects, <code>pandas</code> automatically aligns items by matching index labels.</p> <pre><code>print(s2.keys())\nprint(s3.keys())\n\ns2 + s3\n</code></pre> Output <pre><code>Index(['alice', 'bob', 'charles', 'darwin'], dtype='object')\nIndex(['alice', 'bob', 'colin', 'darwin'], dtype='object')\nalice      136.0\nbob        166.0\ncharles      NaN\ncolin        NaN\ndarwin     136.0\ndtype: float64\n</code></pre> <p>The resulting <code>Series</code> contains the union of index labels from <code>s2</code> and <code>s3</code>. Since <code>\"colin\"</code> is missing from <code>s2</code> and <code>\"charles\"</code> is missing from <code>s3</code>, these items have a <code>NaN</code> result value. (ie. Not-a-Number means missing).</p> <p>Automatic alignment is very handy when working with data that may come from various sources with varying structure and missing items. But if you forget to set the right index labels, you can have surprising results:</p> <pre><code>s5 = pd.Series([1000,1000,1000,1000])\nprint(\"s2 =\", s2.values)\nprint(\"s5 =\", s5.values)\n\ns2 + s5\n</code></pre> Output <pre><code>s2 = [ 68  83 112  68]\ns5 = [1000 1000 1000 1000]\nalice     NaN\nbob       NaN\ncharles   NaN\ndarwin    NaN\n0         NaN\n1         NaN\n2         NaN\n3         NaN\ndtype: float64\n</code></pre> <p>Pandas could not align the <code>Series</code>, since their labels do not match at all, hence the full <code>NaN</code> result.</p>"},{"location":"Tutorials/Libraries/pandas/#init-with-a-scalar","title":"Init with a scalar","text":"<p>You can also initialize a <code>Series</code> object using a scalar and a list of index labels: all items will be set to the scalar.</p> <pre><code>meaning = pd.Series(42, [\"life\", \"universe\", \"everything\"])\nmeaning\n</code></pre> Output <pre><code>life          42\nuniverse      42\neverything    42\ndtype: int64\n</code></pre>"},{"location":"Tutorials/Libraries/pandas/#series-name","title":"Series name","text":"<p>A <code>Series</code> can have a <code>name</code>:</p> <pre><code>s6 = pd.Series([83, 68], index=[\"bob\", \"alice\"], name=\"weights\")\ns6\n</code></pre> Output <pre><code>bob      83\nalice    68\nName: weights, dtype: int64\n</code></pre>"},{"location":"Tutorials/Libraries/pandas/#plotting-a-series","title":"Plotting a Series","text":"<p>Pandas makes it easy to plot <code>Series</code> data using matplotlib (for more details on matplotlib, check out the matplotlib tutorial). Just import matplotlib and call the <code>plot()</code> method:</p> <pre><code>%matplotlib inline\nimport matplotlib.pyplot as plt\ntemperatures = [4.4,5.1,6.1,6.2,6.1,6.1,5.7,5.2,4.7,4.1,3.9,3.5]\ns7 = pd.Series(temperatures, name=\"Temperature\")\ns7.plot()\nplt.show()\n</code></pre> Output <p></p> <p>There are many options for plotting your data. It is not necessary to list them all here: if you need a particular type of plot (histograms, pie charts, etc.), just look for it in the excellent Visualization section of pandas' documentation, and look at the example code.</p>"},{"location":"Tutorials/Libraries/pandas/#handling-time","title":"Handling time","text":"<p>Many datasets have timestamps, and pandas is awesome at manipulating such data:</p> <ul> <li> <p>it can represent periods (such as 2016Q3) and frequencies (such as \"monthly\"),</p> </li> <li> <p>it can convert periods to actual timestamps, and vice versa,</p> </li> <li> <p>it can resample data and aggregate values any way you like,</p> </li> <li> <p>it can handle timezones.</p> </li> </ul>"},{"location":"Tutorials/Libraries/pandas/#time-range","title":"Time range","text":"<p>Let's start by creating a time series using <code>pd.date_range()</code>. This returns a <code>DatetimeIndex</code> containing one datetime per hour for 12 hours starting on October 29<sup>th</sup> 2016 at 5:30pm.</p> <pre><code>dates = pd.date_range('2016/10/29 5:30pm', periods=12, freq='H')\ndates\n</code></pre> Output <pre><code>DatetimeIndex(['2016-10-29 17:30:00', '2016-10-29 18:30:00',\n            '2016-10-29 19:30:00', '2016-10-29 20:30:00',\n            '2016-10-29 21:30:00', '2016-10-29 22:30:00',\n            '2016-10-29 23:30:00', '2016-10-30 00:30:00',\n            '2016-10-30 01:30:00', '2016-10-30 02:30:00',\n            '2016-10-30 03:30:00', '2016-10-30 04:30:00'],\n            dtype='datetime64[ns]', freq='H')\n</code></pre> <p>This <code>DatetimeIndex</code> may be used as an index in a <code>Series</code>:</p> <pre><code>temp_series = pd.Series(temperatures, dates)\ntemp_series\n</code></pre> Output <pre><code>2016-10-29 17:30:00    4.4\n2016-10-29 18:30:00    5.1\n2016-10-29 19:30:00    6.1\n2016-10-29 20:30:00    6.2\n2016-10-29 21:30:00    6.1\n2016-10-29 22:30:00    6.1\n2016-10-29 23:30:00    5.7\n2016-10-30 00:30:00    5.2\n2016-10-30 01:30:00    4.7\n2016-10-30 02:30:00    4.1\n2016-10-30 03:30:00    3.9\n2016-10-30 04:30:00    3.5\nFreq: H, dtype: float64\n</code></pre> <p>Let's plot this series:</p> <pre><code>temp_series.plot(kind=\"bar\")\n\nplt.grid(True)\nplt.show()\n</code></pre> Output <p></p>"},{"location":"Tutorials/Libraries/pandas/#resampling","title":"Resampling","text":"<p>Pandas lets us resample a time series very simply. Just call the <code>resample()</code> method and specify a new frequency:</p> <pre><code>temp_series_freq_2H = temp_series.resample(\"2H\")\ntemp_series_freq_2H\n</code></pre> Output <pre><code>DatetimeIndexResampler [freq=&lt;2 * Hours&gt;, axis=0, closed=left, label=left, convention=start, base=0]\n</code></pre> <p>The resampling operation is actually a deferred operation, which is why we did not get a <code>Series</code> object, but a <code>DatetimeIndexResampler</code> object instead. To actually perform the resampling operation, we can simply call the <code>mean()</code> method: Pandas will compute the mean of every pair of consecutive hours:</p> <pre><code>temp_series_freq_2H = temp_series_freq_2H.mean()\n</code></pre> <p>Let's plot the result:</p> <pre><code>temp_series_freq_2H.plot(kind=\"bar\")\nplt.show()\n</code></pre> Output <p></p> <p>Note how the values have automatically been aggregated into 2-hour periods. If we look at the 6-8pm period, for example, we had a value of <code>5.1</code> at 6:30pm, and <code>6.1</code> at 7:30pm. After resampling, we just have one value of <code>5.6</code>, which is the mean of <code>5.1</code> and <code>6.1</code>. Rather than computing the mean, we could have used any other aggregation function, for example we can decide to keep the minimum value of each period:</p> <pre><code>temp_series_freq_2H = temp_series.resample(\"2H\").min()\ntemp_series_freq_2H\n</code></pre> Output <pre><code>2016-10-29 16:00:00    4.4\n2016-10-29 18:00:00    5.1\n2016-10-29 20:00:00    6.1\n2016-10-29 22:00:00    5.7\n2016-10-30 00:00:00    4.7\n2016-10-30 02:00:00    3.9\n2016-10-30 04:00:00    3.5\nFreq: 2H, dtype: float64\n</code></pre> <p>Or, equivalently, we could use the <code>apply()</code> method instead:</p> <pre><code>temp_series_freq_2H = temp_series.resample(\"2H\").apply(np.min)\ntemp_series_freq_2H\n</code></pre> Output <pre><code>2016-10-29 16:00:00    4.4\n2016-10-29 18:00:00    5.1\n2016-10-29 20:00:00    6.1\n2016-10-29 22:00:00    5.7\n2016-10-30 00:00:00    4.7\n2016-10-30 02:00:00    3.9\n2016-10-30 04:00:00    3.5\nFreq: 2H, dtype: float64\n</code></pre>"},{"location":"Tutorials/Libraries/pandas/#upsampling-and-interpolation","title":"Upsampling and interpolation","text":"<p>This was an example of downsampling. We can also upsample (ie. increase the frequency), but this creates holes in our data:</p> <pre><code>temp_series_freq_15min = temp_series.resample(\"15Min\").mean()\ntemp_series_freq_15min.head(n=10) # `head` displays the top n values\n</code></pre> Output <pre><code>2016-10-29 17:30:00    4.4\n2016-10-29 17:45:00    NaN\n2016-10-29 18:00:00    NaN\n2016-10-29 18:15:00    NaN\n2016-10-29 18:30:00    5.1\n2016-10-29 18:45:00    NaN\n2016-10-29 19:00:00    NaN\n2016-10-29 19:15:00    NaN\n2016-10-29 19:30:00    6.1\n2016-10-29 19:45:00    NaN\nFreq: 15T, dtype: float64\n</code></pre> <p>One solution is to fill the gaps by interpolating. We just call the <code>interpolate()</code> method. The default is to use linear interpolation, but we can also select another method, such as cubic interpolation:</p> <pre><code>temp_series_freq_15min = temp_series.resample(\"15Min\").interpolate(method=\"cubic\")\ntemp_series_freq_15min.head(n=10)\n</code></pre> Output <pre><code>2016-10-29 17:30:00    4.400000\n2016-10-29 17:45:00    4.452911\n2016-10-29 18:00:00    4.605113\n2016-10-29 18:15:00    4.829758\n2016-10-29 18:30:00    5.100000\n2016-10-29 18:45:00    5.388992\n2016-10-29 19:00:00    5.669887\n2016-10-29 19:15:00    5.915839\n2016-10-29 19:30:00    6.100000\n2016-10-29 19:45:00    6.203621\nFreq: 15T, dtype: float64\n</code></pre> <pre><code>temp_series.plot(label=\"Period: 1 hour\")\ntemp_series_freq_15min.plot(label=\"Period: 15 minutes\")\nplt.legend()\nplt.show()\n</code></pre> Output <p></p>"},{"location":"Tutorials/Libraries/pandas/#timezones","title":"Timezones","text":"<p>By default datetimes are naive: they are not aware of timezones, so 2016-10-30 02:30 might mean October 30<sup>th</sup> 2016 at 2:30am in Paris or in New York. We can make datetimes timezone aware by calling the <code>tz_localize()</code> method:</p> <pre><code>temp_series_ny = temp_series.tz_localize(\"America/New_York\")\ntemp_series_ny\n</code></pre> Output <pre><code>2016-10-29 17:30:00-04:00    4.4\n2016-10-29 18:30:00-04:00    5.1\n2016-10-29 19:30:00-04:00    6.1\n2016-10-29 20:30:00-04:00    6.2\n2016-10-29 21:30:00-04:00    6.1\n2016-10-29 22:30:00-04:00    6.1\n2016-10-29 23:30:00-04:00    5.7\n2016-10-30 00:30:00-04:00    5.2\n2016-10-30 01:30:00-04:00    4.7\n2016-10-30 02:30:00-04:00    4.1\n2016-10-30 03:30:00-04:00    3.9\n2016-10-30 04:30:00-04:00    3.5\nFreq: H, dtype: float64\n</code></pre> <p>Note that <code>-04:00</code> is now appended to all the datetimes. This means that these datetimes refer to UTC - 4 hours.</p> <p>We can convert these datetimes to Paris time like this:</p> <pre><code>temp_series_paris = temp_series_ny.tz_convert(\"Europe/Paris\")\ntemp_series_paris\n</code></pre> Output <pre><code>2016-10-29 23:30:00+02:00    4.4\n2016-10-30 00:30:00+02:00    5.1\n2016-10-30 01:30:00+02:00    6.1\n2016-10-30 02:30:00+02:00    6.2\n2016-10-30 02:30:00+01:00    6.1\n2016-10-30 03:30:00+01:00    6.1\n2016-10-30 04:30:00+01:00    5.7\n2016-10-30 05:30:00+01:00    5.2\n2016-10-30 06:30:00+01:00    4.7\n2016-10-30 07:30:00+01:00    4.1\n2016-10-30 08:30:00+01:00    3.9\n2016-10-30 09:30:00+01:00    3.5\nFreq: H, dtype: float64\n</code></pre> <p>You may have noticed that the UTC offset changes from <code>+02:00</code> to <code>+01:00</code>: this is because France switches to winter time at 3am that particular night (time goes back to 2am). Notice that 2:30am occurs twice! Let's go back to a naive representation (if you log some data hourly using local time, without storing the timezone, you might get something like this):</p> <pre><code>temp_series_paris_naive = temp_series_paris.tz_localize(None)\ntemp_series_paris_naive\n</code></pre> Output <pre><code>2016-10-29 23:30:00    4.4\n2016-10-30 00:30:00    5.1\n2016-10-30 01:30:00    6.1\n2016-10-30 02:30:00    6.2\n2016-10-30 02:30:00    6.1\n2016-10-30 03:30:00    6.1\n2016-10-30 04:30:00    5.7\n2016-10-30 05:30:00    5.2\n2016-10-30 06:30:00    4.7\n2016-10-30 07:30:00    4.1\n2016-10-30 08:30:00    3.9\n2016-10-30 09:30:00    3.5\nFreq: H, dtype: float64\n</code></pre> <p>Now <code>02:30</code> is really ambiguous. If we try to localize these naive datetimes to the Paris timezone, we get an error:</p> <pre><code>try:\n    temp_series_paris_naive.tz_localize(\"Europe/Paris\")\nexcept Exception as e:\n    print(type(e))\n    print(e)\n</code></pre> Output <pre><code>&lt;class 'pytz.exceptions.AmbiguousTimeError'&gt;\nCannot infer dst time from Timestamp('2016-10-30 02:30:00'), try using the 'ambiguous' argument\n</code></pre> <p>Fortunately using the <code>ambiguous</code> argument we can tell pandas to infer the right DST (Daylight Saving Time) based on the order of the ambiguous timestamps:</p> <pre><code>temp_series_paris_naive.tz_localize(\"Europe/Paris\", ambiguous=\"infer\")\n</code></pre> Output <pre><code>2016-10-29 23:30:00+02:00    4.4\n2016-10-30 00:30:00+02:00    5.1\n2016-10-30 01:30:00+02:00    6.1\n2016-10-30 02:30:00+02:00    6.2\n2016-10-30 02:30:00+01:00    6.1\n2016-10-30 03:30:00+01:00    6.1\n2016-10-30 04:30:00+01:00    5.7\n2016-10-30 05:30:00+01:00    5.2\n2016-10-30 06:30:00+01:00    4.7\n2016-10-30 07:30:00+01:00    4.1\n2016-10-30 08:30:00+01:00    3.9\n2016-10-30 09:30:00+01:00    3.5\nFreq: H, dtype: float64\n</code></pre>"},{"location":"Tutorials/Libraries/pandas/#periods","title":"Periods","text":"<p>The <code>pd.period_range()</code> function returns a <code>PeriodIndex</code> instead of a <code>DatetimeIndex</code>. For example, let's get all quarters in 2016 and 2017:</p> <pre><code>quarters = pd.period_range('2016Q1', periods=8, freq='Q')\nquarters\n</code></pre> Output <pre><code>PeriodIndex(['2016Q1', '2016Q2', '2016Q3', '2016Q4', '2017Q1', '2017Q2',\n            '2017Q3', '2017Q4'],\n            dtype='period[Q-DEC]', freq='Q-DEC')\n</code></pre> <p>Adding a number <code>N</code> to a <code>PeriodIndex</code> shifts the periods by <code>N</code> times the <code>PeriodIndex</code>'s frequency:</p> <pre><code>quarters + 3\n</code></pre> Output <pre><code>PeriodIndex(['2016Q4', '2017Q1', '2017Q2', '2017Q3', '2017Q4', '2018Q1',\n            '2018Q2', '2018Q3'],\n            dtype='period[Q-DEC]', freq='Q-DEC')\n</code></pre> <p>The <code>asfreq()</code> method lets us change the frequency of the <code>PeriodIndex</code>. All periods are lengthened or shortened accordingly. For example, let's convert all the quarterly periods to monthly periods (zooming in):</p> <pre><code>quarters.asfreq(\"M\")\n</code></pre> Output <pre><code>PeriodIndex(['2016-03', '2016-06', '2016-09', '2016-12', '2017-03', '2017-06',\n            '2017-09', '2017-12'],\n            dtype='period[M]', freq='M')\n</code></pre> <p>By default, the <code>asfreq</code> zooms on the end of each period. We can tell it to zoom on the start of each period instead:</p> <pre><code>quarters.asfreq(\"M\", how=\"start\")\n</code></pre> Output <pre><code>PeriodIndex(['2016-01', '2016-04', '2016-07', '2016-10', '2017-01', '2017-04',\n            '2017-07', '2017-10'],\n            dtype='period[M]', freq='M')\n</code></pre> <p>And we can zoom out:</p> <pre><code>quarters.asfreq(\"A\")\n</code></pre> Output <pre><code>PeriodIndex(['2016', '2016', '2016', '2016', '2017', '2017', '2017', '2017'], dtype='period[A-DEC]', freq='A-DEC')\n</code></pre> <p>Of course we can create a <code>Series</code> with a <code>PeriodIndex</code>:</p> <pre><code>quarterly_revenue = pd.Series([300, 320, 290, 390, 320, 360, 310, 410], index = quarters)\nquarterly_revenue\n</code></pre> Output <pre><code>2016Q1    300\n2016Q2    320\n2016Q3    290\n2016Q4    390\n2017Q1    320\n2017Q2    360\n2017Q3    310\n2017Q4    410\nFreq: Q-DEC, dtype: int64\n</code></pre> <pre><code>quarterly_revenue.plot(kind=\"line\")\nplt.show()\n</code></pre> Output <p></p> <p>We can convert periods to timestamps by calling <code>to_timestamp</code>. By default this will give us the first day of each period, but by setting <code>how</code> and <code>freq</code>, we can get the last hour of each period:</p> <pre><code>last_hours = quarterly_revenue.to_timestamp(how=\"end\", freq=\"H\")\nlast_hours\n</code></pre> Output <pre><code>2016-03-31 23:00:00    300\n2016-06-30 23:00:00    320\n2016-09-30 23:00:00    290\n2016-12-31 23:00:00    390\n2017-03-31 23:00:00    320\n2017-06-30 23:00:00    360\n2017-09-30 23:00:00    310\n2017-12-31 23:00:00    410\nFreq: Q-DEC, dtype: int64\n</code></pre> <p>And back to periods by calling <code>to_period</code>:</p> <pre><code>last_hours.to_period()\n</code></pre> Output <pre><code>2016Q1    300\n2016Q2    320\n2016Q3    290\n2016Q4    390\n2017Q1    320\n2017Q2    360\n2017Q3    310\n2017Q4    410\nFreq: Q-DEC, dtype: int64\n</code></pre> <p>Pandas also provides many other time-related functions that we recommend you check out in the documentation. To whet your appetite, here is one way to get the last business day of each month in 2016, at 9am:</p> <pre><code>months_2016 = pd.period_range(\"2016\", periods=12, freq=\"M\")\none_day_after_last_days = months_2016.asfreq(\"D\") + 1\nlast_bdays = one_day_after_last_days.to_timestamp() - pd.tseries.offsets.BDay()\nlast_bdays.to_period(\"H\") + 9\n</code></pre> Output <pre><code>PeriodIndex(['2016-01-29 09:00', '2016-02-29 09:00', '2016-03-31 09:00',\n            '2016-04-29 09:00', '2016-05-31 09:00', '2016-06-30 09:00',\n            '2016-07-29 09:00', '2016-08-31 09:00', '2016-09-30 09:00',\n            '2016-10-31 09:00', '2016-11-30 09:00', '2016-12-30 09:00'],\n            dtype='period[H]', freq='H')\n</code></pre>"},{"location":"Tutorials/Libraries/pandas/#dataframe-objects","title":"DataFrame objects","text":"<p>A DataFrame object represents a spreadsheet, with cell values, column names and row index labels. You can define expressions to compute columns based on other columns, create pivot-tables, group rows, draw graphs, etc. You can see <code>DataFrame</code>s as dictionaries of <code>Series</code>.</p>"},{"location":"Tutorials/Libraries/pandas/#creating-a-dataframe","title":"Creating a DataFrame","text":"<p>You can create a DataFrame by passing a dictionary of <code>Series</code> objects:</p> <pre><code>people_dict = {\n    \"weight\": pd.Series([68, 83, 112], index=[\"alice\", \"bob\", \"charles\"]),\n    \"birthyear\": pd.Series([1984, 1985, 1992], index=[\"bob\", \"alice\", \"charles\"], name=\"year\"),\n    \"children\": pd.Series([0, 3], index=[\"charles\", \"bob\"]),\n    \"hobby\": pd.Series([\"Biking\", \"Dancing\"], index=[\"alice\", \"bob\"]),\n}\npeople = pd.DataFrame(people_dict)\npeople\n</code></pre> Output birthyear children hobby weight alice 1985 NaN Biking 68 bob 1984 3.0 Dancing 83 charles 1992 0.0 NaN 112 <p>A few things to note:</p> <ul> <li> <p>the <code>Series</code> were automatically aligned based on their index,</p> </li> <li> <p>missing values are represented as <code>NaN</code>,</p> </li> <li> <p><code>Series</code> names are ignored (the name <code>\"year\"</code> was dropped),</p> </li> <li> <p><code>DataFrame</code>s are displayed nicely in Jupyter notebooks, woohoo!</p> </li> </ul> <p>You can access columns pretty much as you would expect. They are returned as <code>Series</code> objects:</p> <pre><code>people[\"birthyear\"]\n</code></pre> Output <pre><code>alice      1985\nbob        1984\ncharles    1992\nName: birthyear, dtype: int64\n</code></pre> <p>You can also get multiple columns at once:</p> <pre><code>people[[\"birthyear\", \"hobby\"]]\n</code></pre> Output birthyear hobby alice 1985 Biking bob 1984 Dancing charles 1992 NaN <p>If you pass a list of columns and/or index row labels to the <code>DataFrame</code> constructor, it will guarantee that these columns and/or rows will exist, in that order, and no other column/row will exist. For example:</p> <pre><code>d2 = pd.DataFrame(\n        people_dict,\n        columns=[\"birthyear\", \"weight\", \"height\"],\n        index=[\"bob\", \"alice\", \"eugene\"]\n     )\nd2\n</code></pre> Output birthyear weight weight bob 1984.0 83.0 NaN alice 1985.0 68.0 NaN eugene NaN NaN NaN <p>Another convenient way to create a <code>DataFrame</code> is to pass all the values to the constructor as an <code>ndarray</code>, or a list of lists, and specify the column names and row index labels separately:</p> <pre><code>values = [\n            [1985, np.nan, \"Biking\",   68],\n            [1984, 3,      \"Dancing\",  83],\n            [1992, 0,      np.nan,    112]\n         ]\nd3 = pd.DataFrame(\n        values,\n        columns=[\"birthyear\", \"children\", \"hobby\", \"weight\"],\n        index=[\"alice\", \"bob\", \"charles\"]\n     )\nd3\n</code></pre> Output birthyear children hobby weight alice 1985 NaN Biking 68 bob 1984 3.0 Dancing 83 charles 1992 0.0 NaN 112 <p>To specify missing values, you can either use <code>np.nan</code> or NumPy's masked arrays:</p> <pre><code>masked_array = np.ma.asarray(values, dtype=np.object)\nmasked_array[(0, 2), (1, 2)] = np.ma.masked\nd3 = pd.DataFrame(\n        masked_array,\n        columns=[\"birthyear\", \"children\", \"hobby\", \"weight\"],\n        index=[\"alice\", \"bob\", \"charles\"]\n     )\nd3\n</code></pre> Output birthyear children hobby weight alice 1985 NaN Biking 68 bob 1984 3 Dancing 83 charles 1992 0 NaN 112 <p>Instead of an <code>ndarray</code>, you can also pass a <code>DataFrame</code> object:</p> <pre><code>d4 = pd.DataFrame(\n         d3,\n         columns=[\"hobby\", \"children\"],\n         index=[\"alice\", \"bob\"]\n     )\nd4\n</code></pre> Output hobby children alice Biking NaN bob Dancing 3 <p>It is also possible to create a <code>DataFrame</code> with a dictionary (or list) of dictionaries (or list):</p> <pre><code>people = pd.DataFrame({\n    \"birthyear\": {\"alice\":1985, \"bob\": 1984, \"charles\": 1992},\n    \"hobby\": {\"alice\":\"Biking\", \"bob\": \"Dancing\"},\n    \"weight\": {\"alice\":68, \"bob\": 83, \"charles\": 112},\n    \"children\": {\"bob\": 3, \"charles\": 0}\n})\npeople\n</code></pre> Output birthyear children hobby weight alice 1985 NaN Biking 68 bob 1984 3.0 Dancing 83 charles 1992 0.0 NaN 112"},{"location":"Tutorials/Libraries/pandas/#multi-indexing","title":"Multi-indexing","text":"<p>If all columns are tuples of the same size, then they are understood as a multi-index. The same goes for row index labels. For example:</p> <pre><code>d5 = pd.DataFrame(\n  {\n    (\"public\", \"birthyear\"):\n        {(\"Paris\",\"alice\"):1985, (\"Paris\",\"bob\"): 1984, (\"London\",\"charles\"): 1992},\n    (\"public\", \"hobby\"):\n        {(\"Paris\",\"alice\"):\"Biking\", (\"Paris\",\"bob\"): \"Dancing\"},\n    (\"private\", \"weight\"):\n        {(\"Paris\",\"alice\"):68, (\"Paris\",\"bob\"): 83, (\"London\",\"charles\"): 112},\n    (\"private\", \"children\"):\n        {(\"Paris\", \"alice\"):np.nan, (\"Paris\",\"bob\"): 3, (\"London\",\"charles\"): 0}\n  }\n)\nd5\n</code></pre> <p>You can now get a <code>DataFrame</code> containing all the <code>\"public\"</code> columns very simply:</p> <pre><code>d5[\"public\"]\n</code></pre> <pre><code>d5[\"public\", \"hobby\"]  # Same result as d5[\"public\"][\"hobby\"]\n</code></pre> Output <pre><code>London  charles        NaN\nParis   alice       Biking\n        bob        Dancing\nName: (public, hobby), dtype: object\n</code></pre>"},{"location":"Tutorials/Libraries/pandas/#dropping-a-level","title":"Dropping a level","text":"<p>Let's look at <code>d5</code> again:</p> <pre><code>d5\n</code></pre> <p>There are two levels of columns, and two levels of indices. We can drop a column level by calling <code>droplevel()</code> (the same goes for indices):</p> <pre><code>d5.columns = d5.columns.droplevel(level = 0)\nd5\n</code></pre>"},{"location":"Tutorials/Libraries/pandas/#transposing","title":"Transposing","text":"<p>You can swap columns and indices using the <code>T</code> attribute:</p> <pre><code>d6 = d5.T\nd6\n</code></pre>"},{"location":"Tutorials/Libraries/pandas/#stacking-and-unstacking-levels","title":"Stacking and unstacking levels","text":"<p>Calling the <code>stack()</code> method will push the lowest column level after the lowest index:</p> <pre><code>d7 = d6.stack()\nd7\n</code></pre> <p>Note that many <code>NaN</code> values appeared. This makes sense because many new combinations did not exist before (eg. there was no <code>bob</code> in <code>London</code>).</p> <p>Calling <code>unstack()</code> will do the reverse, once again creating many <code>NaN</code> values.</p> <pre><code>d8 = d7.unstack()\nd8\n</code></pre> <p>If we call <code>unstack</code> again, we end up with a <code>Series</code> object:</p> <pre><code>d9 = d8.unstack()\nd9\n</code></pre> Output <pre><code>London  alice    children        None\n                weight           NaN\n                birthyear        NaN\n                hobby            NaN\n        bob      children         NaN\n                weight           NaN\n                birthyear        NaN\n                hobby            NaN\n        charles  children           0\n                weight           112\n                birthyear       1992\n                hobby           None\nParis   alice    children        None\n                weight            68\n                birthyear       1985\n                hobby         Biking\n        bob      children           3\n                weight            83\n                birthyear       1984\n                hobby        Dancing\n        charles  children         NaN\n                weight           NaN\n                birthyear        NaN\n                hobby           None\ndtype: object\n</code></pre> <p>The <code>stack()</code> and <code>unstack()</code> methods let you select the <code>level</code> to stack/unstack. You can even stack/unstack multiple levels at once:</p> <pre><code>d10 = d9.unstack(level = (0,1))\nd10\n</code></pre>"},{"location":"Tutorials/Libraries/pandas/#most-methods-return-modified-copies","title":"Most methods return modified copies","text":"<p>As you may have noticed, the <code>stack()</code> and <code>unstack()</code> methods do not modify the object they apply to. Instead, they work on a copy and return that copy. This is true of most methods in pandas.</p>"},{"location":"Tutorials/Libraries/pandas/#accessing-rows","title":"Accessing rows","text":"<p>Let's go back to the <code>people</code> <code>DataFrame</code>:</p> <pre><code>people\n</code></pre> Output birthyear children hobby weight alice 1985 NaN Biking 68 bob 1984 3.0 Dancing 83 charles 1992 0.0 NaN 112 <p>The <code>loc</code> attribute lets you access rows instead of columns. The result is a <code>Series</code> object in which the <code>DataFrame</code>'s column names are mapped to row index labels:</p> <pre><code>people.loc[\"charles\"]\n</code></pre> Output <pre><code>birthyear    1992\nchildren        0\nhobby         NaN\nweight        112\nName: charles, dtype: object\n</code></pre> <p>You can also access rows by integer location using the <code>iloc</code> attribute:</p> <pre><code>people.iloc[2]\n</code></pre> Output <pre><code>birthyear    1992\nchildren        0\nhobby         NaN\nweight        112\nName: charles, dtype: object\n</code></pre> <p>You can also get a slice of rows, and this returns a <code>DataFrame</code> object:</p> <pre><code>people.iloc[1:3]\n</code></pre> Output birthyear children hobby weight bob 1984 3.0 Dancing 83 charles 1992 0.0 NaN 112 <p>Finally, you can pass a boolean array to get the matching rows:</p> <pre><code>people[np.array([True, False, True])]\n</code></pre> Output birthyear children hobby weight alice 1985 NaN Biking 68 charles 1992 0.0 NaN 112 <p>This is most useful when combined with boolean expressions:</p> <pre><code>people[people[\"birthyear\"] &lt; 1990]\n</code></pre> Output birthyear children hobby weight alice 1985 NaN Biking 68 bob 1984 3.0 Dancing 83"},{"location":"Tutorials/Libraries/pandas/#adding-and-removing-columns","title":"Adding and removing columns","text":"<p>You can generally treat <code>DataFrame</code> objects like dictionaries of <code>Series</code>, so the following work fine:</p> <pre><code>people\n</code></pre> Output birthyear children hobby weight alice 1985 NaN Biking 68 bob 1984 3.0 Dancing 83 charles 1992 0.0 NaN 112 <pre><code>people[\"age\"] = 2018 - people[\"birthyear\"]  # adds a new column \"age\"\npeople[\"over 30\"] = people[\"age\"] &gt; 30      # adds another column \"over 30\"\nbirthyears = people.pop(\"birthyear\")\ndel people[\"children\"]\n\npeople\n</code></pre> Output hobby weight age over 30 alice Biking 68 33 True bob Dancing 83 34 True charles NaN 112 26 False <pre><code>birthyears\n</code></pre> Output <pre><code>alice      1985\nbob        1984\ncharles    1992\nName: birthyear, dtype: int64\n</code></pre> <p>When you add a new colum, it must have the same number of rows. Missing rows are filled with NaN, and extra rows are ignored:</p> <pre><code>people[\"pets\"] = pd.Series({\"bob\": 0, \"charles\": 5, \"eugene\":1})  # alice is missing, eugene is ignored\npeople\n</code></pre> Output hobby weight age over 30 pets alice Biking 68 33 True NaN bob Dancing 83 34 True 0.0 charles NaN 112 26 False 5.0 <p>When adding a new column, it is added at the end (on the right) by default. You can also insert a column anywhere else using the <code>insert()</code> method:</p> <pre><code>people.insert(1, \"height\", [172, 181, 185])\npeople\n</code></pre> Output hobby height weight age over 30 pets alice Biking 172 68 33 True NaN bob Dancing 181 83 34 True 0.0 charles NaN 185 112 26 False 5.0"},{"location":"Tutorials/Libraries/pandas/#assigning-new-columns","title":"Assigning new columns","text":"<p>You can also create new columns by calling the <code>assign()</code> method. Note that this returns a new <code>DataFrame</code> object, the original is not modified:</p> <p><pre><code>people.assign(\n    body_mass_index = people[\"weight\"] / (people[\"height\"] / 100) ** 2,\n    has_pets = people[\"pets\"] &gt; 0\n)\n</code></pre> Note that you cannot access columns created within the same assignment:</p> <pre><code>try:\n    people.assign(\n        body_mass_index = people[\"weight\"] / (people[\"height\"] / 100) ** 2,\n        overweight = people[\"body_mass_index\"] &gt; 25\n    )\nexcept KeyError as e:\n    print(\"Key error:\", e)\n</code></pre> Output <p>Key error: 'body_mass_index'</p> <p>The solution is to split this assignment in two consecutive assignments:</p> <pre><code>d6 = people.assign(body_mass_index = people[\"weight\"] / (people[\"height\"] / 100) ** 2)\nd6.assign(overweight = d6[\"body_mass_index\"] &gt; 25)\n</code></pre> <p>Having to create a temporary variable <code>d6</code> is not very convenient. You may want to just chain the assigment calls, but it does not work because the <code>people</code> object is not actually modified by the first assignment:</p> <pre><code>try:\n    (people\n         .assign(body_mass_index = people[\"weight\"] / (people[\"height\"] / 100) ** 2)\n         .assign(overweight = people[\"body_mass_index\"] &gt; 25)\n    )\nexcept KeyError as e:\n    print(\"Key error:\", e)\n</code></pre> Output <p>Key error: 'body_mass_index'</p> <p>But fear not, there is a simple solution. You can pass a function to the <code>assign()</code> method (typically a <code>lambda</code> function), and this function will be called with the <code>DataFrame</code> as a parameter:</p> <pre><code>(people\n     .assign(body_mass_index = lambda df: df[\"weight\"] / (df[\"height\"] / 100) ** 2)\n     .assign(overweight = lambda df: df[\"body_mass_index\"] &gt; 25)\n)\n</code></pre> <p>Problem solved!</p>"},{"location":"Tutorials/Libraries/pandas/#evaluating-an-expression","title":"Evaluating an expression","text":"<p>A great feature supported by pandas is expression evaluation. This relies on the <code>numexpr</code> library which must be installed.</p> <pre><code>people.eval(\"weight / (height/100) ** 2 &gt; 25\")\n</code></pre> Output <pre><code>alice      False\nbob         True\ncharles     True\ndtype: bool\n</code></pre> <p>Assignment expressions are also supported. Let's set <code>inplace=True</code> to directly modify the <code>DataFrame</code> rather than getting a modified copy:</p> <pre><code>people.eval(\"body_mass_index = weight / (height/100) ** 2\", inplace=True)\npeople\n</code></pre> <p>You can use a local or global variable in an expression by prefixing it with <code>'@'</code>:</p> <pre><code>overweight_threshold = 30\npeople.eval(\"overweight = body_mass_index &gt; @overweight_threshold\", inplace=True)\npeople\n</code></pre>"},{"location":"Tutorials/Libraries/pandas/#querying-a-dataframe","title":"Querying a DataFrame","text":"<p>The <code>query()</code> method lets you filter a <code>DataFrame</code> based on a query expression:</p> <pre><code>people.query(\"age &gt; 30 and pets == 0\")\n</code></pre>"},{"location":"Tutorials/Libraries/pandas/#sorting-a-dataframe","title":"Sorting a DataFrame","text":"<p>You can sort a <code>DataFrame</code> by calling its <code>sort_index</code> method. By default it sorts the rows by their index label, in ascending order, but let's reverse the order:</p> <pre><code>people.sort_index(ascending=False)\n</code></pre> <p>Note that <code>sort_index</code> returned a sorted copy of the <code>DataFrame</code>. To modify <code>people</code> directly, we can set the <code>inplace</code> argument to <code>True</code>. Also, we can sort the columns instead of the rows by setting <code>axis=1</code>:</p> <pre><code>people.sort_index(axis=1, inplace=True)\npeople\n</code></pre> <p>To sort the <code>DataFrame</code> by the values instead of the labels, we can use <code>sort_values</code> and specify the column to sort by:</p> <pre><code>people.sort_values(by=\"age\", inplace=True)\npeople\n</code></pre>"},{"location":"Tutorials/Libraries/pandas/#plotting-a-dataframe","title":"Plotting a DataFrame","text":"<p>Just like for <code>Series</code>, pandas makes it easy to draw nice graphs based on a <code>DataFrame</code>.</p> <p>For example, it is trivial to create a line plot from a <code>DataFrame</code>'s data by calling its <code>plot</code> method:</p> <pre><code>people.plot(kind = \"line\", x = \"body_mass_index\", y = [\"height\", \"weight\"])\nplt.show()\n</code></pre> Output <p></p> <p>You can pass extra arguments supported by matplotlib's functions. For example, we can create scatterplot and pass it a list of sizes using the <code>s</code> argument of matplotlib's <code>scatter()</code> function:</p> <pre><code>people.plot(kind = \"scatter\", x = \"height\", y = \"weight\", s=[40, 120, 200])\nplt.show()\n</code></pre> Output <p></p> <p>Again, there are way too many options to list here: the best option is to scroll through the Visualization page in pandas' documentation, find the plot you are interested in and look at the example code.</p>"},{"location":"Tutorials/Natural%20Language%20Processing/","title":"Natural Language Processing","text":""},{"location":"Tutorials/Natural%20Language%20Processing/#what-is-nlp","title":"What is NLP?","text":"<p>Natural Language Processing (NLP) is a field of artificial intelligence (AI) that focuses on the interaction between computers and humans using natural language. The goal is to enable machines to understand, interpret, and generate human language in a way that is both meaningful and contextually relevant. NLP involves a wide range of tasks, including language understanding, language generation, machine translation, sentiment analysis, and more.</p>"},{"location":"Tutorials/Natural%20Language%20Processing/#history-of-nlp","title":"History of NLP","text":"<p>The history of NLP can be traced back to the 1950s when researchers began exploring the possibilities of teaching computers to understand and process human language. One of the earliest and notable milestones in NLP was the development of the Georgetown-IBM Experiment in 1954, which involved automatic translation of Russian sentences into English. Over the decades, NLP has evolved significantly, with breakthroughs in algorithms, increased computing power, and the availability of large datasets contributing to its rapid advancement.</p>"},{"location":"Tutorials/Natural%20Language%20Processing/#challenges","title":"Challenges","text":"<p>Despite its progress, NLP faces several challenges. Ambiguity, context sensitivity, and the vast diversity of languages and expressions make it challenging to create models that can accurately comprehend and generate natural language. Handling nuances, understanding context, and adapting to various communication styles are ongoing challenges in the field. Additionally, ethical considerations related to bias in language models and privacy concerns are areas that researchers and practitioners actively address.</p>"},{"location":"Tutorials/Natural%20Language%20Processing/#applications","title":"Applications","text":"<p>NLP has found applications in various industries and domains. Some common applications include:</p> <p>\ud83d\udd39 Machine Translation: NLP is used for translating text from one language to another, facilitating cross-language communication.</p> <p>\ud83d\udd39 Sentiment Analysis: Businesses use NLP to analyze and understand customer sentiments expressed in reviews, social media, and other textual data.</p> <p>\ud83d\udd39 Chatbots and Virtual Assistants: NLP powers the natural language understanding and generation capabilities of chatbots and virtual assistants, enhancing human-computer interactions.</p> <p>\ud83d\udd39 Information Extraction: NLP is employed to extract structured information from unstructured text, such as extracting named entities or key facts from documents.</p> <p>\ud83d\udd39 Text Summarization: NLP techniques are applied to automatically generate concise and coherent summaries of longer texts.</p> <p>This tutorial will explore these aspects of NLP in more detail, providing insights into the underlying principles, challenges faced, and practical applications that make NLP a crucial component of modern artificial intelligence.</p>"},{"location":"Tutorials/Natural%20Language%20Processing/advanced/","title":"Advanced","text":""},{"location":"Tutorials/Natural%20Language%20Processing/advanced/#text-classification","title":"Text Classification","text":""},{"location":"Tutorials/Natural%20Language%20Processing/advanced/#text-clustering","title":"Text Clustering","text":""},{"location":"Tutorials/Natural%20Language%20Processing/advanced/#latent-dirichlet-allocation-lda","title":"Latent Dirichlet Allocation (LDA)","text":""},{"location":"Tutorials/Natural%20Language%20Processing/advanced/#non-negative-matrix-factorization-nmf","title":"Non-Negative Matrix Factorization (NMF)","text":""},{"location":"Tutorials/Natural%20Language%20Processing/advanced/#glove","title":"GloVe","text":""},{"location":"Tutorials/Natural%20Language%20Processing/advanced/#lexicons","title":"Lexicons","text":""},{"location":"Tutorials/Natural%20Language%20Processing/advanced/#ngrams","title":"NGrams","text":""},{"location":"Tutorials/Natural%20Language%20Processing/advanced/#langague-modeling","title":"Langague Modeling","text":""},{"location":"Tutorials/Natural%20Language%20Processing/advanced/#text-generation","title":"Text Generation","text":""},{"location":"Tutorials/Natural%20Language%20Processing/advanced/#sentimental-analysis","title":"Sentimental Analysis","text":""},{"location":"Tutorials/Natural%20Language%20Processing/advanced/#naive-bayes","title":"Na\u00efve Bayes","text":""},{"location":"Tutorials/Natural%20Language%20Processing/advanced/#vader","title":"Vader","text":""},{"location":"Tutorials/Natural%20Language%20Processing/advanced/#auto-correct","title":"Auto Correct","text":""},{"location":"Tutorials/Natural%20Language%20Processing/advanced/#answering-questions","title":"Answering Questions","text":""},{"location":"Tutorials/Natural%20Language%20Processing/advanced/#summarization","title":"Summarization","text":""},{"location":"Tutorials/Natural%20Language%20Processing/bases/","title":"Bases of NLP","text":""},{"location":"Tutorials/Natural%20Language%20Processing/bases/#libraries","title":"Libraries","text":""},{"location":"Tutorials/Natural%20Language%20Processing/bases/#nltk","title":"nltk","text":"<p>The Natural Language Toolkit (<code>NLTK</code>) is a comprehensive library for working with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources, making it a valuable tool for various NLP tasks.</p> <pre><code># Install NLTK\npip install nltk\n\n# Import NLTK\nimport nltk\n\n# Download NLTK data\nnltk.download('punkt')\n</code></pre>"},{"location":"Tutorials/Natural%20Language%20Processing/bases/#spacy","title":"spacy","text":"<p>SpaCy is an open-source library designed specifically for Natural Language Processing. It offers pre-trained models for various languages and supports tasks like tokenization, part-of-speech tagging, named entity recognition, and more.</p> <pre><code># Install SpaCy\npip install spacy\n\n# Download SpaCy model for English\npython -m spacy download en\n</code></pre>"},{"location":"Tutorials/Natural%20Language%20Processing/bases/#re-regular-expressions","title":"re (Regular Expressions)","text":"<p>The <code>re</code> library in Python is a powerful tool for working with regular expressions. Regular expressions enable flexible and sophisticated pattern matching in text, making it easier to extract or manipulate specific information.</p> <pre><code>import re\n\n# Sample text\ntext = \"Natural Language Processing is fascinating. NLP opens up a world of possibilities.\"\n\n# Define a pattern to search for\npattern = re.compile(r'\\bNLP\\b')\n\n# Search for the pattern in the text\nmatches = pattern.findall(text)\n\n# Print the matches\nprint(matches)\n</code></pre>"},{"location":"Tutorials/Natural%20Language%20Processing/bases/#gensim","title":"gensim","text":"<p><code>Gensim</code> is a library for topic modeling and document similarity analysis. It is particularly useful for tasks like document similarity comparison and topic modeling using techniques like Latent Semantic Analysis.</p> <pre><code># Install Gensim\npip install gensim\n</code></pre>"},{"location":"Tutorials/Natural%20Language%20Processing/bases/#fasttext","title":"fasttext","text":"<p><code>FastText</code> is an open-source, free, lightweight library that allows users to learn text representations and perform text classification tasks efficiently. It is an extension of the Word2Vec model.</p> <pre><code># Install FastText\npip install fasttext\n</code></pre>"},{"location":"Tutorials/Natural%20Language%20Processing/bases/#reading-text","title":"Reading Text","text":""},{"location":"Tutorials/Natural%20Language%20Processing/bases/#txt-files","title":"txt files","text":"<p>This section provides code examples for reading and manipulating text data stored in plain text (txt) files. It covers operations such as reading, writing, and appending text, as well as working with files containing different languages, including Arabic.</p> <pre><code># Writing to a text file\n%%writefile text1.txt \nbla bla bla bla bla bla bla\n\n# Reading from a text file\nmy_file = open('test.txt')\ncontent = my_file.read()\nmy_file.seek(0)\nlines = my_file.readlines()\nmy_file.close()\n\n# Appending to a text file\nwith open('test.txt','a+') as my_file:\n    my_file.write('\\nThis line is being appended to test.txt')\n\n# Appending with magic command\n%%writefile -a test.txt \nThis is more text being appended to test.txt \nAnd another line here.\n\n# Reading the first line from a text file\nwith open('test.txt','r') as txt: \n    first_line = txt.readlines()[0] \nprint(first_line)\n\n# Reading the first line with context manager\nwith open('test.txt','r') as txt: \n    first_line = txt.readlines()[0] \nprint(first_line)\n</code></pre>"},{"location":"Tutorials/Natural%20Language%20Processing/bases/#csv-files","title":"csv files","text":"<p>For handling structured data, particularly in tabular form, this section demonstrates reading from and writing to CSV files. Additionally, it showcases reading data from an Excel file using the Pandas library.</p> <pre><code># Reading the first line from a CSV file\nwith open('test.txt','r') as txt: \n    first_line = txt.readlines()[0] \nprint(first_line)\n\n# Reading data from an Excel file\ndata = pd.read_excel('02.xlsx')# , skiprows = 2) \ndata.head()\n\n# Writing to a CSV file\noutfile = open('03.csv', 'w') \noutfile.write('a') \noutfile.close()\n\n# Writing to an Excel file\noutfile = open('04.xls', 'w') \noutfile.write('a') \noutfile.close()\n\n# Writing to a text file\nf= open('5.txt','w') #write \nf.write('write this line in the file') \nf.close()\n\n# Reading from a text file\nf= open('5.txt','r') #read \nfor a in f: \n    print(a)\n\n# Appending to a text file\nf= open('5.txt','a') #append \nf.write('\\nmore lines') \nf.close()\n\n# Writing to a CSV file using pandas\nimport numpy as np \ndata = pd.DataFrame(pd.Series(np.random.rand(10000))) \ndata.head(20) \ndata.to_csv('6.csv')\n\n# Writing to a text file with Arabic text\n# to use arabic, encoding=\"utf8\"\nf= open('7.txt','w', encoding=\"utf8\") \nf.write('\u0633\u0637\u0648\u0631 \u0628\u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629')\nf.close() \n\n# Appending to a text file with Arabic text\nf= open('7.txt','a', encoding=\"utf8\") \nf.write('\\n\u062b\u0627\u0646\u064a \u0633\u0637\u0631 ')\nf.write('\\n\u062b\u0627\u0644\u062b \u0633\u0637\u0631 ')\nf.write('\\n\u0631\u0627\u0628\u0639 \u0633\u0637\u0631 ')\nf.write('\\n\u0623\u062e\u064a\u0631 \u0633\u0637\u0631 ')\nf.close()\n\n# Reading from a text file with Arabic text\nf= open('7.txt','r', encoding=\"utf8\") \nfor a in f: \n    print(a)\n</code></pre>"},{"location":"Tutorials/Natural%20Language%20Processing/bases/#handling-pdf","title":"Handling PDF","text":"<p><code>PyPDF2</code> is a Python library for reading and manipulating PDF files. This section covers basic operations like reading text from a PDF file, extracting text from specific pages, and merging PDF files.</p> <pre><code># Install PyPDF2\npip install PyPDF2\n\nimport PyPDF2\n\n# Reading text from a PDF file\nf= open('US_Declaration.pdf','rb')\npdf_reader = PyPDF2.PdfFileReader(f)\n\nnum_pages = pdf_reader.numPages\n\npage_one = pdf_reader.getPage(0)\npage_one_text = page_one.extractText()\nprint(page_one_text)\n\n# Reading text from all pages of a PDF file\nf = open('US_Declaration.pdf','rb')\npdf_text = [0]\npdf_reader = PyPDF2.PdfFileReader(f)\nfor p in range(pdf_reader.numPages):\n    page = pdf_reader.getPage(p)\n    pdf_text.append(page.extractText())\nf.close()\nprint(pdf_text)\n\n# Merging PDF files\nf = open('US_Declaration.pdf','rb')\npdf_reader = PyPDF2.PdfFileReader(f)\nfirst_page = pdf_reader.getPage(0)\n\npdf_writer = PyPDF2.PdfFileWriter()\n\npdf_writer.addPage(first_page)\n</code></pre>"},{"location":"Tutorials/Natural%20Language%20Processing/bases/#search-in-text","title":"Search in Text","text":"<p>This section revisits the <code>re</code> library, demonstrating its application for searching specific patterns or keywords within text. Regular expressions are powerful tools for identifying and extracting information based on predefined patterns.</p> <pre><code># Searching for a pattern in text\nimport re\n\n# Sample text\ntext = \"Natural Language Processing is fascinating. NLP opens up a world of possibilities.\"\n\n# Define a pattern to search for\npattern = re.compile(r'\\bNLP\\b')\n\n# Search for the pattern in the text\nmatches = pattern.findall(text)\n\n# Print the matches\nprint(matches)\n</code></pre>"},{"location":"Tutorials/Natural%20Language%20Processing/collection/","title":"Collection","text":""},{"location":"Tutorials/Natural%20Language%20Processing/collection/#tweet-collecting","title":"Tweet Collecting","text":""},{"location":"Tutorials/Natural%20Language%20Processing/collection/#data-scraping","title":"Data Scraping","text":""},{"location":"Tutorials/Natural%20Language%20Processing/collection/#information-extraction","title":"Information Extraction","text":""},{"location":"Tutorials/Natural%20Language%20Processing/collection/#information-retrieval","title":"Information Retrieval","text":""},{"location":"Tutorials/Natural%20Language%20Processing/collection/#relative-extraction","title":"Relative Extraction","text":""},{"location":"Tutorials/Natural%20Language%20Processing/collection/#search-engine","title":"Search Engine","text":""},{"location":"Tutorials/Natural%20Language%20Processing/modern/","title":"Modern","text":""},{"location":"Tutorials/Natural%20Language%20Processing/modern/#teacher-forcing","title":"Teacher Forcing","text":""},{"location":"Tutorials/Natural%20Language%20Processing/modern/#attention-models","title":"Attention Models","text":""},{"location":"Tutorials/Natural%20Language%20Processing/modern/#hugging-face","title":"Hugging Face","text":""},{"location":"Tutorials/Natural%20Language%20Processing/modern/#bert","title":"Bert","text":""},{"location":"Tutorials/Natural%20Language%20Processing/modern/#fasttext","title":"FastText","text":""},{"location":"Tutorials/Natural%20Language%20Processing/modern/#gensim","title":"Gensim","text":""},{"location":"Tutorials/Natural%20Language%20Processing/modern/#chatbot","title":"Chatbot","text":""},{"location":"Tutorials/Natural%20Language%20Processing/modern/#translation","title":"Translation","text":""},{"location":"Tutorials/Natural%20Language%20Processing/reseaunn/","title":"Reseaunn","text":""},{"location":"Tutorials/Natural%20Language%20Processing/reseaunn/#rnn","title":"RNN","text":""},{"location":"Tutorials/Natural%20Language%20Processing/reseaunn/#lstm","title":"LSTM","text":""},{"location":"Tutorials/Natural%20Language%20Processing/reseaunn/#gru","title":"GRU","text":""},{"location":"Tutorials/Natural%20Language%20Processing/reseaunn/#tnn","title":"TNN","text":""},{"location":"Tutorials/Natural%20Language%20Processing/reseaunn/#cnn","title":"CNN","text":""},{"location":"Tutorials/Natural%20Language%20Processing/simple/","title":"Simple","text":""},{"location":"Tutorials/Natural%20Language%20Processing/simple/#word-meaning","title":"Word Meaning","text":""},{"location":"Tutorials/Natural%20Language%20Processing/simple/#word-embedding","title":"Word Embedding","text":""},{"location":"Tutorials/Natural%20Language%20Processing/simple/#text-vectors","title":"Text Vectors","text":""},{"location":"Tutorials/Natural%20Language%20Processing/simple/#word2vec","title":"Word2Vec","text":""},{"location":"Tutorials/Natural%20Language%20Processing/simple/#bag-of-words-bow","title":"Bag Of Words (BOW)","text":""},{"location":"Tutorials/Natural%20Language%20Processing/simple/#tf-idf","title":"TF-IDF","text":""},{"location":"Tutorials/Natural%20Language%20Processing/simple/#text-similarity","title":"Text Similarity","text":""},{"location":"Tutorials/Natural%20Language%20Processing/simple/#distributional-similarity","title":"Distributional Similarity","text":""},{"location":"Tutorials/Natural%20Language%20Processing/tools/","title":"Tools","text":""},{"location":"Tutorials/Natural%20Language%20Processing/tools/#tokenization","title":"Tokenization","text":""},{"location":"Tutorials/Natural%20Language%20Processing/tools/#sentence-segmentation","title":"Sentence Segmentation","text":""},{"location":"Tutorials/Natural%20Language%20Processing/tools/#part-of-speech-pos","title":"Part of Speech (POS)","text":""},{"location":"Tutorials/Natural%20Language%20Processing/tools/#stemming-lemmatization","title":"Stemming &amp; Lemmatization","text":""},{"location":"Tutorials/Natural%20Language%20Processing/tools/#named-entity-recognition-ner","title":"Named-Entity Recognition (NER)","text":""},{"location":"Tutorials/Natural%20Language%20Processing/tools/#stopwords","title":"Stopwords","text":""},{"location":"Tutorials/Natural%20Language%20Processing/tools/#matchers","title":"Matchers","text":""},{"location":"Tutorials/Natural%20Language%20Processing/tools/#syntactic-structure","title":"Syntactic Structure","text":""},{"location":"Tutorials/Natural%20Language%20Processing/tools/#text-visualization","title":"Text Visualization","text":""},{"location":"blogs/Data%20Pipelines/","title":"Welcome to \"\ud835\udc0f\ud835\udc22\ud835\udc29\ud835\udc1e\ud835\udc25\ud835\udc22\ud835\udc27\ud835\udc1e \ud835\udc0c\ud835\udc1a\ud835\udc2c\ud835\udc2d\ud835\udc1e\ud835\udc2b\ud835\udc32 \ud835\udc12\ud835\udc1e\ud835\udc2b\ud835\udc22\ud835\udc1e\ud835\udc2c\"","text":"<p>Data pipelines play a crucial role in modern data architecture, facilitating the efficient flow and processing of data. Let's explore different types of data pipelines and provide a real example for each:</p> <ul> <li> <p> Batch Processing Data Pipeline</p> <p>Description: Batch processing involves collecting, processing, and storing data in predefined intervals.</p> </li> </ul> <ul> <li> <p> Real-Time Streaming Data Pipeline</p> <p>Description: Real-time pipelines process data as it arrives, allowing for near-instantaneous insights.</p> </li> </ul> <ul> <li> <p> Cloud-Based Data Pipeline</p> <p>Description: Cloud-based pipelines leverage cloud services to process and store data, providing scalability and flexibility.</p> </li> </ul> <ul> <li> <p> Machine Learning Data Pipeline</p> <p>Description: ML pipelines integrate machine learning models into data workflows for training, deployment, and monitoring.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/batch_processing/","title":"Building a Robust Batch Processing Data Pipeline: A Comprehensive Guide","text":"<p>In the dynamic landscape of data engineering, Batch Processing Data Pipelines play a pivotal role in efficiently handling large volumes of data. These pipelines are fundamental for organizations that require periodic processing and analysis of data, ensuring insights are derived in a systematic and timely manner. In this comprehensive guide, we will delve into the key steps and considerations for implementing a robust Batch Processing Data Pipeline.</p>"},{"location":"blogs/Data%20Pipelines/batch_processing/#understanding-batch-processing-data-pipelines","title":"Understanding Batch Processing Data Pipelines","text":""},{"location":"blogs/Data%20Pipelines/batch_processing/#what-is-a-batch-processing-data-pipeline","title":"What is a Batch Processing Data Pipeline?","text":"<p>A Batch Processing Data Pipeline is a structured and periodic approach to collecting, processing, and analyzing data in predefined intervals. Unlike real-time processing, which handles data on-the-fly, batch processing occurs at scheduled intervals, making it suitable for scenarios where near-instantaneous insights are not required.</p>"},{"location":"blogs/Data%20Pipelines/batch_processing/#why-batch-processing","title":"Why Batch Processing?","text":"<ul> <li> <p>Scalability: Batch processing is well-suited for handling large volumes of data, providing scalability by processing data in chunks.</p> </li> <li> <p>Resource Optimization: Since batch jobs can be scheduled during off-peak hours, resource utilization can be optimized, avoiding contention for resources during peak times.</p> </li> <li> <p>Data Consistency: Batch processing ensures data consistency by processing data in sets, reducing the likelihood of discrepancies compared to real-time processing.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/batch_processing/#steps-to-implement-a-batch-processing-data-pipeline","title":"Steps to Implement a Batch Processing Data Pipeline","text":""},{"location":"blogs/Data%20Pipelines/batch_processing/#1-define-objectives-and-requirements","title":"1. Define Objectives and Requirements:","text":"<ul> <li> <p>Clearly outline the goals of your batch processing pipeline.</p> </li> <li> <p>Identify the data sources, processing requirements, and the desired output.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/batch_processing/#2-data-extraction","title":"2. Data Extraction:","text":"<ul> <li> <p>Identify the sources of data, which can include databases, APIs, flat files, or other repositories.</p> </li> <li> <p>Extract the relevant data needed for processing.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/batch_processing/#3-data-transformation","title":"3. Data Transformation:","text":"<ul> <li> <p>Cleanse and transform the raw data into a format suitable for analysis.</p> </li> <li> <p>Apply business rules, aggregations, or any necessary transformations.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/batch_processing/#4-data-loading","title":"4. Data Loading:","text":"<ul> <li> <p>Choose an appropriate data storage solution (e.g., data warehouse) for storing processed data.</p> </li> <li> <p>Load the transformed data into the storage system.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/batch_processing/#5-job-scheduling","title":"5. Job Scheduling:","text":"<ul> <li> <p>Implement a scheduling mechanism to define when the batch job should run.</p> </li> <li> <p>Consider dependencies between different batch jobs to ensure a coherent workflow.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/batch_processing/#6-error-handling-and-logging","title":"6. Error Handling and Logging:","text":"<ul> <li> <p>Incorporate mechanisms for error handling to identify and address issues during processing.</p> </li> <li> <p>Implement comprehensive logging to facilitate troubleshooting and auditing.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/batch_processing/#7-monitoring-and-performance-optimization","title":"7. Monitoring and Performance Optimization:","text":"<ul> <li> <p>Set up monitoring tools to track the performance of your batch processing pipeline.</p> </li> <li> <p>Optimize the pipeline for efficiency, considering factors such as parallel processing and data partitioning.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/batch_processing/#8-dependency-management","title":"8. Dependency Management:","text":"<ul> <li> <p>Define dependencies between different stages of the pipeline to ensure the correct order of execution.</p> </li> <li> <p>Handle inter-job dependencies carefully to prevent data inconsistencies.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/batch_processing/#9-testing","title":"9. Testing:","text":"<ul> <li> <p>Conduct thorough testing of the entire pipeline, including unit tests for individual components and end-to-end testing of the complete workflow.</p> </li> <li> <p>Validate the accuracy of results against expected outcomes.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/batch_processing/#10-documentation","title":"10. Documentation:","text":"<ul> <li> <p>Document the entire pipeline, including the workflow, dependencies, and any configurations.</p> </li> <li> <p>Ensure that the documentation is kept up-to-date as changes are made.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/batch_processing/#real-world-example-etl-pipeline-with-apache-airflow","title":"Real-World Example: ETL Pipeline with Apache Airflow","text":"<p>Let's walk through a real-world example of implementing a Batch Processing Data Pipeline using Apache Airflow, a popular open-source platform for orchestrating complex workflows.</p>"},{"location":"blogs/Data%20Pipelines/batch_processing/#scenario","title":"Scenario:","text":"<p>We want to analyze customer data from a CRM system on a daily basis to derive insights for marketing campaigns.</p>"},{"location":"blogs/Data%20Pipelines/batch_processing/#apache-airflow-dag-directed-acyclic-graph","title":"Apache Airflow DAG (Directed Acyclic Graph):","text":"<ol> <li> <p>Define the DAG:</p> <ul> <li>Create a Python script defining the DAG structure.</li> </ul> <pre><code>from airflow import DAG\nfrom datetime import datetime, timedelta\nfrom airflow.operators.python_operator import PythonOperator\n\ndefault_args = {\n    'owner': 'data_engineer',\n    'start_date': datetime(2023, 1, 1),\n    'retries': 1,\n    'retry_delay': timedelta(minutes=5),\n}\n\ndag = DAG(\n    'customer_data_analysis',\n    default_args=default_args,\n    schedule_interval=timedelta(days=1),\n)\n</code></pre> </li> <li> <p>Define Tasks:</p> <ul> <li>Create Python functions for each processing step.</li> </ul> <pre><code>def extract_data():\n# Code for extracting data from CRM system\n\ndef transform_data():\n    # Code for cleansing and transforming data\n\ndef load_data():\n    # Code for loading data into the data warehouse\n</code></pre> </li> <li> <p>Define Task Dependencies:</p> <ul> <li>Set up dependencies between tasks.</li> </ul> <pre><code>extract_task = PythonOperator(\n    task_id='extract_task',\n    python_callable=extract_data,\n    dag=dag,\n)\n\ntransform_task = PythonOperator(\n    task_id='transform_task',\n    python_callable=transform_data,\n    dag=dag,\n)\n\nload_task = PythonOperator(\n    task_id='load_task',\n    python_callable=load_data,\n    dag=dag,\n)\n\nextract_task &gt;&gt; transform_task &gt;&gt; load_task\n</code></pre> </li> <li> <p>Execute the Pipeline:</p> <ul> <li>Start the Airflow scheduler to execute the pipeline according to the defined schedule.</li> </ul> </li> </ol>"},{"location":"blogs/Data%20Pipelines/batch_processing/#conclusion","title":"Conclusion","text":"<p>Implementing a Batch Processing Data Pipeline involves careful planning, execution, and continuous monitoring. Whether you're dealing with large-scale data warehousing or analyzing business metrics, a well-designed batch processing pipeline ensures reliable, consistent, and scalable data processing. By following the steps outlined in this guide and incorporating best practices, you can build a robust batch processing data pipeline tailored to your organization's specific needs.</p>"},{"location":"blogs/Data%20Pipelines/cloud_based_processing/","title":"Building a Cloud-Based Data Pipeline: A Comprehensive Guide","text":"<p>In the era of cloud computing, organizations are increasingly adopting cloud-based data pipelines to streamline the flow of data, enhance scalability, and leverage the benefits of cloud services. Cloud-based data pipelines offer flexibility, cost-effectiveness, and ease of maintenance. In this detailed guide, we'll explore the key steps and considerations for implementing a robust cloud-based data pipeline.</p>"},{"location":"blogs/Data%20Pipelines/cloud_based_processing/#understanding-cloud-based-data-pipelines","title":"Understanding Cloud-Based Data Pipelines","text":""},{"location":"blogs/Data%20Pipelines/cloud_based_processing/#what-is-a-cloud-based-data-pipeline","title":"What is a Cloud-Based Data Pipeline?","text":"<p>A cloud-based data pipeline is a set of processes and services that facilitate the efficient and automated movement of data from various sources to its destination in the cloud. Leveraging cloud infrastructure, these pipelines often include data extraction, transformation, loading (ETL), and data storage components, providing a scalable and flexible solution for handling diverse data processing needs.</p>"},{"location":"blogs/Data%20Pipelines/cloud_based_processing/#why-cloud-based-data-pipelines","title":"Why Cloud-Based Data Pipelines?","text":"<ul> <li> <p>Scalability: Cloud platforms offer on-demand scalability, allowing pipelines to handle varying workloads.</p> </li> <li> <p>Cost Efficiency: Pay-as-you-go models ensure cost efficiency by only charging for the resources used.</p> </li> <li> <p>Managed Services: Cloud providers offer managed services for data storage, processing, and analytics, reducing the operational burden on organizations.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/cloud_based_processing/#steps-to-implement-a-cloud-based-data-pipeline","title":"Steps to Implement a Cloud-Based Data Pipeline","text":""},{"location":"blogs/Data%20Pipelines/cloud_based_processing/#1-define-objectives-and-requirements","title":"1. Define Objectives and Requirements:","text":"<ul> <li> <p>Clearly outline the goals of your cloud-based data pipeline.</p> </li> <li> <p>Identify specific requirements, such as data sources, destinations, and processing needs.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/cloud_based_processing/#2-select-cloud-platform","title":"2. Select Cloud Platform:","text":"<ul> <li> <p>Choose a cloud service provider based on your organization's preferences and requirements.</p> </li> <li> <p>Popular options include Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform (GCP).</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/cloud_based_processing/#3-design-the-pipeline-architecture","title":"3. Design the Pipeline Architecture:","text":"<ul> <li> <p>Define the overall architecture of your data pipeline, including components such as data storage, processing, and analytics services.</p> </li> <li> <p>Consider the use of serverless computing, containerization, and microservices architecture.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/cloud_based_processing/#4-data-ingestion","title":"4. Data Ingestion:","text":"<ul> <li> <p>Implement mechanisms for ingesting data from various sources to the cloud.</p> </li> <li> <p>Leverage cloud-native services like AWS S3, Azure Blob Storage, or Google Cloud Storage.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/cloud_based_processing/#5-data-transformation","title":"5. Data Transformation:","text":"<ul> <li> <p>Design data transformation processes to clean, enrich, or reshape the data as needed.</p> </li> <li> <p>Use cloud-based ETL services like AWS Glue, Azure Data Factory, or Google Cloud Dataprep.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/cloud_based_processing/#6-data-processing-and-analytics","title":"6. Data Processing and Analytics:","text":"<ul> <li> <p>Integrate cloud-based processing and analytics services for advanced data insights.</p> </li> <li> <p>Utilize services such as AWS EMR, Azure HDInsight, or Google Cloud Dataproc for big data processing.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/cloud_based_processing/#7-integration-with-data-warehousing","title":"7. Integration with Data Warehousing:","text":"<ul> <li> <p>Connect the pipeline to a cloud-based data warehouse for structured storage and analysis.</p> </li> <li> <p>Consider platforms like AWS Redshift, Azure Synapse Analytics, or Google BigQuery.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/cloud_based_processing/#8-monitoring-and-logging","title":"8. Monitoring and Logging:","text":"<ul> <li> <p>Implement monitoring tools to track the performance and health of your pipeline.</p> </li> <li> <p>Leverage cloud-native monitoring solutions such as AWS CloudWatch, Azure Monitor, or Google Cloud Monitoring.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/cloud_based_processing/#9-security-considerations","title":"9. Security Considerations:","text":"<ul> <li> <p>Implement security measures to protect data during transit and storage.</p> </li> <li> <p>Use encryption, identity and access management (IAM), and comply with relevant security standards.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/cloud_based_processing/#10-orchestration-and-workflow-management","title":"10. Orchestration and Workflow Management:","text":"<ul> <li> <p>Use cloud-native orchestration services to manage the workflow of your pipeline.</p> </li> <li> <p>Examples include AWS Step Functions, Azure Logic Apps, or Google Cloud Composer.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/cloud_based_processing/#11-testing-and-quality-assurance","title":"11. Testing and Quality Assurance:","text":"<ul> <li> <p>Establish a comprehensive testing strategy, including unit tests and end-to-end testing of the pipeline.</p> </li> <li> <p>Use cloud-based testing services or frameworks compatible with your chosen cloud platform.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/cloud_based_processing/#12-documentation","title":"12. Documentation:","text":"<ul> <li> <p>Document the entire cloud-based data pipeline architecture, including configurations, dependencies, and processes.</p> </li> <li> <p>Provide guidelines for troubleshooting, maintenance, and future enhancements.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/cloud_based_processing/#real-world-example-aws-cloud-based-data-pipeline","title":"Real-World Example: AWS Cloud-Based Data Pipeline","text":"<p>Let's walk through a real-world example of implementing a cloud-based data pipeline using Amazon Web Services (AWS), one of the leading cloud service providers.</p> <p>Creating a complete AWS cloud-based data pipeline involves several services to collect, process, store, and analyze data. In this example, we'll build a basic data pipeline using the following AWS services:</p> <ul> <li> <p>Amazon S3: For storage of raw data.</p> </li> <li> <p>AWS Glue: For ETL (Extract, Transform, Load) jobs.</p> </li> <li> <p>Amazon Athena: For querying data in S3.</p> </li> <li> <p>Amazon CloudWatch Events: For scheduling pipeline activities.</p> </li> <li> <p>AWS Lambda: For triggering ETL jobs.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/cloud_based_processing/#step-1-setup","title":"Step 1: Setup","text":"<ol> <li> <p>Create an S3 Bucket Create an S3 bucket to store raw data. Replace  with your desired bucket name. <li> <p>Set Up AWS Glue Create an AWS Glue database and a table to represent your data schema.</p> </li> <li> <p>Set Up AWS Lambda Create a Lambda function to trigger Glue ETL jobs. The Lambda function will be triggered by CloudWatch Events.</p> </li> <li> <p>Set Up CloudWatch Events Create a CloudWatch Events rule to schedule the Lambda function at specified intervals.</p> </li>"},{"location":"blogs/Data%20Pipelines/cloud_based_processing/#step-2-etl-job-with-aws-glue","title":"Step 2: ETL Job with AWS Glue","text":"<p>Write a Glue ETL script in Python. This script will read data from the raw S3 bucket, perform transformations, and write the transformed data back to S3.</p> <pre><code># etl_script.py\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n\n# Boilerplate code for Glue job\nargs = getResolvedOptions(sys.argv, ['JOB_NAME'])\nsc = SparkContext()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)\njob.init(args['JOB_NAME'], args)\n\n# Define source and target paths\nsource_path = \"s3://&lt;your-bucket-name&gt;/raw-data/\"\ntarget_path = \"s3://&lt;your-bucket-name&gt;/processed-data/\"\n\n# Create DynamicFrame for the source data\ndatasource = glueContext.create_dynamic_frame.from_catalog(database=\"&lt;your-database-name&gt;\", table_name=\"&lt;your-table-name&gt;\")\n\n# Perform transformations\n# Example: Convert a column to uppercase\ntransformed_data = datasource.apply_mapping([('column_name', 'string', 'column_name', 'string')])\n\n# Write transformed data to target S3 location\nglueContext.write_dynamic_frame.from_options(frame = transformed_data, connection_type = \"s3\", connection_options = {\"path\": target_path}, format = \"parquet\")\n\n# Commit the job\njob.commit()\n</code></pre>"},{"location":"blogs/Data%20Pipelines/cloud_based_processing/#step-3-aws-lambda-function","title":"Step 3: AWS Lambda Function","text":"<p>Write a Lambda function in Python to trigger the Glue ETL job.</p> <pre><code># lambda_function.py\nimport boto3\n\ndef lambda_handler(event, context):\n    glue = boto3.client('glue')\n    job_name = '&lt;your-glue-job-name&gt;'\n\n    response = glue.start_job_run(JobName=job_name)\n\n    return {\n        'statusCode': 200,\n        'body': response\n    }\n</code></pre>"},{"location":"blogs/Data%20Pipelines/cloud_based_processing/#step-4-cloudwatch-events-rule","title":"Step 4: CloudWatch Events Rule","text":"<p>Create a CloudWatch Events rule to schedule the Lambda function at specific intervals.</p>"},{"location":"blogs/Data%20Pipelines/cloud_based_processing/#step-5-testing","title":"Step 5: Testing","text":"<p>Upload some raw data to the S3 bucket. The CloudWatch Events rule will trigger the Lambda function, which in turn triggers the Glue ETL job. The transformed data will be stored in the specified S3 location.</p> <p>Remember to replace placeholder values like <code>&lt;your-bucket-name&gt;</code>, <code>&lt;your-database-name&gt;</code>, <code>&lt;your-table-name&gt;</code>, and <code>&lt;your-glue-job-name&gt;</code> with your actual values.</p> <p>This is a simplified example, and in a real-world scenario, you may need to handle errors, manage dependencies between different pipeline stages, and possibly use additional AWS services for specific requirements. Always follow best practices for security and performance when designing production-grade data pipelines.</p>"},{"location":"blogs/Data%20Pipelines/cloud_based_processing/#conclusion","title":"Conclusion","text":"<p>Implementing a cloud-based data pipeline is a strategic move for organizations aiming to harness the power of cloud computing for data processing and analytics. By carefully planning and following the steps outlined in this guide, you can build a robust pipeline that meets your organization's specific requirements. Stay informed about the evolving landscape of cloud services, regularly optimize your pipeline, and embrace the flexibility and scalability offered by the cloud to ensure the success of your data-driven initiatives.</p>"},{"location":"blogs/Data%20Pipelines/real_time_processing/","title":"Building a Real-Time Streaming Data Pipeline: A Comprehensive Guide","text":"<p>In the fast-paced world of data engineering, real-time streaming data pipelines have become essential for organizations seeking to derive immediate insights from their data. These pipelines enable the continuous processing of data as it flows, allowing for timely decision-making and actionable intelligence. In this detailed guide, we will explore the key steps and considerations for implementing a robust real-time streaming data pipeline.</p>"},{"location":"blogs/Data%20Pipelines/real_time_processing/#understanding-real-time-streaming-data-pipelines","title":"Understanding Real-Time Streaming Data Pipelines","text":""},{"location":"blogs/Data%20Pipelines/real_time_processing/#what-is-a-real-time-streaming-data-pipeline","title":"What is a Real-Time Streaming Data Pipeline?","text":"<p>A real-time streaming data pipeline is a system that enables the continuous ingestion, processing, and analysis of data in near real-time. Unlike batch processing, where data is collected and processed in predefined intervals, streaming data pipelines handle data on-the-fly, offering low-latency processing for time-sensitive applications.</p>"},{"location":"blogs/Data%20Pipelines/real_time_processing/#why-real-time-streaming","title":"Why Real-Time Streaming?","text":"<ul> <li> <p>Immediate Insights: Real-time pipelines provide instant insights into changing data, allowing organizations to respond rapidly to emerging trends or issues.</p> </li> <li> <p>Dynamic Data Processing: Ideal for applications requiring constant updates, such as financial transactions, social media analytics, or IoT sensor data.</p> </li> <li> <p>Event-Driven Architecture: Enables event-driven workflows, triggering actions in response to specific events as they occur.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/real_time_processing/#steps-to-implement-a-real-time-streaming-data-pipeline","title":"Steps to Implement a Real-Time Streaming Data Pipeline","text":""},{"location":"blogs/Data%20Pipelines/real_time_processing/#1-define-objectives-and-use-cases","title":"1. Define Objectives and Use Cases:","text":"<ul> <li> <p>Clearly outline the goals of your real-time streaming pipeline.</p> </li> <li> <p>Identify specific use cases and applications that require low-latency data processing.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/real_time_processing/#2-choose-streaming-framework","title":"2. Choose Streaming Framework:","text":"<ul> <li> <p>Select a streaming framework suitable for your needs.</p> </li> <li> <p>Popular choices include Apache Kafka, Apache Flink, Apache Storm, or cloud-based solutions like AWS Kinesis or Google Cloud Dataflow.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/real_time_processing/#3-data-ingestion","title":"3. Data Ingestion:","text":"<ul> <li> <p>Set up mechanisms for data ingestion from various sources, such as IoT devices, social media feeds, or application logs.</p> </li> <li> <p>Ensure scalability for handling varying data volumes.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/real_time_processing/#4-data-processing","title":"4. Data Processing:","text":"<ul> <li> <p>Design data processing logic for real-time analysis.</p> </li> <li> <p>Implement transformations, aggregations, and filtering based on business requirements.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/real_time_processing/#5-streaming-analytics","title":"5. Streaming Analytics:","text":"<ul> <li> <p>Integrate streaming analytics tools to gain insights from the processed data.</p> </li> <li> <p>Leverage technologies like Apache Flink or Spark Streaming for complex analytics.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/real_time_processing/#6-integration-with-storage","title":"6. Integration with Storage:","text":"<ul> <li> <p>Connect the streaming pipeline to a storage solution for persistence.</p> </li> <li> <p>Consider options like Apache Cassandra, Amazon DynamoDB, or Google Bigtable for storing real-time data.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/real_time_processing/#7-monitoring-and-alerting","title":"7. Monitoring and Alerting:","text":"<ul> <li> <p>Implement monitoring tools to track the health and performance of the streaming pipeline.</p> </li> <li> <p>Set up alerts for potential issues or anomalies in real-time data processing.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/real_time_processing/#8-scalability-and-performance-optimization","title":"8. Scalability and Performance Optimization:","text":"<ul> <li> <p>Design the pipeline for scalability to handle growing data volumes.</p> </li> <li> <p>Optimize performance by considering parallel processing and data partitioning.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/real_time_processing/#9-security-considerations","title":"9. Security Considerations:","text":"<ul> <li> <p>Implement security measures to protect data during streaming and storage.</p> </li> <li> <p>Utilize encryption, authentication, and access controls as necessary.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/real_time_processing/#10-deployment-and-orchestration","title":"10. Deployment and Orchestration:","text":"<ul> <li> <p>Deploy the streaming pipeline in a production environment.</p> </li> <li> <p>Use orchestration tools like Apache NiFi, Apache Airflow, or Kubernetes for managing the pipeline components.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/real_time_processing/#11-continuous-testing","title":"11. Continuous Testing:","text":"<ul> <li> <p>Establish a robust testing strategy, including unit testing and end-to-end testing of the streaming pipeline.</p> </li> <li> <p>Implement automated testing to ensure reliability and correctness.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/real_time_processing/#12-documentation","title":"12. Documentation:","text":"<ul> <li> <p>Document the entire streaming pipeline architecture, including components, configurations, and dependencies.</p> </li> <li> <p>Provide guidelines for troubleshooting and maintenance.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/real_time_processing/#real-world-example-apache-kafka-for-real-time-streaming","title":"Real-World Example: Apache Kafka for Real-Time Streaming","text":"<p>Let's consider a scenario where we want to build a real-time streaming application using Apache Kafka and Python. We'll create a simple producer that generates and sends messages to a Kafka topic, and a consumer that processes these messages in real-time.</p>"},{"location":"blogs/Data%20Pipelines/real_time_processing/#prerequisites","title":"Prerequisites:","text":"<ul> <li> <p>Install Apache Kafka: Follow the official Kafka Quickstart Guide to set up Kafka on your machine.</p> </li> <li> <p>Install the <code>confluent_kafka</code> Python library:     <pre><code>pip install confluent_kafka\n</code></pre></p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/real_time_processing/#step-1-create-a-kafka-topic","title":"Step 1: Create a Kafka Topic","text":"<p>Let's create a Kafka topic named <code>real-time-streaming-topic</code>.</p> <pre><code>kafka-topics.sh --create --topic real-time-streaming-topic --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1\n</code></pre>"},{"location":"blogs/Data%20Pipelines/real_time_processing/#step-2-producer-code","title":"Step 2: Producer Code","text":"<p>Create a Python script for the Kafka producer, which will generate and send messages to the Kafka topic.</p> <pre><code># producer.py\nfrom confluent_kafka import Producer\nimport json\nimport time\n\ndef delivery_report(err, msg):\n    if err is not None:\n        print('Message delivery failed: {}'.format(err))\n    else:\n        print('Message delivered to {} [{}]'.format(msg.topic(), msg.partition()))\n\ndef produce_messages(producer, topic):\n    for i in range(10):\n        data = {'message': f'Message {i}', 'timestamp': time.time()}\n        producer.produce(topic, key=str(i), value=json.dumps(data), callback=delivery_report)\n        producer.poll(0.5)  # Poll for callbacks\n\n    producer.flush()\n\nif __name__ == '__main__':\n    producer_config = {'bootstrap.servers': 'localhost:9092'}\n    producer = Producer(producer_config)\n\n    topic_name = 'real-time-streaming-topic'\n    produce_messages(producer, topic_name)\n</code></pre>"},{"location":"blogs/Data%20Pipelines/real_time_processing/#step-3-consumer-code","title":"Step 3: Consumer Code","text":"<p>Create a Python script for the Kafka consumer, which will process the incoming messages in real-time.</p> <pre><code># consumer.py\nfrom confluent_kafka import Consumer, KafkaError\nimport json\n\ndef consume_messages(consumer, topic):\n    consumer.subscribe([topic])\n\n    while True:\n        msg = consumer.poll(1.0)\n\n        if msg is None:\n            continue\n        if msg.error():\n            if msg.error().code() == KafkaError._PARTITION_EOF:\n                continue\n            else:\n                print(msg.error())\n                break\n\n        value = json.loads(msg.value().decode('utf-8'))\n        print(f'Received message: {value}')\n\nif __name__ == '__main__':\n    consumer_config = {'bootstrap.servers': 'localhost:9092', 'group.id': 'my-group', 'auto.offset.reset': 'earliest'}\n    consumer = Consumer(consumer_config)\n\n    topic_name = 'real-time-streaming-topic'\n    consume_messages(consumer, topic_name)\n</code></pre>"},{"location":"blogs/Data%20Pipelines/real_time_processing/#step-4-run-the-example","title":"Step 4: Run the Example","text":"<ol> <li> <p>Start the Kafka server: <code>bin/kafka-server-start.sh config/server.properties</code></p> </li> <li> <p>Run the producer: <code>python producer.py</code></p> </li> <li> <p>In a separate terminal, run the consumer: <code>python consumer.py</code></p> </li> </ol> <p>You should see the producer generating messages and the consumer processing them in real-time.</p> <p>This is a simple example, and in a real-world scenario, you might want to handle more complex data, implement error handling, and scale the system as needed. Additionally, you may consider using Kafka Streams or other processing frameworks for more advanced stream processing tasks.</p>"},{"location":"blogs/Data%20Pipelines/real_time_processing/#conclusion","title":"Conclusion","text":"<p>Implementing a real-time streaming data pipeline requires careful planning, selection of appropriate technologies, and continuous optimization. Whether you are dealing with IoT data, social media feeds, or financial transactions, a well-designed streaming pipeline ensures timely insights and responsiveness. Consider the unique requirements of your use case, stay updated on emerging technologies, and iterate on your pipeline design to keep pace with the dynamic nature of real-time data processing.</p>"},{"location":"blogs/Data%20Pipelines/serverless_processing/","title":"Building a Machine Learning Data Pipeline: A Comprehensive Guide","text":"<p>Machine Learning (ML) data pipelines play a pivotal role in harnessing the power of data for training, deploying, and maintaining machine learning models. In this detailed guide, we'll explore the key steps and considerations for implementing a robust machine learning data pipeline.</p>"},{"location":"blogs/Data%20Pipelines/serverless_processing/#understanding-machine-learning-data-pipelines","title":"Understanding Machine Learning Data Pipelines","text":""},{"location":"blogs/Data%20Pipelines/serverless_processing/#what-is-a-machine-learning-data-pipeline","title":"What is a Machine Learning Data Pipeline?","text":"<p>A machine learning data pipeline is a systematic process that facilitates the flow of data from various sources to the creation, training, and deployment of machine learning models. These pipelines encompass data collection, preprocessing, feature engineering, model training, evaluation, and deployment, ensuring a seamless and efficient workflow.</p>"},{"location":"blogs/Data%20Pipelines/serverless_processing/#why-machine-learning-data-pipelines","title":"Why Machine Learning Data Pipelines?","text":"<ul> <li> <p>Data Preparation: ML models are highly dependent on the quality and format of data. Data pipelines ensure that data is prepared, cleaned, and transformed for model training.</p> </li> <li> <p>Reproducibility: A well-defined pipeline allows for the reproducibility of experiments, making it easier to trace back and understand the steps involved in model development.</p> </li> <li> <p>Scalability: ML data pipelines enable the handling of large volumes of data and the scalability of model training processes.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/serverless_processing/#steps-to-implement-a-machine-learning-data-pipeline","title":"Steps to Implement a Machine Learning Data Pipeline","text":""},{"location":"blogs/Data%20Pipelines/serverless_processing/#1-define-objectives-and-use-cases","title":"1. Define Objectives and Use Cases:","text":"<ul> <li> <p>Clearly outline the goals of your machine learning data pipeline.</p> </li> <li> <p>Identify specific use cases and applications for machine learning in your organization.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/serverless_processing/#2-data-collection","title":"2. Data Collection:","text":"<ul> <li> <p>Ingest data from various sources relevant to your ML use case.</p> </li> <li> <p>Utilize tools and frameworks for data extraction, such as Apache Kafka, cloud-based storage, or API integration.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/serverless_processing/#3-data-preprocessing","title":"3. Data Preprocessing:","text":"<ul> <li> <p>Cleanse, normalize, and preprocess the raw data to make it suitable for model training.</p> </li> <li> <p>Address missing values, handle outliers, and standardize features as necessary.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/serverless_processing/#4-feature-engineering","title":"4. Feature Engineering:","text":"<ul> <li> <p>Identify and create relevant features that contribute to the predictive power of the model.</p> </li> <li> <p>Utilize domain knowledge to engineer features that capture important patterns in the data.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/serverless_processing/#5-data-splitting","title":"5. Data Splitting:","text":"<ul> <li> <p>Divide the dataset into training, validation, and test sets.</p> </li> <li> <p>Ensure a representative distribution of data across sets to avoid bias.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/serverless_processing/#6-model-training","title":"6. Model Training:","text":"<ul> <li> <p>Select an appropriate machine learning algorithm based on your use case (e.g., regression, classification, clustering).</p> </li> <li> <p>Train the model using the training dataset and evaluate its performance on the validation set.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/serverless_processing/#7-hyperparameter-tuning","title":"7. Hyperparameter Tuning:","text":"<ul> <li> <p>Fine-tune model hyperparameters to optimize performance.</p> </li> <li> <p>Utilize techniques such as grid search or randomized search to find optimal hyperparameter values.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/serverless_processing/#8-model-evaluation","title":"8. Model Evaluation:","text":"<ul> <li> <p>Evaluate the model's performance on the test set to assess its generalization ability.</p> </li> <li> <p>Utilize metrics relevant to your specific use case (accuracy, precision, recall, F1 score).</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/serverless_processing/#9-model-deployment","title":"9. Model Deployment:","text":"<ul> <li> <p>Deploy the trained model to a production environment for inference.</p> </li> <li> <p>Utilize containerization (e.g., Docker) or serverless deployment options for efficient deployment.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/serverless_processing/#10-monitoring-and-logging","title":"10. Monitoring and Logging:","text":"<ul> <li> <p>Implement monitoring tools to track the performance of the deployed model in real-time.</p> </li> <li> <p>Set up logging to capture relevant information for debugging and auditing.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/serverless_processing/#11-feedback-loop","title":"11. Feedback Loop:","text":"<ul> <li> <p>Establish a feedback loop to continuously improve the model.</p> </li> <li> <p>Collect user feedback, monitor model performance, and retrain the model as needed.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/serverless_processing/#12-documentation","title":"12. Documentation:","text":"<ul> <li> <p>Document the entire machine learning data pipeline, including data sources, preprocessing steps, model architecture, and deployment details.</p> </li> <li> <p>Provide guidelines for model maintenance, updates, and versioning.</p> </li> </ul>"},{"location":"blogs/Data%20Pipelines/serverless_processing/#real-world-example-scikit-learn-and-tensorflow-based-pipeline","title":"Real-World Example: Scikit-Learn and TensorFlow-based Pipeline","text":"<p>Let's walk through a real-world example of implementing a machine learning data pipeline using Scikit-Learn and TensorFlow, two widely used machine learning libraries.</p> <p>In this example, we'll create a real-world machine learning pipeline using Scikit-Learn for data preprocessing and modeling, and TensorFlow for building and training a neural network. This pipeline will involve data preprocessing, feature engineering, model training, and evaluation.</p>"},{"location":"blogs/Data%20Pipelines/serverless_processing/#step-1-data-preprocessing-with-scikit-learn","title":"Step 1: Data Preprocessing with Scikit-Learn","text":"<p>Let's start by loading a dataset and performing some basic preprocessing using Scikit-Learn.</p> <pre><code># Step 1: Data Preprocessing with Scikit-Learn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\n\n# Load your dataset (replace 'load_dataset' and 'target_column' with your actual loading code)\nX, y = load_dataset()\ntarget_column = 'target'\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Define a Scikit-Learn pipeline for preprocessing\npreprocessing_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='mean')),  # Handle missing values\n    ('scaler', StandardScaler())  # Standardize features\n])\n\n# Fit the preprocessing pipeline on the training data\nX_train_preprocessed = preprocessing_pipeline.fit_transform(X_train)\nX_test_preprocessed = preprocessing_pipeline.transform(X_test)\n</code></pre>"},{"location":"blogs/Data%20Pipelines/serverless_processing/#step-2-building-a-neural-network-with-tensorflowkeras","title":"Step 2: Building a Neural Network with TensorFlow/Keras","text":"<p>Next, let's build a simple neural network using TensorFlow and Keras.</p> <pre><code># Step 2: Building a Neural Network with TensorFlow/Keras\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n# Build a simple neural network model\nmodel = keras.Sequential([\n    layers.Dense(64, activation='relu', input_shape=(X_train_preprocessed.shape[1],)),\n    layers.Dense(1, activation='sigmoid')  # Assuming binary classification, adjust for your task\n])\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n</code></pre>"},{"location":"blogs/Data%20Pipelines/serverless_processing/#step-3-training-the-model","title":"Step 3: Training the Model","text":"<p>Now, let's train the model on the preprocessed data.</p> <pre><code># Step 3: Training the Model\n# Train the model on the preprocessed training data\nmodel.fit(X_train_preprocessed, y_train, epochs=10, batch_size=32, validation_split=0.2)\n</code></pre>"},{"location":"blogs/Data%20Pipelines/serverless_processing/#step-4-model-evaluation","title":"Step 4: Model Evaluation","text":"<p>Evaluate the trained model on the test set.</p> <pre><code># Step 4: Model Evaluation\n# Evaluate the model on the preprocessed test data\ntest_loss, test_accuracy = model.evaluate(X_test_preprocessed, y_test)\nprint(f'Test Accuracy: {test_accuracy}')\n</code></pre>"},{"location":"blogs/Data%20Pipelines/serverless_processing/#step-5-making-predictions","title":"Step 5: Making Predictions","text":"<p>Use the trained model to make predictions on new data.</p> <pre><code># Step 5: Making Predictions\n# Assuming 'new_data' is the new data you want to make predictions on\nnew_data_preprocessed = preprocessing_pipeline.transform(new_data)\npredictions = model.predict(new_data_preprocessed)\n</code></pre>"},{"location":"blogs/Data%20Pipelines/serverless_processing/#conclusion","title":"Conclusion","text":"<p>This example demonstrates a simplified machine learning pipeline using Scikit-Learn for data preprocessing and TensorFlow/Keras for building and training a neural network. In a real-world scenario, you might need to fine-tune hyperparameters, handle more complex data, and potentially use more advanced models or ensembles. Additionally, proper validation, hyperparameter tuning, and model interpretation are crucial steps in building robust machine learning pipelines.</p>"},{"location":"blogs/MA%20challenges/","title":"Welcome to AI Morocco Challenges","text":""},{"location":"blogs/MA%20challenges/#discover-how-artificial-intelligence-is-transforming-morocco","title":"Discover How Artificial Intelligence is Transforming Morocco","text":"<p>Over the next 12 days, we invite you on an exciting journey through the world of Artificial Intelligence (AI) and Deep Learning. Our series of posts, <code>ML &amp; DL Morocco Challenges</code>, explores how AI is contributing to the transformation of diverse sectors in Morocco.</p>"},{"location":"blogs/MA%20challenges/#what-youll-discover","title":"What You'll Discover:","text":"<p>\ud83d\ude80 A New Sector Every Day: Over these 12 days, we will dive into areas such as healthcare, education, agriculture, transportation, finance, energy, and much more.</p> <p>\ud83e\udde0 The Impact of AI: Explore how AI is revolutionizing these sectors, fueling innovation and development in Morocco.</p> <p>\ud83c\udf10 Challenges and Opportunities: We'll examine the unique challenges and exciting opportunities that AI brings to our beautiful country.</p>"},{"location":"blogs/MA%20challenges/#join-the-conversation","title":"Join the Conversation","text":"<p>We believe that AI has the power to catalyze growth and enhance the quality of life in Morocco. Join the conversation, share your ideas, and discover how AI can shape our future.</p>"},{"location":"blogs/MA%20challenges/#start-your-journey","title":"Start Your Journey","text":"<p>Get ready for an immersive exploration of AI in Morocco. Visit tomorrow for our first post in the series and stay tuned for regular updates.</p> <p>Together, let's uncover how Artificial Intelligence is transforming our nation.</p> <p>Follow me on LinkedIn to stay informed about the latest updates and discussions.</p>"},{"location":"blogs/MA%20challenges/agriculture/","title":"\ud83c\udf3e Day 3: Agriculture Revolution \ud83c\udf3e","text":"<p>Welcome to the third day of our <code>ML &amp; DL Morocco Challenges</code> series. Today, we embark on a journey to discover how Artificial Intelligence is revolutionizing agriculture in Morocco, a sector that lies at the heart of our nation's prosperity.</p>"},{"location":"blogs/MA%20challenges/agriculture/#ais-impact-on-agriculture","title":"AI's Impact on Agriculture","text":"<p>Agriculture is the backbone of Morocco's economy, and Artificial Intelligence is poised to transform the way we farm and cultivate. AI-driven advancements are changing the game in agriculture:</p> <p>\ud83d\udd39 Precision Farming: AI enables farmers to optimize crop management, ensuring efficient resource use and higher yields.</p> <p>\ud83d\udd39 Crop Health Monitoring: AI technologies can identify and diagnose crop diseases and pests, allowing for early interventions.</p> <p>\ud83d\udd39 Climate Resilience: AI models can predict weather patterns, helping farmers adapt to changing climate conditions.</p>"},{"location":"blogs/MA%20challenges/agriculture/#the-moroccan-agriculture-landscape","title":"The Moroccan Agriculture Landscape","text":"<p>In Morocco, AI offers the potential to increase food production and enhance the livelihoods of our rural communities. By addressing issues like water management, soil health, and access to modern farming techniques, AI can play a vital role in our agricultural sector's sustainable growth.</p>"},{"location":"blogs/MA%20challenges/agriculture/#join-the-conversation","title":"Join the Conversation","text":"<p>How do you envision AI transforming agriculture in Morocco? What are the specific challenges and opportunities in our agricultural sector that AI can address? Share your thoughts and experiences in the comments below.</p>"},{"location":"blogs/MA%20challenges/agriculture/#mr-belmady","title":"\ud83e\udde0 Mr BELMADY","text":"<p>AI technologies, particularly Machine Learning (ML) and Deep Learning (DL), have the potential to drive a significant transformation in Morocco's agricultural sector. One specific technique that can make a substantial contribution to Morocco's agricultural development is Precision Agriculture, powered by ML and DL.</p> <p>Precision Agriculture for Morocco's Diverse Landscape:</p> <p>Precision Agriculture, also known as Precision Farming, is an AI-driven approach that tailors farming practices to specific variables, such as soil quality, climate, crop health, and resource utilization. Here's how Precision Agriculture can revolutionize Morocco's agriculture:</p> <ol> <li>Enhanced Crop Management:<ul> <li>ML algorithms can analyze data from various sources, including satellites, drones, and sensors, to monitor crop health and identify potential issues such as pests, diseases, or nutrient deficiencies. This information enables farmers to take timely and targeted action, reducing crop losses.</li> </ul> </li> <li>Optimized Resource Utilization:<ul> <li>AI can analyze data to optimize the use of resources like water and fertilizers. Given Morocco's climate diversity, this is particularly vital for ensuring sustainable agriculture and addressing water scarcity concerns.</li> </ul> </li> <li>Soil Health Assessment:<ul> <li>DL models can assess soil quality, helping farmers choose the right crops and fertilizers for their specific soil conditions. This ensures optimal yields and sustainability.</li> </ul> </li> <li>Climate Prediction and Adaptation:<ul> <li>ML can predict weather patterns and climatic changes, allowing farmers to adapt their planting and harvesting schedules to minimize the impact of climate variability.</li> </ul> </li> <li>Reduced Environmental Impact:<ul> <li>Precision Agriculture minimizes the environmental footprint by minimizing excess resource use and mitigating soil degradation, benefiting Morocco's ecosystems.</li> </ul> </li> <li>Data-Driven Decision-Making:<ul> <li>Through real-time data collection and analysis, farmers can make informed decisions regarding planting, irrigation, and harvest, leading to increased productivity and income.</li> </ul> </li> <li>Financial Benefits:<ul> <li>By maximizing resource efficiency and minimizing waste, Precision Agriculture can lead to cost savings for farmers, particularly smallholders, contributing to rural economic development.</li> </ul> </li> </ol> <p>By leveraging Precision Agriculture techniques, based on ML and DL, Morocco can address the unique challenges posed by its diverse agricultural landscape. This approach not only increases the productivity and sustainability of the sector but also promotes rural development and food security in the country.</p>"},{"location":"blogs/MA%20challenges/agriculture/#a-greener-more-prosperous-morocco-awaits","title":"A Greener, More Prosperous Morocco Awaits","text":"<p>By harnessing the potential of Machine Learning and Deep Learning in agriculture, Morocco can aspire to achieve a greener, more food-secure, and prosperous future. Stay tuned for more insights on how AI can drive development in our country.</p>"},{"location":"blogs/MA%20challenges/ai_talent/","title":"\ud83e\udde0 Day 10: Nurturing AI Talent \ud83e\udde0","text":"<p>Welcome to the tenth day of our <code>ML &amp; DL Morocco Challenges</code> series. Today, we focus on the critical aspect of nurturing AI talent in Morocco, preparing the next generation of innovators.</p>"},{"location":"blogs/MA%20challenges/ai_talent/#the-importance-of-ai-talent","title":"The Importance of AI Talent","text":"<p>In the age of AI, a skilled workforce is essential for driving innovation and development. Nurturing AI talent can have profound implications:</p> <p>\ud83d\udd39 Innovation Hub: AI talent can turn Morocco into a hub for AI innovation, attracting investments and talent from around the world.</p> <p>\ud83d\udd39 Economic Growth: A strong AI talent pool can stimulate economic growth by fostering AI-based startups and industries.</p> <p>\ud83d\udd39 Solving Local Challenges: AI talent can address local challenges unique to Morocco, from healthcare to agriculture.</p>"},{"location":"blogs/MA%20challenges/ai_talent/#fostering-ai-talent-in-morocco","title":"Fostering AI Talent in Morocco","text":"<p>Morocco has recognized the need for AI talent development. Initiatives are underway to train, educate, and empower the workforce to meet the AI demands of the future. Challenges include access to quality education, retaining talent, and bridging the gender gap in tech.</p>"},{"location":"blogs/MA%20challenges/ai_talent/#join-the-conversation","title":"Join the Conversation","text":"<p>How do you envision the growth of AI talent in Morocco? What initiatives or experiences have inspired you? Share your thoughts and ideas in the comments below.</p>"},{"location":"blogs/MA%20challenges/ai_talent/#mr-belmady","title":"\ud83e\udde0 Mr BELMADY","text":"<p>Fostering AI talent and nurturing the next generation of experts in Machine Learning (ML) and Deep Learning (DL) is crucial for the future of AI in Morocco. Here are some specific strategies and techniques that can help contribute to Morocco's development through ML and DL expertise:</p> <ol> <li>Education and Curriculum Enhancement:<ul> <li><code>Introduce ML and DL in Education</code>: Collaborate with educational institutions to incorporate ML and DL courses into the curriculum at various levels, from secondary schools to universities. This can help students develop a strong foundation in AI.</li> </ul> </li> <li>Scholarships and Financial Support:<ul> <li><code>Scholarship Programs</code>: Establish scholarship programs that support talented students pursuing degrees in AI-related fields. This can reduce financial barriers and encourage more students to enter the AI workforce.</li> </ul> </li> <li>Hands-on Learning:<ul> <li><code>AI Labs and Workshops</code>: Create AI research and development labs at universities and offer workshops to provide students with hands-on experience. This practical knowledge is invaluable for building expertise in ML and DL.</li> </ul> </li> <li>Mentorship and Networking:<ul> <li><code>Industry-Academia Collaboration</code>: Foster collaboration between academia and industry to provide students with mentorship opportunities and real-world projects. Encourage professionals in ML and DL to mentor aspiring talent.</li> </ul> </li> <li>Online Learning Platforms:<ul> <li><code>Online Courses and Resources</code>: Promote the use of online learning platforms and resources, such as MOOCs and AI toolkits, to enable self-paced learning and skill development in ML and DL.</li> </ul> </li> <li>Hackathons and Competitions:<ul> <li><code>AI Challenges</code>: Organize hackathons, coding competitions, and AI challenges to encourage students to apply their ML and DL knowledge to solve real-world problems and showcase their skills.</li> </ul> </li> <li>Research and Innovation Centers:<ul> <li><code>Establish Research Hubs</code>: Establish research centers and hubs focusing on AI and ML innovation. These centers can attract top talent and facilitate cutting-edge research.</li> </ul> </li> <li>Government Initiatives:<ul> <li><code>Support Policies</code>: Encourage government initiatives to fund AI research and development projects, making it an attractive field for both students and professionals.</li> </ul> </li> <li>Industry Training Programs:<ul> <li><code>Corporate Training</code>: Encourage companies to offer training programs for their employees in ML and DL, enhancing the skills of the current workforce and keeping them up-to-date with the latest advancements.</li> </ul> </li> <li>Startups and Entrepreneurship:<ul> <li><code>Support AI Startups</code>: Provide support and resources for AI startups, which can serve as incubators for AI talent and innovation.</li> </ul> </li> <li>Local Language and Cultural Relevance:<ul> <li><code>Develop Local Solutions</code>: Encourage the development of AI solutions that are relevant to Morocco's unique linguistic and cultural context, creating a niche for local AI expertise.</li> </ul> </li> <li>Public Awareness and Outreach:<ul> <li><code>AI Events and Seminars</code>: Organize AI conferences, seminars, and public talks to raise awareness about the potential of AI and its impact on various sectors in Morocco.</li> </ul> </li> </ol> <p>By implementing these strategies and techniques, Morocco can nurture AI talent, develop a skilled workforce in ML and DL, and position itself as a hub for AI expertise and innovation. This, in turn, will contribute to the country's overall development by leveraging the power of AI in various industries.</p>"},{"location":"blogs/MA%20challenges/ai_talent/#a-future-of-limitless-possibilities-awaits","title":"A Future of Limitless Possibilities Awaits","text":"<p>By nurturing AI talent in Morocco, our nation can prepare for a future marked by innovation, economic growth, and the ability to tackle local and global challenges. Stay tuned for more insights on how AI can drive development in our country.</p>"},{"location":"blogs/MA%20challenges/collaboration/","title":"\ud83e\udd1d Day 12: Fostering Collaboration \ud83e\udd1d","text":"<p>Welcome to the twelfth and final day of our <code>ML &amp; DL Morocco Challenges</code> series. Today, we emphasize the significance of fostering collaboration and partnerships to drive AI development in Morocco.</p>"},{"location":"blogs/MA%20challenges/collaboration/#the-power-of-collaboration","title":"The Power of Collaboration","text":"<p>Collaboration is at the heart of progress. By working together, we can achieve more than we ever could individually:</p> <p>\ud83d\udd39 Knowledge Exchange: Collaborating with experts and organizations allows for the exchange of knowledge and expertise.</p> <p>\ud83d\udd39 Resource Sharing: Joint efforts make it possible to pool resources, increasing the potential impact of projects.</p> <p>\ud83d\udd39 Diverse Perspectives: Collaboration brings together people with different viewpoints, fostering innovation and creativity.</p>"},{"location":"blogs/MA%20challenges/collaboration/#collaboration-in-moroccos-ai-journey","title":"Collaboration in Morocco's AI Journey","text":"<p>In Morocco, fostering collaboration among research institutions, businesses, government agencies, and the public is essential for AI development. Collaboration can help address challenges such as talent retention, funding, and infrastructure.</p>"},{"location":"blogs/MA%20challenges/collaboration/#join-the-conversation","title":"Join the Conversation","text":"<p>How do you envision collaboration strengthening Morocco's AI journey? What are the opportunities and challenges in fostering collaboration to drive AI development? Share your thoughts, experiences, and ideas in the comments below.</p>"},{"location":"blogs/MA%20challenges/collaboration/#mr-belmady","title":"\ud83e\udde0 Mr BELMADY","text":"<p>Promoting and strengthening collaborations between the public and private sectors is essential for successful AI development in Morocco. To facilitate such partnerships, here are specific strategies, including techniques in Machine Learning (ML) and Deep Learning (DL), that can contribute to Morocco's development:</p> <ol> <li>Open Data Initiatives:<ul> <li><code>Data Sharing Platforms</code>: Create open data platforms that allow public and private entities to share anonymized data for research and AI model development, particularly in areas like healthcare and urban planning.</li> </ul> </li> <li>Research Grants and Funding:<ul> <li><code>AI Research Grants</code>: Offer grants and funding opportunities for joint AI research projects between public research institutions and private companies to drive innovation.</li> </ul> </li> <li>Public-Private AI Labs:<ul> <li><code>Collaborative Research Labs</code>: Establish collaborative AI research labs where experts from academia, government, and industry work together to solve complex problems using ML and DL techniques.</li> </ul> </li> <li>Data Collaboration Agreements:<ul> <li><code>Data Sharing Agreements</code>: Encourage the development of data sharing agreements that address privacy concerns while facilitating the responsible sharing of data for AI development.</li> </ul> </li> <li>AI Competitions and Challenges:<ul> <li><code>Public-Private AI Competitions</code>: Organize AI competitions and challenges that invite both public and private organizations to compete in solving real-world problems using ML and DL.</li> </ul> </li> <li>AI in Education:<ul> <li><code>Public-Private Training Programs</code>: Collaborate on educational programs and training initiatives to equip the workforce with AI skills, including ML and DL.</li> </ul> </li> <li>Regulatory Frameworks:<ul> <li><code>Collaborative Regulations</code>: Develop regulatory frameworks for AI development that involve input and collaboration between public and private stakeholders to ensure fairness and compliance.</li> </ul> </li> <li>AI Startups and Incubators:<ul> <li><code>Support Ecosystems</code>: Create AI startup incubators and accelerators with public and private sector participation to nurture innovative AI companies.</li> </ul> </li> <li>Public Procurement for AI Solutions:<ul> <li><code>AI Procurement Policies</code>: Encourage public sector organizations to procure AI solutions from local private companies, fostering a market for AI products and services.</li> </ul> </li> <li>Public Data Access for Research:<ul> <li><code>Public Sector Data Sharing</code>: Make certain non-sensitive public sector data accessible to AI researchers and developers in the private sector for innovation and solution development.</li> </ul> </li> <li>Standardization and Certification:<ul> <li><code>Collaborative Standards</code>: Work together to establish AI standards and certification processes that ensure quality and ethical practices in AI development.</li> </ul> </li> <li>Public Awareness Campaigns:<ul> <li><code>Joint AI Promotion</code>: Collaborate on public awareness campaigns to educate the population about the benefits and responsible use of AI, including ML and DL.</li> </ul> </li> <li>Investment Incentives:<ul> <li><code>Private Sector Investment</code>: Provide tax incentives and investment opportunities to encourage private sector investment in AI research and development.</li> </ul> </li> </ol> <p>By implementing these strategies and encouraging ML and DL techniques in collaborative projects, Morocco can promote and strengthen partnerships between the public and private sectors. This collaboration will accelerate AI development, drive innovation, and contribute to the country's overall progress.</p>"},{"location":"blogs/MA%20challenges/collaboration/#a-unified-and-prosperous-morocco-awaits","title":"A Unified and Prosperous Morocco Awaits","text":"<p>By fostering collaboration, Morocco can amplify its AI development efforts, enhance innovation, and overcome challenges to create a prosperous future. Thank you for joining us on this journey through the \"ML &amp; DL Morocco Challenges\" series.</p>"},{"location":"blogs/MA%20challenges/cybersecurity/","title":"\ud83c\udf10 Day 9: Cybersecurity Reinforcement \ud83c\udf10","text":"<p>Welcome to the ninth day of our <code>ML &amp; DL Morocco Challenges</code> series. Today, we delve into the realm of cybersecurity, exploring how Artificial Intelligence reinforces the digital defenses of Morocco.</p>"},{"location":"blogs/MA%20challenges/cybersecurity/#ais-role-in-cybersecurity","title":"AI's Role in Cybersecurity","text":"<p>In an increasingly connected world, cybersecurity is paramount. Artificial Intelligence is proving to be a game-changer in safeguarding our digital landscape:</p> <p>\ud83d\udd39 Threat Detection: AI can identify and respond to cyber threats in real-time, enhancing our ability to protect sensitive data.</p> <p>\ud83d\udd39 Anomaly Detection: AI algorithms detect unusual patterns and behaviors that could signal a cyberattack.</p> <p>\ud83d\udd39 Security Automation: AI automates routine security tasks, freeing up cybersecurity professionals for strategic defense.</p>"},{"location":"blogs/MA%20challenges/cybersecurity/#cybersecurity-in-morocco","title":"Cybersecurity in Morocco","text":"<p>Morocco faces the challenge of securing its digital infrastructure and data from cyber threats. AI is a crucial tool in this endeavor, as it provides the capability to protect our digital assets effectively. Challenges include talent development, policy frameworks, and international cooperation.</p>"},{"location":"blogs/MA%20challenges/cybersecurity/#join-the-conversation","title":"Join the Conversation","text":"<p>How do you see AI fortifying cybersecurity in Morocco? What are the specific cybersecurity challenges and opportunities that our nation faces in the digital age? Share your thoughts, experiences, and ideas in the comments below.</p>"},{"location":"blogs/MA%20challenges/cybersecurity/#mr-belmady","title":"\ud83e\udde0 Mr BELMADY","text":"<p>AI technologies, particularly Machine Learning (ML) and Deep Learning (DL), can significantly enhance cybersecurity in Morocco through a specific technique known as Anomaly Detection.</p> <p>Enhancing Cybersecurity in Morocco with Anomaly Detection:</p> <p><code>Opportunities:</code></p> <ol> <li>Threat Detection: ML and DL models can analyze network traffic, system logs, and user behavior to identify unusual patterns and behaviors that may indicate cyber threats. This enables early threat detection, reducing the risk of cyberattacks.</li> <li>Real-time Monitoring: Anomaly detection models can continuously monitor network activities and system processes in real-time, providing immediate alerts when suspicious activities are detected. This proactive approach helps prevent security breaches.</li> <li>Predictive Analysis: ML models can predict potential vulnerabilities and attack vectors by analyzing historical data. This allows organizations to patch vulnerabilities before they can be exploited by malicious actors.</li> <li>User Behavior Analysis: By monitoring user behavior, AI can detect anomalies in access patterns and alert system administrators to unauthorized access or misuse of resources.</li> <li>Malware Detection: DL models can be trained to recognize new and evolving malware strains, offering advanced protection against cyber threats.</li> </ol> <p><code>Challenges:</code></p> <ol> <li>Data Quality: Anomaly detection relies on high-quality, labeled data. Ensuring the accuracy and relevance of training data can be challenging, especially for rare or highly targeted cyber threats.</li> <li>False Positives: Overly sensitive anomaly detection systems can generate false positive alerts, which may overwhelm security teams. Fine-tuning these systems is essential to reduce false alarms.</li> <li>Resource Intensity: Implementing and maintaining ML and DL models require computational resources and expertise, which can be a challenge for organizations with limited budgets.</li> <li>Privacy Concerns: Monitoring user behavior and network activities raises privacy concerns, necessitating careful handling of data and compliance with data protection regulations.</li> <li>Cybersecurity Skills: Developing and maintaining AI-based cybersecurity solutions requires a skilled workforce with expertise in ML and DL techniques.</li> </ol> <p>By leveraging Anomaly Detection, Morocco can significantly enhance its cybersecurity posture. This approach not only safeguards critical infrastructure and sensitive data but also fosters a secure environment for business growth and digital innovation in the country.</p>"},{"location":"blogs/MA%20challenges/cybersecurity/#a-more-secure-and-resilient-morocco-awaits","title":"A More Secure and Resilient Morocco Awaits","text":"<p>By harnessing the power of Machine Learning and Deep Learning in cybersecurity, Morocco can strive to be a more secure and resilient digital nation. Stay tuned for more insights on how AI can drive development in our country.</p>"},{"location":"blogs/MA%20challenges/data_privacy/","title":"\ud83d\udee1\ufe0f Day 11: Prioritizing Data Privacy \ud83d\udee1\ufe0f","text":"<p>Welcome to the eleventh day of our <code>ML &amp; DL Morocco Challenges</code> series. Today, we address a critical aspect of the AI era: the importance of prioritizing data privacy and protection in Morocco.</p>"},{"location":"blogs/MA%20challenges/data_privacy/#the-significance-of-data-privacy","title":"The Significance of Data Privacy","text":"<p>In an age where data is a valuable resource, safeguarding privacy is essential. Data privacy matters for several reasons:</p> <p>\ud83d\udd39 Trust and Security: Prioritizing data privacy builds trust between individuals, businesses, and the government.</p> <p>\ud83d\udd39 Legal Compliance: Complying with data privacy laws is not only essential but also ensures that Morocco can participate in the global digital economy.</p> <p>\ud83d\udd39 Ethical Responsibility: Protecting personal data is an ethical obligation that underscores respect for individuals' rights.</p>"},{"location":"blogs/MA%20challenges/data_privacy/#data-privacy-in-morocco","title":"Data Privacy in Morocco","text":"<p>Morocco is making strides in establishing data privacy regulations and practices. It's crucial for the nation to create a robust legal framework that ensures data protection for its citizens and organizations. Challenges include raising awareness, data breach prevention, and enforcement of data privacy laws.</p>"},{"location":"blogs/MA%20challenges/data_privacy/#join-the-conversation","title":"Join the Conversation","text":"<p>How do you view the importance of data privacy in Morocco's digital transformation? What steps should be taken to strengthen data protection and ensure ethical data practices? Share your insights, experiences, and ideas in the comments below.</p>"},{"location":"blogs/MA%20challenges/data_privacy/#mr-belmady","title":"\ud83e\udde0 Mr BELMADY","text":"<p>Ensuring responsible AI practices in Morocco is crucial as the country embraces AI technologies. Here are specific strategies, including techniques in Machine Learning (ML) and Deep Learning (DL), that can help Morocco uphold ethical principles and safeguard data privacy while harnessing the potential of AI:</p> <ol> <li>Data Privacy Compliance:<ul> <li><code>Privacy-Preserving ML</code>: Implement techniques such as Federated Learning and Homomorphic Encryption to enable model training without exposing raw data, thereby safeguarding privacy.</li> </ul> </li> <li>Ethical AI Guidelines:<ul> <li><code>Develop Ethical Frameworks</code>: Establish guidelines and regulations that promote ethical AI practices, addressing issues such as bias, fairness, transparency, and accountability in AI algorithms.</li> </ul> </li> <li>Education and Awareness:<ul> <li><code>Ethics Training</code>: Integrate ethics and responsible AI components into ML and DL education programs to ensure that AI professionals are well-versed in ethical considerations.</li> </ul> </li> <li>Algorithmic Fairness:<ul> <li><code>Bias Mitigation</code>: Employ techniques like bias detection and mitigation to ensure AI models do not discriminate against specific groups, considering Morocco's diverse population.</li> </ul> </li> <li>Transparency and Explainability:<ul> <li><code>Interpretable Models</code>: Use techniques like LIME (Local Interpretable Model-agnostic Explanations) and SHAP (SHapley Additive exPlanations) to make AI models more interpretable and explainable.</li> </ul> </li> <li>Local Language and Cultural Relevance:<ul> <li><code>Localize AI Models</code>: Train AI models in Moroccan dialects and languages, ensuring that AI solutions are culturally relevant and respect local customs and values.</li> </ul> </li> <li>Third-party Audits:<ul> <li><code>Ethical Audits</code>: Conduct regular third-party audits of AI systems and algorithms to verify compliance with ethical and privacy standards.</li> </ul> </li> <li>Consent Mechanisms:<ul> <li><code>Dynamic Consent Models</code>: Develop dynamic consent mechanisms that allow individuals to control how their data is used in AI applications.</li> </ul> </li> <li>Data Governance:<ul> <li><code>Data Handling Protocols</code>: Establish robust data governance policies to protect sensitive information, including healthcare and financial data, by implementing access controls and encryption.</li> </ul> </li> <li>Collaboration and International Standards:<ul> <li><code>Collaboration with International Bodies</code>: Collaborate with international organizations and adhere to global standards for data privacy and ethical AI practices.</li> </ul> </li> <li>Public-Private Partnership:<ul> <li><code>Engage Private Sector</code>: Encourage public-private partnerships to ensure that businesses and organizations also adhere to ethical AI guidelines and data protection regulations.</li> </ul> </li> <li>Regulatory Framework:<ul> <li><code>AI Regulatory Authority</code>: Establish an authority responsible for regulating AI practices, ensuring compliance with ethical and privacy standards.</li> </ul> </li> <li>Data Anonymization:<ul> <li><code>Anonymization Techniques</code>: Implement data anonymization techniques to protect individual identities while allowing data to be used for AI training.</li> </ul> </li> </ol> <p>By incorporating these strategies and ML/DL techniques, Morocco can promote responsible AI practices, protect data privacy, and uphold ethical principles in the development and deployment of AI solutions. This, in turn, will help build trust in AI technologies and drive sustainable AI-driven development in the country.</p>"},{"location":"blogs/MA%20challenges/data_privacy/#a-safer-and-more-trustworthy-morocco-awaits","title":"A Safer and More Trustworthy Morocco Awaits","text":"<p>By prioritizing data privacy, Morocco can establish itself as a secure and responsible participant in the global digital ecosystem. Stay tuned for more insights on how AI can drive development in our country.</p>"},{"location":"blogs/MA%20challenges/education/","title":"\ud83e\udd16 Day 1: Education \ud83d\udcda","text":"<p>Welcome to the first day of our <code>ML &amp; DL Morocco Challenges</code> series. Today, we're delving into the pivotal role of Artificial Intelligence in education, a sector that shapes the future of our nation.</p>"},{"location":"blogs/MA%20challenges/education/#the-power-of-ai-in-education","title":"The Power of AI in Education","text":"<p>Quality education is the cornerstone of progress and development. With the advent of Artificial Intelligence (AI), we have the opportunity to revolutionize the way we learn and teach in Morocco. Here's how AI is making a significant impact on education:</p> <p>\ud83d\udd39 Personalized Learning: AI can customize learning experiences for individual students, adapting to their pace and style. This not only enhances comprehension but also fosters a deeper love for learning.</p> <p>\ud83d\udd39 Accessible Education: Through AI, educational content becomes more accessible to diverse learners, including those with disabilities. This inclusivity is a significant step towards democratizing education.</p> <p>\ud83d\udd39 Teacher Support: AI assists educators in various ways. From automating administrative tasks to providing data-driven insights about student performance, teachers can focus on what truly matters\u2014nurturing young minds.</p>"},{"location":"blogs/MA%20challenges/education/#the-moroccan-perspective","title":"The Moroccan Perspective","text":"<p>In Morocco, AI in education has the potential to bridge the gap in access to quality education. Whether it's improving literacy rates or preparing our youth for the digital age, the possibilities are endless. But, of course, challenges lie ahead, including access to technology, curriculum adaptation, and digital literacy.</p>"},{"location":"blogs/MA%20challenges/education/#join-the-conversation","title":"Join the Conversation","text":"<p>How do you envision AI transforming education in Morocco? What role can it play in addressing the unique challenges our educational system faces? Share your thoughts in the comments and let's start a meaningful dialogue.</p>"},{"location":"blogs/MA%20challenges/education/#mr-belmady","title":"\ud83e\udde0 Mr BELMADY","text":"<p>Integrating Adaptive Machine Learning into educational platforms involves implementing algorithms that can understand and process the collected data, enabling automated predictive analysis. Here's how this integration can be achieved:</p> <ol> <li>Data Collection and Assessment: The first step is to gather relevant data about the learners. This data can include their past performance, learning preferences, and areas of strength and weakness. Educational platforms can collect this data through various means, including quizzes, assignments, and learner interactions with the platform.</li> <li>Feature Engineering: Once the data is collected, it needs to be pre-processed to extract meaningful features. Feature engineering involves selecting the data attributes that are most relevant for understanding a learner's needs and progress. This step ensures that the data is in a suitable format for machine learning algorithms.</li> <li>Machine Learning Models: Adaptive Machine Learning relies on machine learning models that can make predictions and decisions based on the collected data. Algorithms such as decision trees, neural networks, and reinforcement learning models can be used to develop a predictive model that adapts to each learner's needs.</li> <li>Training and Validation: The machine learning model is trained using historical data to learn patterns and relationships within the data. It is essential to validate the model's performance to ensure that it can make accurate predictions.</li> <li>Real-Time Adaptation: As learners interact with the educational platform, their actions and progress are continuously fed into the machine learning model. The model uses this real-time data to adapt and personalize the learning experience for each individual. For example, if a learner is struggling with a particular topic, the system can provide additional resources or practice exercises in that area.</li> <li>Feedback Loop: The adaptive learning system should include a feedback loop where the model's recommendations and adaptations are continually evaluated. If a suggestion does not lead to improved learning outcomes, the system can adjust its recommendations accordingly.</li> <li>User Interface Integration: The adaptive learning features need to be seamlessly integrated into the user interface of the educational platform. Learners should be able to access personalized recommendations, progress tracking, and additional resources in a user-friendly manner.</li> <li>Scalability and Maintenance: To ensure the scalability of the platform, the algorithms and infrastructure should be designed to handle a growing user base. Regular maintenance and updates are also crucial to keep the adaptive learning system effective and up to date.</li> <li>Data Privacy and Security: It's essential to prioritize data privacy and security. Protecting the personal information and learning data of users is of utmost importance. Compliance with data protection regulations and encryption techniques should be implemented.</li> </ol> <p>By integrating Adaptive Machine Learning into educational platforms, we can create a more personalized, effective, and accessible learning experience for all learners, allowing the system to adapt to individual needs and enhance overall educational outcomes. This approach can help bridge educational gaps and support diverse learning styles, ultimately benefiting Moroccan students and learners worldwide.</p>"},{"location":"blogs/MA%20challenges/education/#mr-mouchane","title":"\ud83e\udde0 Mr MOUCHANE","text":"<p>Unlike reputable foreign textbooks, most Moroccan textbooks do not come with digital materials like extra PDF practice worksheets or software that students could use to practice and become independent learners.</p> <p>I believe it is easier and cost-effective to use Machine Learning to generate such E-learning documents or software and apps for existing textbooks that lack these digital resources instead of starting from scratch.</p>"},{"location":"blogs/MA%20challenges/education/#a-brighter-future-awaits","title":"A Brighter Future Awaits","text":"<p>By harnessing the potential of Machine Learning and Deep Learning in education, Morocco can equip its youth with the skills and knowledge needed to thrive in an ever-changing world. Stay tuned for more insights on how AI can drive development in our country.</p>"},{"location":"blogs/MA%20challenges/energy/","title":"\u26a1 Day 5: Sustainable Energy\u26a1","text":"<p>Welcome to the fifth day of our <code>ML &amp; DL Morocco Challenges</code> series. Today, we venture into the world of sustainable energy and how Artificial Intelligence is powering the transformation of energy sources in Morocco.</p>"},{"location":"blogs/MA%20challenges/energy/#ais-role-in-sustainable-energy","title":"AI's Role in Sustainable Energy","text":"<p>Sustainability and renewable energy are key to Morocco's future. Artificial Intelligence is driving innovation and efficiency in the energy sector:</p> <p>\ud83d\udd39 Smart Grids: AI optimizes the distribution of electricity in smart grids, reducing wastage and increasing reliability.</p> <p>\ud83d\udd39 Renewable Energy Forecasting: AI can predict energy production from renewable sources, helping balance supply and demand.</p> <p>\ud83d\udd39 Energy Efficiency: AI-driven solutions help reduce energy consumption in industries and households, contributing to a greener environment.</p>"},{"location":"blogs/MA%20challenges/energy/#moroccos-clean-energy-vision","title":"Morocco's Clean Energy Vision","text":"<p>Morocco has set ambitious targets for renewable energy adoption. AI can help us achieve these goals by making energy production more predictable and efficient. Challenges like infrastructure development and policy support must be addressed to fully realize this potential.</p> <p>Join the Conversation</p> <p>How do you envision AI's role in shaping a sustainable energy landscape in Morocco? What challenges and opportunities can AI address to accelerate our transition to clean energy? Share your insights and experiences in the comments below.</p>"},{"location":"blogs/MA%20challenges/energy/#mr-belmady","title":"\ud83e\udde0 Mr BELMADY","text":"<p>AI technologies, particularly Machine Learning (ML) and Deep Learning (DL), can significantly accelerate Morocco's transition to sustainable energy sources. One specific technique within this domain is Predictive Maintenance for Renewable Energy Systems. Here's how it can contribute to Morocco's sustainable energy development:</p> <p>Predictive Maintenance for Renewable Energy Systems:</p> <ol> <li>Optimizing Energy Production:<ul> <li>ML algorithms can predict when and where energy systems, such as solar panels or wind turbines, are likely to require maintenance. By identifying issues before they cause downtime, AI ensures that renewable energy systems operate at maximum efficiency.</li> </ul> </li> <li>Minimizing Downtime:<ul> <li>AI can anticipate equipment failures, enabling proactive maintenance that reduces unplanned downtime. This is critical for maximizing the energy output of renewable sources and ensuring a stable power supply.</li> </ul> </li> <li>Resource Efficiency:<ul> <li>By monitoring renewable energy infrastructure, AI helps optimize resource usage, reducing waste and improving the lifespan of equipment. This is particularly crucial for the sustainability of these systems.</li> </ul> </li> <li>Weather Predictions:<ul> <li>ML can analyze weather data and predict patterns to help renewable energy systems adapt to changing weather conditions. For instance, predictive models can adjust solar panel angles or wind turbine blade orientations for optimal energy production.</li> </ul> </li> <li>Energy Storage Management:<ul> <li>DL models can optimize the charging and discharging of energy storage systems, such as batteries, ensuring efficient use of stored energy and reducing grid strain.</li> </ul> </li> <li>Grid Management:<ul> <li>ML can assist in managing the integration of renewable energy into the national grid. Predictive models help anticipate energy surpluses or shortages, allowing for a smoother transition to sustainable energy sources.</li> </ul> </li> <li>Cost Reduction:<ul> <li>Predictive maintenance reduces operational costs, as it minimizes the need for emergency repairs and reduces overall maintenance expenses.</li> </ul> </li> <li>Sustainability Reporting:<ul> <li>AI can provide real-time data on energy production and environmental impact, assisting in sustainability reporting and ensuring compliance with renewable energy goals.</li> </ul> </li> </ol> <p>By adopting Predictive Maintenance techniques within the framework of ML and DL, Morocco can significantly enhance the efficiency and reliability of its renewable energy systems. This not only accelerates the transition to sustainable energy sources but also strengthens the country's position as a leader in clean energy production and environmental stewardship.</p> <p>A Greener and More Sustainable Morocco Awaits</p> <p>By harnessing the potential of Machine Learning and Deep Learning in the energy sector, Morocco can advance towards a future powered by clean and renewable energy sources. Stay tuned for more insights on how AI can drive development in our country.</p>"},{"location":"blogs/MA%20challenges/finance/","title":"\ud83d\udcb0 Day 4: Financial Inclusion \ud83d\udcb0","text":"<p>Welcome to the fourth day of our <code>ML &amp; DL Morocco Challenges</code> series. Today, we dive into the realm of financial inclusion, exploring how Artificial Intelligence is reshaping access to financial services in Morocco.</p>"},{"location":"blogs/MA%20challenges/finance/#ai-and-financial-inclusion","title":"AI and Financial Inclusion","text":"<p>Financial inclusion is not just about banking; it's about ensuring that all individuals and businesses have access to affordable, useful, and relevant financial services. Artificial Intelligence is playing a pivotal role in achieving this goal:</p> <p>\ud83d\udd39 Credit Scoring: AI algorithms can analyze non-traditional data to assess creditworthiness, opening up opportunities for those previously excluded from the credit system.</p> <p>\ud83d\udd39 Digital Payments: AI-powered digital payment platforms make financial transactions easier and more accessible, even for those without a traditional bank account.</p> <p>\ud83d\udd39 Risk Management: AI enhances fraud detection and risk assessment, making it safer for institutions to provide financial services to underserved populations.</p>"},{"location":"blogs/MA%20challenges/finance/#financial-inclusion-in-morocco","title":"Financial Inclusion in Morocco","text":"<p>In Morocco, financial inclusion is essential for economic growth and poverty reduction. AI has the potential to bring unbanked and underbanked individuals into the formal financial system. However, we must address challenges like digital literacy, infrastructure, and regulations.</p>"},{"location":"blogs/MA%20challenges/finance/#join-the-conversation","title":"Join the Conversation","text":"<p>How do you see AI driving financial inclusion in Morocco? What unique challenges and opportunities does our nation face in this regard? Share your thoughts and experiences in the comments below.</p>"},{"location":"blogs/MA%20challenges/finance/#mr-belmady","title":"\ud83e\udde0 Mr BELMADY","text":"<p>AI can play a pivotal role in enhancing financial inclusion in Morocco, and one specific technique that holds great promise in this context is Natural Language Processing (NLP). Here's how AI, particularly NLP, can contribute to financial inclusion:</p> <p>Leveraging NLP for Financial Inclusion in Morocco:</p> <ol> <li>Digital Customer Support:<ul> <li>NLP-powered chatbots and virtual assistants can provide 24/7 support for individuals seeking information about financial services, helping them navigate the complexities of banking, insurance, and investment.</li> </ul> </li> <li>Language Accessibility:<ul> <li>Given the linguistic diversity in Morocco, NLP can assist in offering financial services and educational materials in multiple languages, making it more accessible for individuals who may not be fluent in a specific language.</li> </ul> </li> <li>Credit Scoring and Risk Assessment:<ul> <li>ML models can analyze alternative data sources, such as social media activity and mobile phone usage, to build credit profiles for individuals who lack traditional credit histories. This enables more people to access loans and financial services.</li> </ul> </li> <li>Fraud Detection:<ul> <li>ML algorithms can detect fraudulent activities in real-time, safeguarding the financial assets of individuals and financial institutions. This, in turn, builds trust in the financial system.</li> </ul> </li> <li>Personalized Financial Recommendations:<ul> <li>NLP can analyze an individual's financial history and preferences to provide tailored recommendations for savings, investments, and financial planning.</li> </ul> </li> <li>Financial Education:<ul> <li>AI-powered chatbots can deliver financial literacy content and answer questions, helping people make informed financial decisions.</li> </ul> </li> <li>Accessibility to Government Services:<ul> <li>NLP can facilitate access to government services, including subsidy programs and financial aid, ensuring that all eligible citizens can benefit from these initiatives.</li> </ul> </li> <li>Branchless Banking:<ul> <li>NLP interfaces can make it easier for individuals to access their bank accounts, transfer funds, and make payments using simple, natural language commands via text or voice.</li> </ul> </li> </ol> <p>By leveraging NLP and AI technologies, Morocco can significantly expand financial inclusion, ensuring that individuals from all walks of life have access to a broader range of financial services. This not only fosters economic development but also empowers individuals and communities by promoting financial literacy and independence.</p>"},{"location":"blogs/MA%20challenges/finance/#a-more-inclusive-financial-future-awaits","title":"A More Inclusive Financial Future Awaits","text":"<p>By harnessing the power of Machine Learning and Deep Learning, Morocco can work towards a more inclusive and prosperous financial landscape. Stay tuned for more insights on how AI can drive development in our country.</p>"},{"location":"blogs/MA%20challenges/healthcare/","title":"\ud83c\udfe5 Day 2: Healthcare Transformation \ud83c\udfe5","text":"<p>Welcome to the second day of our <code>ML &amp; DL Morocco Challenges</code> series. Today, we explore the profound impact of Artificial Intelligence on healthcare, a sector that holds the key to the well-being of our nation.</p>"},{"location":"blogs/MA%20challenges/healthcare/#ai-revolution-in-healthcare","title":"AI Revolution in Healthcare","text":"<p>In Morocco, just as in the rest of the world, healthcare is being transformed by the capabilities of Artificial Intelligence. AI is proving to be a game-changer in healthcare for several reasons:</p> <p>\ud83d\udd39 Early Diagnosis: AI can analyze medical data swiftly and accurately, aiding in the early detection of diseases and medical conditions, potentially saving lives.</p> <p>\ud83d\udd39 Treatment Personalization: AI tailors treatments to individual patient needs, optimizing effectiveness while minimizing side effects.</p> <p>\ud83d\udd39 Data Management: AI streamlines medical record-keeping and data management, reducing administrative burdens and enhancing patient care.</p>"},{"location":"blogs/MA%20challenges/healthcare/#the-moroccan-perspective","title":"The Moroccan Perspective","text":"<p>For Morocco, AI offers the potential to significantly improve healthcare accessibility, especially in rural areas. Telemedicine and AI-driven diagnostics can bring quality medical care to those who were previously underserved. However, we must address challenges such as data security and infrastructure development to make this a reality.</p>"},{"location":"blogs/MA%20challenges/healthcare/#join-the-conversation","title":"Join the Conversation","text":"<p>How do you envision AI transforming healthcare in Morocco? What are the unique healthcare challenges and opportunities that AI can address in our nation? Share your insights and experiences in the comments below.</p>"},{"location":"blogs/MA%20challenges/healthcare/#mr-belmady","title":"\ud83e\udde0 Mr BELMADY","text":"<p>I envision AI, specifically Machine Learning (ML) and Deep Learning (DL), revolutionizing healthcare in Morocco in several impactful ways. One particular technique that can significantly contribute to Morocco's healthcare development is Computer Vision, a subset of ML and DL.</p> <ol> <li>Medical Image Analysis with Computer Vision: ML and DL algorithms, particularly in the domain of Computer Vision, can be applied to analyze medical images such as X-rays, MRIs, and CT scans. This can have a profound impact on healthcare in Morocco by:<ul> <li><code>Faster and More Accurate Diagnoses</code>: Computer Vision algorithms can quickly and accurately identify anomalies or diseases in medical images, assisting healthcare professionals in making timely and precise diagnoses.</li> <li><code>Increased Accessibility</code>: These algorithms can help bridge the gap between urban and rural healthcare facilities by allowing remote healthcare centers to transmit images to experts for analysis, reducing the need for patients to travel long distances for consultations.</li> <li><code>Early Disease Detection</code>: ML and DL can detect early signs of diseases, which is crucial for preventive healthcare and reducing the burden of advanced-stage treatments.</li> <li><code>Improving Radiology Services</code>: Automating image analysis tasks can free up radiologists' time for more complex cases and reduce the risk of human error.</li> </ul> </li> <li>Patient Monitoring and Personalized Treatment: ML and DL can analyze patient data, including electronic health records, vital signs, and genomics, to:<ul> <li><code>Enable Personalized Medicine</code>: Algorithms can help tailor treatment plans to individual patients, accounting for genetic variations and treatment response prediction.</li> <li><code>Remote Monitoring</code>: In a large country like Morocco, where access to healthcare can be challenging, remote patient monitoring through wearable devices can help manage chronic conditions and track patient health over time.</li> </ul> </li> <li>Healthcare Resource Management: ML and DL can optimize healthcare resource allocation:<ul> <li><code>Patient Triage</code>: ML algorithms can assist in patient triage by predicting the urgency of cases, ensuring that critical patients receive immediate attention.</li> <li><code>Supply Chain Management</code>: Predictive analytics can be used to optimize the procurement and distribution of medical supplies and drugs, ensuring their availability where needed.</li> </ul> </li> <li>Language Processing for Healthcare: Natural Language Processing (NLP), another ML and DL technique, can be applied to medical records and doctor-patient communication:<ul> <li><code>EHR Data Extraction</code>: NLP can extract valuable insights from electronic health records, improving data utilization and decision-making.</li> <li><code>Multilingual Support</code>: Given Morocco's linguistic diversity, NLP can assist in doctor-patient communication by providing real-time translation services.</li> </ul> </li> <li>Disease Outbreak Prediction: ML models can analyze data on population movements, environmental factors, and historical health data to predict disease outbreaks, which is critical for timely responses and prevention.</li> </ol> <p>By harnessing the power of Computer Vision, Natural Language Processing, and other ML/DL techniques, Morocco's healthcare system can become more efficient, accessible, and effective. This not only improves patient care but also contributes to the development of the healthcare infrastructure and expertise in the country.</p>"},{"location":"blogs/MA%20challenges/healthcare/#a-healthier-morocco-awaits","title":"A Healthier Morocco Awaits","text":"<p>By harnessing the potential of Machine Learning and Deep Learning in healthcare, Morocco can strive for a healthier population, improved medical access, and innovative healthcare solutions. Stay tuned for more insights on how AI can drive development in our country.</p>"},{"location":"blogs/MA%20challenges/innovation/","title":"\ud83d\ude80 Day 7: Empowering Innovation \ud83d\ude80","text":"<p>Welcome to the seventh day of our <code>ML &amp; DL Morocco Challenges</code> series. Today, we're setting our sights on the limitless world of innovation, where Artificial Intelligence serves as a catalyst for progress.</p>"},{"location":"blogs/MA%20challenges/innovation/#ais-impact-on-innovation","title":"AI's Impact on Innovation","text":"<p>Innovation drives economic growth and prosperity. Artificial Intelligence is becoming a central force in fostering innovation:</p> <p>\ud83d\udd39 Product Development: AI accelerates product development by analyzing market trends and consumer needs.</p> <p>\ud83d\udd39 Process Optimization: AI streamlines operations, reducing costs and improving efficiency.</p> <p>\ud83d\udd39 Data-Driven Insights: AI uncovers valuable insights within vast datasets, unlocking new possibilities.</p>"},{"location":"blogs/MA%20challenges/innovation/#moroccos-innovation-ambitions","title":"Morocco's Innovation Ambitions","text":"<p>Morocco is poised to make significant strides in innovation. AI empowers startups, businesses, and institutions to embrace innovation as a core driver of growth. Challenges include fostering an innovation-friendly ecosystem, access to funding, and nurturing a culture of creativity.</p>"},{"location":"blogs/MA%20challenges/innovation/#join-the-conversation","title":"Join the Conversation","text":"<p>How do you envision AI powering innovation in Morocco? What innovative ventures are you excited about in our nation's development journey? Share your thoughts, experiences, and ideas in the comments below.</p>"},{"location":"blogs/MA%20challenges/innovation/#a-future-of-unbounded-possibilities-awaits","title":"A Future of Unbounded Possibilities Awaits","text":"<p>By harnessing the power of Machine Learning and Deep Learning in innovation, Morocco can aspire to be a hub of creativity, entrepreneurship, and groundbreaking ideas. Stay tuned for more insights on how AI can drive development in our country.</p>"},{"location":"blogs/MA%20challenges/public_services/","title":"\ud83c\udfdb\ufe0f Day 8: Transforming Public Services \ud83c\udfdb\ufe0f","text":"<p>Welcome to the eighth day of our <code>ML &amp; DL Morocco Challenges</code> series. Today, we explore the dynamic role of Artificial Intelligence in the transformation of public services, a sector at the heart of our nation's progress.</p>"},{"location":"blogs/MA%20challenges/public_services/#ais-impact-on-public-services","title":"AI's Impact on Public Services","text":"<p>Public services are the backbone of any nation, and AI is poised to make them more efficient and citizen-centric:</p> <p>\ud83d\udd39 Smart Governance: AI streamlines administrative processes, reducing bureaucracy and improving service delivery.</p> <p>\ud83d\udd39 Citizen Engagement: AI tools enable better communication and interaction between citizens and public authorities.</p> <p>\ud83d\udd39 Data-Driven Decision Making: AI-driven insights help public officials make informed policy decisions.</p>"},{"location":"blogs/MA%20challenges/public_services/#moroccos-vision-for-enhanced-public-services","title":"Morocco's Vision for Enhanced Public Services","text":"<p>Morocco aims to provide better, more accessible public services to its citizens. AI can play a pivotal role in this journey by automating tasks, enhancing transparency, and ensuring inclusivity. Challenges include data privacy, digital literacy, and infrastructure development.</p>"},{"location":"blogs/MA%20challenges/public_services/#join-the-conversation","title":"Join the Conversation","text":"<p>How do you see AI revolutionizing public services in Morocco? What are the unique challenges and opportunities that our nation faces as we seek to enhance service delivery to citizens? Share your insights, experiences, and ideas in the comments below.</p>"},{"location":"blogs/MA%20challenges/public_services/#mr-belmady","title":"\ud83e\udde0 Mr BELMADY","text":"<p>I envision AI, particularly Machine Learning (ML) and Deep Learning (DL), transforming public services in Morocco through a specific technique known as Natural Language Processing (NLP). NLP can play a pivotal role in enhancing the accessibility, efficiency, and effectiveness of public services in Morocco in the following ways:</p> <p>NLP for Public Services Transformation in Morocco:</p> <ol> <li>Multilingual Service Delivery: Morocco's linguistic diversity can be addressed with NLP-powered chatbots and virtual assistants capable of providing services and information in multiple languages. This ensures that all citizens, regardless of their language preference, can access public services seamlessly.</li> <li>Improved Communication: NLP can automate and streamline communication with citizens through email, chat, or voice interfaces. This leads to faster response times and more efficient interactions, making public services more accessible to a broader audience.</li> <li>Efficient Document Processing: NLP can be used to automatically extract information from documents, reducing manual data entry and streamlining administrative processes. This efficiency can lead to faster service delivery and reduced administrative overhead.</li> <li>Data Analytics for Decision-Making: NLP models can analyze unstructured text data from citizen feedback, surveys, and social media to extract insights and sentiment analysis. This data-driven decision-making helps public agencies identify areas for improvement and respond to citizen needs more effectively.</li> </ol> <p><code>Challenges and Considerations:</code></p> <ol> <li>Data Privacy and Security: Handling sensitive citizen data necessitates stringent security and privacy measures. Public agencies must ensure that NLP applications comply with data protection regulations.</li> <li>Resource Investment: Implementing NLP technology requires investment in both technology and skilled professionals. Public agencies need to allocate resources for infrastructure, software, and talent.</li> <li>Language Diversity: Ensuring NLP systems understand and process various Moroccan dialects can be a complex task, but it's essential for effective service delivery.</li> <li>Regulatory Compliance: Public services must navigate legal and regulatory requirements related to data handling and language localization.</li> </ol> <p>By embracing NLP within the AI framework, Morocco's public services can be transformed to be more inclusive, efficient, and responsive to citizens' needs. This approach not only modernizes the public sector but also contributes to the overall development and progress of the country.</p>"},{"location":"blogs/MA%20challenges/public_services/#a-more-efficient-and-citizen-centric-morocco-awaits","title":"A More Efficient and Citizen-Centric Morocco Awaits","text":"<p>By harnessing the power of Machine Learning and Deep Learning in public services, Morocco can aspire to provide efficient, transparent, and inclusive services to its citizens. Stay tuned for more insights on how AI can drive development in our country.</p>"},{"location":"blogs/MA%20challenges/transportation/","title":"\ud83d\ude97 Day 6: Smart Transportation \ud83d\ude97","text":"<p>Welcome to the sixth day of our <code>ML &amp; DL Morocco Challenges</code> series. Today, we hit the road to explore the future of smart transportation in Morocco, where Artificial Intelligence is steering the way.</p>"},{"location":"blogs/MA%20challenges/transportation/#the-ai-drive-in-smart-transportation","title":"The AI Drive in Smart Transportation","text":"<p>Transportation is at the heart of economic growth and societal well-being. AI is transforming the way we move and commute:</p> <p>\ud83d\udd39 Traffic Management: AI optimizes traffic flow, reducing congestion and making commutes more efficient.</p> <p>\ud83d\udd39 Autonomous Vehicles: AI-driven self-driving cars promise safer and more convenient travel.</p> <p>\ud83d\udd39 Eco-Friendly Transport: AI helps reduce emissions by optimizing routes and promoting eco-friendly modes of transportation.</p>"},{"location":"blogs/MA%20challenges/transportation/#moroccos-transportation-revolution","title":"Morocco's Transportation Revolution","text":"<p>In Morocco, smart transportation is crucial for addressing urbanization and improving connectivity. AI offers solutions to ease traffic challenges and enhance the overall transportation experience. However, we must consider infrastructure development, regulations, and data security.</p>"},{"location":"blogs/MA%20challenges/transportation/#join-the-conversation","title":"Join the Conversation","text":"<p>How do you envision AI transforming transportation in Morocco? What specific challenges and opportunities are you excited about in our journey towards smarter and more efficient transportation? Share your thoughts and experiences in the comments below.</p>"},{"location":"blogs/MA%20challenges/transportation/#mr-belmady","title":"\ud83e\udde0 Mr BELMADY","text":"<p>AI, particularly Machine Learning (ML) and Deep Learning (DL), will play a pivotal role in shaping the future of transportation in Morocco. One specific technique that can contribute significantly to Morocco's transportation development is Smart Traffic Management.</p> <p>Smart Traffic Management for the Future of Transportation in Morocco:</p> <ol> <li>Traffic Optimization:<ul> <li>ML algorithms can analyze real-time traffic data to optimize traffic flow, reduce congestion, and improve overall road efficiency. This is crucial for Morocco's urban areas, which often face traffic challenges.</li> </ul> </li> <li>Reduced Accidents:<ul> <li>DL models can predict and prevent accidents by continuously monitoring traffic and identifying potential hazards. AI-driven systems can react more quickly and accurately than humans, leading to fewer accidents on Moroccan roads.</li> </ul> </li> <li>Eco-Friendly Transportation:<ul> <li>AI can promote energy-efficient transportation by optimizing routes and driving patterns, reducing fuel consumption and emissions. This aligns with Morocco's commitment to sustainability and environmental conservation.</li> </ul> </li> <li>Public Transportation Enhancement:<ul> <li>ML and DL can be applied to improve public transportation systems, including buses and trains. This can include optimizing routes and schedules for better accessibility and convenience, particularly in densely populated areas.</li> </ul> </li> <li>Traffic Light Synchronization:<ul> <li>AI-driven systems can synchronize traffic lights based on real-time traffic data, reducing waiting times and minimizing idling, thus saving fuel and reducing emissions.</li> </ul> </li> <li>Safety Enhancements:<ul> <li>DL algorithms can continuously learn and adapt to road conditions, enhancing vehicle safety. This is critical for the safety of Moroccan travelers and supports the reduction of road accidents.</li> </ul> </li> <li>Data-Driven Decision-Making:<ul> <li>ML and DL can provide insights into transportation patterns and preferences, aiding in the development of effective transportation policies and urban planning.</li> </ul> </li> <li>Infrastructure Integration:<ul> <li>AI can facilitate the integration of transportation systems with smart city infrastructure, such as sensors and data-sharing platforms. This enhances transportation efficiency and safety.</li> </ul> </li> <li>Predictive Maintenance:<ul> <li>ML can be applied to predict maintenance needs for vehicles and infrastructure, reducing breakdowns and ensuring smooth transportation services.</li> </ul> </li> </ol> <p>By implementing Smart Traffic Management solutions driven by ML and DL techniques, Morocco can modernize its transportation systems, making them more efficient, eco-friendly, and safe. This approach not only improves the quality of life for Moroccan citizens but also contributes to economic development, as efficient transportation systems are essential for a thriving economy.</p>"},{"location":"blogs/MA%20challenges/transportation/#a-smoother-and-more-connected-morocco-awaits","title":"A Smoother and More Connected Morocco Awaits","text":"<p>By harnessing the power of Machine Learning and Deep Learning in transportation, Morocco can aspire to have smarter, more efficient, and eco-friendly mobility solutions. Stay tuned for more insights on how AI can drive development in our country.</p>"},{"location":"projects/Painting%20Vermeer/","title":"Algorithmes G\u00e9n\u00e9tiques 2: Peindre Vermeer","text":""},{"location":"projects/Painting%20Vermeer/#introduction","title":"Introduction","text":"<p>Packages</p> <p>Les Algorithmes G\u00e9n\u00e9tiques 2: Peindre Vermeer est un probl\u00e8me dans lequel un algorithme g\u00e9n\u00e9tique peut \u00eatre appliqu\u00e9. L'objectif est de cr\u00e9er une peinture g\u00e9n\u00e9r\u00e9e par ordinateur qui ressemble \u00e0 une peinture du c\u00e9l\u00e8bre peintre hollandais Johannes Vermeer.</p> <p>Pour appliquer un algorithme g\u00e9n\u00e9tique \u00e0 ce probl\u00e8me, nous devons d\u00e9finir un ensemble de g\u00e8nes, qui repr\u00e9sentent dans ce cas la couleur et la position de chaque coup de pinceau. Chaque individu de la population serait une peinture cr\u00e9\u00e9e en combinant les g\u00e8nes d'une mani\u00e8re particuli\u00e8re. La fonction d'adaptation serait utilis\u00e9e pour \u00e9valuer dans quelle mesure chaque peinture ressemble \u00e0 une v\u00e9ritable peinture de Vermeer.</p> <p>L'algorithme g\u00e9n\u00e9tique serait ensuite appliqu\u00e9 de la mani\u00e8re suivante :</p> <ol> <li> <p>Initialisation : G\u00e9n\u00e9rer une population initiale d'individus al\u00e9atoires.</p> </li> <li> <p>\u00c9valuation : \u00c9valuer la qualit\u00e9 de chaque individu en utilisant la fonction d'adaptation.</p> </li> <li> <p>S\u00e9lection : S\u00e9lectionner un sous-ensemble d'individus de la population pour servir de parents \u00e0 la prochaine g\u00e9n\u00e9ration.</p> </li> <li> <p>Croisement : Combiner les g\u00e8nes des parents s\u00e9lectionn\u00e9s pour cr\u00e9er de nouveaux individus.</p> </li> <li> <p>Mutation : Introduire des changements al\u00e9atoires dans les g\u00e8nes des nouveaux individus.</p> </li> <li> <p>Remplacement : Remplacer certains individus de la population actuelle par les nouveaux individus.</p> </li> <li> <p>Condition d'arr\u00eat : V\u00e9rifier si la condition d'arr\u00eat a \u00e9t\u00e9 atteinte. Si ce n'est pas le cas, revenir \u00e0 l'\u00e9tape 2.</p> </li> </ol> <p>Dans le cas de la peinture de Vermeer, la condition d'arr\u00eat pourrait \u00eatre un nombre maximal de g\u00e9n\u00e9rations ou un niveau d'adaptation seuil.</p> <p>En appliquant ces \u00e9tapes de mani\u00e8re it\u00e9rative, l'algorithme g\u00e9n\u00e9tique am\u00e9liorera progressivement la qualit\u00e9 des peintures dans la population. Au fil du temps, l'algorithme peut converger vers une peinture qui ressemble \u00e9troitement \u00e0 une peinture de Vermeer.</p>"},{"location":"projects/Painting%20Vermeer/#importer-les-packages","title":"Importer les Packages","text":"<p>Packages</p> <ul> <li> <p>os : est une biblioth\u00e8que standard de Python qui permet d'interagir avec le syst\u00e8me d'exploitation sous-jacent. Il fournit des fonctionnalit\u00e9s pour effectuer des op\u00e9rations li\u00e9es aux fichiers et aux r\u00e9pertoires, \u00e0 l'environnement syst\u00e8me, aux processus, etc.</p> </li> <li> <p>NumPy : NumPy est une biblioth\u00e8que Python populaire pour le calcul scientifique qui fournit des structures de donn\u00e9es pour la repr\u00e9sentation de tableaux multidimensionnels et des fonctions pour manipuler ces tableaux.</p> </li> <li> <p>random : The random module in Python provides a suite of functions for generating random numbers.</p> </li> <li> <p>colour : est une biblioth\u00e8que de gestion des couleurs qui offre des fonctionnalit\u00e9s pour la manipulation, la conversion et la repr\u00e9sentation des couleurs dans diff\u00e9rents espaces colorim\u00e9triques.</p> </li> <li> <p>json : cette biblioth\u00e8que permet de travailler avec des donn\u00e9es au format JSON (JavaScript Object Notation). Le module json offre des fonctions pour la s\u00e9rialisation (encodage) et la d\u00e9s\u00e9rialisation (d\u00e9codage) des objets Python en JSON et vice versa.</p> </li> <li> <p>Pygame : est une biblioth\u00e8que Python populaire utilis\u00e9e pour d\u00e9velopper des jeux vid\u00e9o et des applications multim\u00e9dias interactives. Elle fournit des fonctionnalit\u00e9s pour la cr\u00e9ation de graphismes, la gestion des \u00e9v\u00e9nements, le traitement du son, la gestion des entr\u00e9es utilisateur et bien plus encore.</p> </li> </ul> <pre><code>import os\nimport numpy as np\nfrom numpy.random import choice, random, normal\nfrom colour import Color\nimport json\nimport pygame\n</code></pre>"},{"location":"projects/Painting%20Vermeer/#initialiser-un-organisme","title":"Initialiser un organisme","text":"<p>Organism</p> <p>Ce code d\u00e9finit la classe <code>Organism</code> (Organisme) qui repr\u00e9sente un organisme avec un ensemble de g\u00e8nes. Elle a les attributs suivants :</p> <p>chromosome: un tableau numpy repr\u00e9sentant les g\u00e8nes de l'organisme. Les valeurs des g\u00e8nes sont limit\u00e9es entre 0 et 1 \u00e0 l'aide de np.clip(genes, 0, 1).</p> <p>visual: une variable utilis\u00e9e pour stocker une repr\u00e9sentation visuelle de l'organisme (probablement une image).</p> <p>fitness: une variable utilis\u00e9e pour stocker la valeur de fitness de l'organisme.</p> <p>La classe <code>Organism</code> a \u00e9galement une m\u00e9thode <code>mutate</code> qui effectue une mutation sur l'organisme. Les param\u00e8tres rate, scale et add sont les taux de mutation et d'ajout, ainsi que l'\u00e9chelle de mutation utilis\u00e9s dans le processus de mutation. Voici ce que fait la m\u00e9thode <code>mutate</code> :</p> <ul> <li> <p>Elle effectue une copie du chromosome de l'organisme en utilisant np.copy(self.chromosome).</p> </li> <li> <p>Elle d\u00e9termine le nombre de mutations \u00e0 effectuer en fonction du taux de mutation : num_mutations = 1 + int(rate * n_gene).</p> </li> <li> <p>Elle it\u00e8re sur le nombre de mutations et effectue les mutations suivantes :</p> <ul> <li> <p>Si le r\u00e9sultat de random() &gt; add est True, une mutation sur un g\u00e8ne existant est effectu\u00e9e.</p> <ul> <li> <p>Un indice i est choisi al\u00e9atoirement \u00e0 partir des indices de caract\u00e9ristiques (n_feat).</p> </li> <li> <p>Une valeur al\u00e9atoire est ajout\u00e9e \u00e0 la caract\u00e9ristique s\u00e9lectionn\u00e9e dans un g\u00e8ne s\u00e9lectionn\u00e9 al\u00e9atoirement dans le chromosome.</p> </li> <li> <p>Si l'indice est 3, la valeur de cette caract\u00e9ristique est modulo 1.</p> </li> </ul> </li> <li> <p>Sinon, une op\u00e9ration d'ajout ou de suppression d'un g\u00e8ne est effectu\u00e9e.</p> <ul> <li>Si random() &lt; 0.3, un g\u00e8ne est supprim\u00e9 al\u00e9atoirement du chromosome. Sinon, deux g\u00e8nes existants sont s\u00e9lectionn\u00e9s al\u00e9atoirement pour cr\u00e9er un nouveau g\u00e8ne. Le nouveau g\u00e8ne est obtenu en faisant la moyenne des deux g\u00e8nes s\u00e9lectionn\u00e9s et en ajoutant une perturbation. La troisi\u00e8me caract\u00e9ristique du nouveau g\u00e8ne est multipli\u00e9e par 0.2.</li> </ul> </li> </ul> </li> <li> <p>Enfin, la m\u00e9thode renvoie un nouvel objet <code>Organism</code> avec le chromosome mut\u00e9.</p> </li> </ul> <pre><code>class Organism:\n    def __init__(self, genes):\n        \"\"\"\n        Initialise un organisme avec un ensemble de g\u00e8nes.\n\n        - genes : Matrice repr\u00e9sentant les g\u00e8nes de l'organisme.\n        \"\"\"\n        self.chromosome = np.clip(genes, 0, 1)\n        self.visual = None\n        self.fitness = None\n\n    def mutate(self, rate=0.01, scale=0.3, add=0.3):\n        \"\"\"\n        Effectue une mutation sur l'organisme avec des taux de mutation et une \u00e9chelle donn\u00e9s.\n\n        - rate : Taux de mutation, probabilit\u00e9 qu'un g\u00e8ne soit mut\u00e9.\n        - scale : \u00c9chelle de la mutation, d\u00e9termine l'amplitude des mutations.\n        - add : Probabilit\u00e9 d'ajouter un nouveau g\u00e8ne lors de la mutation.\n\n        Retourne un nouvel organisme mut\u00e9.\n        \"\"\"\n        chromosome = np.copy(self.chromosome)\n        n_gene, n_feat = chromosome.shape\n\n        # Ici, nous pouvons ajouter/supprimer un g\u00e8ne ou muter un g\u00e8ne existant\n        if random() &gt; add:\n            # Mutation des caract\u00e9ristiques de nos g\u00e8nes\n            num_mutations = 1 + int(rate * n_gene)\n            # \u00c0 mesure que nous effectuons plus de mutations, la taille des mutations diminue\n            scale2 = scale / num_mutations\n            for i in range(num_mutations):\n                if random() &gt; 0.5:\n                    i = 3\n                else:\n                    i = choice(n_feat)\n                chromosome[choice(n_gene), i] += normal() * scale2\n                if i == 3:\n                    chromosome[:, i] = np.mod(chromosome[:, i], 1)\n        else:\n            # Ajout ou suppression d'un g\u00e8ne\n            if random() &lt; 0.3:\n                chromosome = np.delete(chromosome, choice(n_gene), axis=0)\n            else:\n                # Lorsque nous ajoutons un g\u00e8ne, nous le ferons en m\u00e9langeant deux g\u00e8nes existants\n                # et en le perturbant. Il est plus probable de trouver un bon g\u00e8ne de cette mani\u00e8re.\n                a, b = choice(n_gene, 2, replace=False)\n                gene = np.atleast_2d(0.5 * (chromosome[a, :] + chromosome[b, :]))\n                gene += scale * normal(size=(1, gene.size))\n                gene[:, 2] *= 0.2\n                chromosome = np.append(chromosome, gene, axis=0)\n\n        return Organism(chromosome)\n</code></pre>"},{"location":"projects/Painting%20Vermeer/#initialiser-une-population","title":"Initialiser une population","text":"<p>Population</p> <p>La classe <code>Population</code> comprend plusieurs m\u00e9thodes pour simuler et faire \u00e9voluer une population d'organismes bas\u00e9e sur une image de r\u00e9f\u00e9rence.</p> <p>Le code utilise la biblioth\u00e8que Pygame pour g\u00e9rer les graphiques et la manipulation d'images. Voici un bref r\u00e9sum\u00e9 de chaque m\u00e9thode dans le code :</p> <ul> <li> <p>init(self, path) : M\u00e9thode constructeur qui charge une image de r\u00e9f\u00e9rence \u00e0 partir d'un chemin de fichier donn\u00e9 en utilisant la biblioth\u00e8que Pygame, cr\u00e9e une surface sur laquelle dessiner et initialise une liste de population vide.</p> </li> <li> <p>draw(self, organism) : M\u00e9thode pour dessiner un organisme sur la surface en it\u00e9rant sur son chromosome et en dessinant des cercles avec une position, une taille et une couleur donn\u00e9es.</p> </li> <li> <p>spawn(self, pop_size=30, complexity=10) : M\u00e9thode pour g\u00e9n\u00e9rer une nouvelle population d'organismes en cr\u00e9ant un certain nombre d'organismes avec un nombre sp\u00e9cifi\u00e9 de g\u00e8nes dans chaque membre.</p> </li> <li> <p>calc_fitness(self, organism) : M\u00e9thode pour calculer la forme physique d'un organisme en le dessinant et en le comparant \u00e0 l'image de r\u00e9f\u00e9rence. La forme physique est calcul\u00e9e comme la diff\u00e9rence absolue moyenne n\u00e9gative entre les pixels des deux images.</p> </li> <li> <p>get_child(self, a, b) : M\u00e9thode pour g\u00e9n\u00e9rer un nouvel organisme en combinant deux organismes parents. Les g\u00e8nes de chaque parent sont choisis au hasard avec une probabilit\u00e9 de 70% pour le premier parent et de 30% pour le deuxi\u00e8me parent. Les g\u00e8nes communs sont m\u00e9lang\u00e9s dans le nouvel organisme.</p> </li> <li> <p>save(self, path) : M\u00e9thode pour enregistrer la population actuelle dans un fichier JSON.</p> </li> <li> <p>load(self, path) : M\u00e9thode pour charger une population \u00e0 partir d'un fichier JSON.</p> </li> <li> <p>mutate_and_pick(self, organism, rate, scale, add, attempts=10) : M\u00e9thode pour muter un organisme en ajoutant une valeur al\u00e9atoire \u00e0 chaque g\u00e8ne avec une probabilit\u00e9 sp\u00e9cifi\u00e9e. La m\u00e9thode essaie de muter l'organisme un certain nombre de fois sp\u00e9cifi\u00e9 et renvoie l'organisme mut\u00e9 avec la forme physique la plus \u00e9lev\u00e9e.</p> </li> <li> <p>step(self, time, outdir, rate=0.01, scale=0.1, add=0.3) : M\u00e9thode pour simuler une \u00e9tape d'\u00e9volution en cr\u00e9ant de nouvelles descendances, en les mutant et en conservant les plus adapt\u00e9es. La m\u00e9thode enregistre une image de l'organisme le plus adapt\u00e9 dans un fichier et enregistre la population actuelle dans un fichier JSON.</p> </li> </ul> <pre><code>class Population:\n    def __init__(self, path):\n        \"\"\"Charge l'image de r\u00e9f\u00e9rence et cr\u00e9e une surface sur laquelle on peut dessiner.\"\"\"\n        pygame.init()\n        self.ref = pygame.surfarray.pixels3d(pygame.image.load(path))\n        w, h, d = self.ref.shape\n        self.screen = pygame.Surface((w, h))\n        self.screen.fill((255, 255, 255))\n\n        self.population = []\n\n    def draw(self, organism):\n        \"\"\"Dessine un organisme en exprimant chaque g\u00e8ne.\"\"\"\n        w, h, d = self.ref.shape\n        screen = self.screen.copy()\n        for gene in organism.chromosome:\n            x, y, size, *hsl = gene\n            position = (int(x * w), int(y * h))\n            c = tuple(map(lambda x: int(255 * x), Color(hsl=hsl).rgb))\n            pygame.draw.circle(screen, c, position, int((size * 0.3 + 0.01) * w))\n        return screen\n\n    def spawn(self, pop_size=30, complexity=10):\n        \"\"\"G\u00e9n\u00e8re une nouvelle population avec `complexity` g\u00e8nes dans chaque membre.\"\"\"\n        for i in range(pop_size):\n            organism = Organism(random((complexity, 6)))\n            self.population.append(organism) \n            self.calc_fitness(organism)\n        self.population = sorted(self.population, key=lambda x: -x.fitness)\n\n    def calc_fitness(self, organism):\n        \"\"\"Calcule la forme physique d'un g\u00e8ne en le dessinant et en le comparant \u00e0 la r\u00e9f\u00e9rence.\"\"\"\n        screen = self.draw(organism)\n        diff = pygame.surfarray.pixels3d(screen) - self.ref\n        organism.fitness = -np.mean(np.abs(diff)) - 1e-5 * organism.chromosome.size\n        organism.visual = screen\n\n    def get_child(self, a, b):\n        \"\"\"Croit un nouvel organisme en m\u00e9langeant les g\u00e8nes de longueur commune, en privil\u00e9giant le premier parent.\"\"\"\n        new_genes = []\n        n_a, n_b = a.chromosome.shape[0], b.chromosome.shape[0]\n        for i in range(max(n_a, n_b)):\n            if i &lt; n_a and i &lt; n_b:\n                if random() &lt; 0.7:\n                    new_genes.append(a.chromosome[i, :])\n                else:\n                    new_genes.append(b.chromosome[i, :])\n            elif i &lt; n_a:\n                new_genes.append(a.chromosome[i, :])\n            else:\n                if random() &lt; 0.3:\n                    new_genes.append(b.chromosome[i, :])\n            chromosome = np.array(new_genes)\n        o = Organism(chromosome)\n        self.calc_fitness(o)\n        return o\n\n    def save(self, path):\n        \"\"\"Enregistre la population dans un fichier JSON.\"\"\"\n        out = [o.chromosome.tolist() for o in self.population]\n        with open(path, \"w\") as f:\n            json.dump(out, f)\n\n    def load(self, path):\n        \"\"\"Charge la population \u00e0 partir d'un fichier JSON.\"\"\"\n        with open(path) as f:\n            inp = json.load(f)\n        self.population = [Organism(np.array(x)) for x in inp]\n        for o in self.population:\n            self.calc_fitness(o)\n\n    def mutate_and_pick(self, organism, rate, scale, add, attempts=10):\n        \"\"\" Muter l'organisme un certain nombre de fois pour essayer d'obtenir quelque chose de meilleur \"\"\"\n        for i in range(attempts):\n            o = organism.mutate(rate=rate, scale=scale, add=add)\n            self.calc_fitness(o)\n            if o.fitness &gt; organism.fitness:\n                return o\n        return organism\n\n    def step(self, time, outdir, rate=0.01, scale=0.1, add=0.3):\n        \"\"\" Avancer dans le temps en cr\u00e9ant des enfants, en les mutant, puis en laissant les plus aptes survivre \"\"\"\n\n        new_orgs = []\n        weights = 1 - np.linspace(0, 0.2, len(self.population))\n        for i in range(len(self.population)):\n            a, b = choice(self.population, 2, replace=True, p=weights / weights.sum())\n            child = self.get_child(a, b)\n            new_orgs.append(self.mutate_and_pick(child, rate, scale, add))\n\n        for o in new_orgs:\n            self.calc_fitness(o)\n        sorted_orgs = sorted(new_orgs, key=lambda x: -x.fitness)\n        self.population = sorted_orgs[:len(self.population)]\n\n        path = outdir + f\"{time:04d}.png\"\n        pygame.image.save(self.population[0].visual, path)\n        self.save(outdir + \"save.json\")\n</code></pre>"},{"location":"projects/Painting%20Vermeer/#faire-evoluer-la-population-dorganismes","title":"Faire Evoluer la population d'organismes","text":"<p>evolve</p> <p>La fonction <code>evolve</code> effectue l'\u00e9volution de la population d'organismes en utilisant les param\u00e8tres de mutation fournis.</p> <p>La fonction commence par cr\u00e9er une instance de la classe <code>Population</code> en fournissant le chemin d'acc\u00e8s \u00e0 l'image de r\u00e9f\u00e9rence. Ensuite, elle cr\u00e9e un r\u00e9pertoire de sortie pour enregistrer les images g\u00e9n\u00e9r\u00e9es au cours de l'\u00e9volution.</p> <p>Si une sauvegarde de population existe d\u00e9j\u00e0, elle est charg\u00e9e \u00e0 partir du fichier JSON correspondant. Le num\u00e9ro de l'\u00e9tape de d\u00e9part est \u00e9galement d\u00e9termin\u00e9 en se basant sur le nom du dernier fichier d'image enregistr\u00e9.</p> <p>Si aucune sauvegarde de population n'existe, une population initiale est g\u00e9n\u00e9r\u00e9e en appelant la m\u00e9thode spawn de l'instance de <code>Population</code>.</p> <p>Ensuite, la boucle principale de l'\u00e9volution d\u00e9marre, it\u00e9rant sur le nombre d'\u00e9tapes sp\u00e9cifi\u00e9. \u00c0 chaque \u00e9tape, la m\u00e9thode step de l'instance de <code>Population</code> est appel\u00e9e pour effectuer une it\u00e9ration de l'\u00e9volution. Les param\u00e8tres de mutation (rate, scale, add_chance) sont transmis \u00e0 cette m\u00e9thode.</p> <p>L'image du meilleur organisme de chaque \u00e9tape est enregistr\u00e9e dans le r\u00e9pertoire de sortie, et la population actuelle est sauvegard\u00e9e dans un fichier JSON.</p> <pre><code>def evolve(rate, scale, add_chance, steps=700000):\n    pop = Population(\"/content/test.jpg\")\n    outdir = f\"genetic2/output/\"\n    os.makedirs(outdir, exist_ok=True)\n    save = outdir + \"save.json\"\n\n    # Chargement de la population pr\u00e9c\u00e9demment sauvegard\u00e9e si elle existe\n    if os.path.exists(save):\n        pop.load(save)\n        start = int(sorted(os.listdir(outdir))[-2][:-4]) * 2\n    else:\n        # G\u00e9n\u00e9ration initiale de la population\n        pop.spawn(complexity=20)\n        start = 0\n\n    # \u00c9volution de la population pendant le nombre d'\u00e9tapes sp\u00e9cifi\u00e9\n    for i in range(start, steps):\n        pop.step(i, outdir, rate=rate, scale=scale, add=add_chance)\n</code></pre>"},{"location":"projects/Painting%20Vermeer/#executer-le-processus-devolution-de-la-population-dorganismes","title":"Ex\u00e9cuter le processus d'\u00e9volution de la population d'organismes","text":"<p>evolve(0.01, 0.1, 0.01)</p> <p>La fonction <code>evolve(0.01, 0.1, 0.01)</code> ex\u00e9cute le processus d'\u00e9volution de la population d'organismes en utilisant les param\u00e8tres suivants :</p> <p>Taux de mutation : 0,01 (1% de chance de mutation)</p> <p>\u00c9chelle (scale) : 0,1 (distribution normale avec un \u00e9cart-type de 0,1)</p> <p>Chance d'ajout ou de suppression : 0,01 (1% de chance d'ajout ou de suppression de g\u00e8nes)</p> <ul> <li> <p> Cela signifie que lors de chaque it\u00e9ration de l'\u00e9volution, les organismes de la population seront soumis \u00e0 des mutations avec une probabilit\u00e9 de 0,01 (1% de chance). Les mutations consistent \u00e0 modifier les valeurs des g\u00e8nes des organismes. L'\u00e9chelle de mutation est d\u00e9finie \u00e0 0,1, ce qui signifie que les modifications de g\u00e8nes seront tir\u00e9es d'une distribution normale avec un \u00e9cart-type de 0,1.</p> </li> <li> <p> De plus, il y a une probabilit\u00e9 de 0,01 (1% de chance) d'ajouter ou de supprimer des g\u00e8nes lors de la mutation des organismes.</p> </li> <li> <p> Ces param\u00e8tres contr\u00f4lent le niveau de diversit\u00e9 g\u00e9n\u00e9tique et de variation au sein de la population, ainsi que la probabilit\u00e9 de modifications importantes des caract\u00e9ristiques des organismes au fil des \u00e9tapes de l'\u00e9volution.</p> </li> </ul> <pre><code>evolve(0.01, 0.1, 0.01)\n</code></pre> Image de test (Input) <p></p> R\u00e9sultat final (Output) <p></p>"},{"location":"projects/Painting%20Vermeer/#conclusion","title":"Conclusion","text":"<p>Conclusion</p> <p>Vous pouvez observer une am\u00e9lioration des images g\u00e9n\u00e9r\u00e9es \u00e0 chaque it\u00e9ration. Cependant, en raison des contraintes de ressources, je n'ai pas pu poursuivre l'ex\u00e9cution du code car j'utilisais Google Colab, qui est limit\u00e9 en termes de temps. Pour obtenir le r\u00e9sultat final de mon algorithme, il serait n\u00e9cessaire de souscrire \u00e0 Google Colab Pro.</p>"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/","title":"Reciprocal n-body Collision Avoidance","text":""},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#importer-les-packages","title":"Importer les Packages","text":"<ul> <li> <p>NumPy : NumPy est une biblioth\u00e8que Python populaire pour le calcul scientifique qui fournit des structures de donn\u00e9es pour la repr\u00e9sentation de tableaux multidimensionnels et des fonctions pour manipuler ces tableaux.</p> </li> <li> <p>Matplotlib : Matplotlib est une biblioth\u00e8que en Python utilis\u00e9e pour tracer des graphiques et des visualisations.</p> </li> <li> <p>heapq : heapq est un module Python qui impl\u00e9mente les algorithmes d'heaps ou de tas pour des structures de donn\u00e9es.</p> </li> <li> <p>math : Le module math en Python fournit des fonctions math\u00e9matiques courantes, telles que les fonctions trigonom\u00e9triques, exponentielles, logarithmiques, etc.</p> </li> <li> <p>CVXOPT : CVXOPT est une biblioth\u00e8que open source Python pour l'optimisation convexe. Elle est utilis\u00e9e pour r\u00e9soudre des probl\u00e8mes d'optimisation convexe tels que la programmation lin\u00e9aire, la programmation quadratique, la programmation semi-d\u00e9finie, la programmation convexe et autres. Elle fournit des solveurs rapides et pr\u00e9cis pour les probl\u00e8mes d'optimisation convexe, y compris des interfaces pour les solvers externes.</p> </li> <li> <p>random : The random module in Python provides a suite of functions for generating random numbers.</p> </li> <li> <p>time : Le module time est un module Python qui fournit diverses fonctions permettant de manipuler le temps.</p> </li> <li> <p>cv2 : cv2 is a library for computer vision and image processing. It is a Python wrapper for OpenCV (Open Source Computer Vision), which is a C++ library that includes numerous computer vision algorithms.</p> </li> <li> <p>IPython : La biblioth\u00e8que IPython fournit un certain nombre d'outils pour faciliter le d\u00e9veloppement et l'analyse de donn\u00e9es en Python.</p> </li> <li> <p>tqdm : tqdm is a Python package that provides a progress bar visualization for iterative tasks, making it easy to see how far along a task is and how much longer it is expected to take.</p> </li> </ul> Packages<pre><code>import numpy\nfrom numpy.linalg import norm\nfrom numpy import dot,array\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle, Circle\nimport matplotlib.patches as patches\nfrom pylab import show,imshow\nimport heapq\nfrom math import *\nimport cvxopt\nfrom cvxopt import matrix,solvers\nimport random\nimport time\nimport os\nimport matplotlib.animation as animation\nimport cv2\nfrom IPython import display\nfrom tqdm import tqdm\n</code></pre>"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#initialiser-la-geometrie","title":"Initialiser la g\u00e9om\u00e9trie","text":""},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#draw","title":"draw","text":"<p>On commence par d\u00e9finir la fonction <code>draw</code> qui prend plusieurs arguments en entr\u00e9e et qui trace une sc\u00e8ne avec des agents et des obstacles.</p> <p>Les arguments en entr\u00e9e sont:</p> <p><code>Ex</code> : une liste des sorties de la sc\u00e8ne</p> <p><code>Obs</code> : une liste des obstacles rectangulaires</p> <p><code>Obs_cir</code> : une liste des obstacles circulaires</p> <p><code>scene</code> : une paire (L, l) qui repr\u00e9sente les dimensions de la sc\u00e8ne</p> <p><code>agents</code> : une liste d'agents, o\u00f9 chaque agent est repr\u00e9sent\u00e9 par sa position, sa taille et sa couleur</p> <p><code>t</code> : temps de simulation</p> <p><code>savepath</code> : le chemin pour enregistrer la figure g\u00e9n\u00e9r\u00e9e</p> <p><code>play</code> : un bool\u00e9en qui sp\u00e9cifie si l'animation doit \u00eatre affich\u00e9e ou non</p> <p>La fonction commence par cr\u00e9er une figure et un axe avec une taille d\u00e9termin\u00e9e par la dimension de la sc\u00e8ne. Ensuite, elle dessine les obstacles, les sorties et les agents sur la figure. Les obstacles rectangulaires sont repr\u00e9sent\u00e9s par des rectangles noirs, les obstacles circulaires par des cercles noirs, les sorties par des rectangles orange et les agents par des cercles de couleur.</p> <p>Enfin, la fonction sauvegarde la figure \u00e0 l'emplacement sp\u00e9cifi\u00e9 par \"savepath\". Si \"play\" est faux, la figure est ferm\u00e9e.</p> draw<pre><code>def draw(Ex, Obs, Obs_cir, scene, agents, t, savepath, play = False):\n\n    L , l = scene\n    ratio = l/L\n    c = 10\n\n    fig, ax = plt.subplots(figsize=(c/ratio,c))\n\n    title = ax.text(0.5, 1.05, \"Temps de simulation : %s s \\n Nombre des agents : %s\" %(t,len(agents)), \n                    transform=ax.transAxes, ha=\"center\", size=20)\n\n    #Draw the environment\n    plt.plot([0, L], [0, 0], 'white')\n    plt.plot([L, L], [0, l], 'white')\n    plt.plot([L, 0], [l,l], 'white')\n    plt.plot([0,0], [l,0], 'white')\n\n\n    #Draw Obstacle\n    for obs in Obs:\n        rect = Rectangle(obs.position, obs.width, obs.height)\n        rect.set_color('black')\n        ax.add_patch(rect)\n\n    #Draw Obstacle Cir\n    for obs in Obs_cir:\n        circle = Circle(obs.position, obs.rayon)\n        circle.set_color('black')\n        ax.add_patch(circle)\n\n    #Draw exits\n    for e in Ex:\n        rect = Rectangle(e.position, e.width, e.height)\n        rect.set_color('orange')\n        ax.add_patch(rect)\n\n    #Draw agents\n    for agent in agents:\n        x,y = agent.position\n        circle = Circle((x,y), agent.size)\n        circle.set_color(agent.color)\n        ax.add_patch(circle)\n\n    plt.xticks(fontsize=20)\n    plt.yticks(fontsize=20)\n\n    fig.savefig(savepath)\n\n    if not play:\n        plt.close()\n</code></pre>"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#record_video","title":"record_video","text":"<p>La fonction appel\u00e9e <code>record_video</code> prend un argument optionnel speed (dont la valeur par d\u00e9faut est 25). Le but de cette fonction est de cr\u00e9er une vid\u00e9o \u00e0 partir d'une s\u00e9quence d'images sauvegard\u00e9es dans un r\u00e9pertoire, et de sauvegarder le fichier vid\u00e9o r\u00e9sultant dans le r\u00e9pertoire de travail actuel. Les arguments pass\u00e9s \u00e0 cette fonction sont les suivants :</p> <p><code>speed</code> : une valeur enti\u00e8re repr\u00e9sentant le nombre d'images par seconde de la vid\u00e9o r\u00e9sultante (c'est-\u00e0-dire le taux de rafra\u00eechissement de la vid\u00e9o).</p> <p>La fonction commence par imprimer un message indiquant qu'elle commence l'enregistrement de la vid\u00e9o. Ensuite, elle lit la premi\u00e8re image de la s\u00e9quence d'images pour d\u00e9terminer les dimensions de la vid\u00e9o.</p> <p>Elle cr\u00e9e ensuite un objet VideoWriter en utilisant la m\u00e9thode cv2.VideoWriter d'OpenCV, en sp\u00e9cifiant le nom du fichier de sortie, le codec vid\u00e9o (dans ce cas XVID), le taux de rafra\u00eechissement et les dimensions de la vid\u00e9o (bas\u00e9es sur les dimensions de la premi\u00e8re image).</p> <p>Ensuite, elle boucle sur les images restantes de la s\u00e9quence et ajoute chacune \u00e0 la vid\u00e9o \u00e0 l'aide de la m\u00e9thode video.write(). Les images sont lues en utilisant la m\u00e9thode cv2.imread() d'OpenCV, qui lit une image \u00e0 partir d'un chemin de fichier sp\u00e9cifi\u00e9.</p> <p>Enfin, la fonction nettoie toutes les fen\u00eatres qui ont pu \u00eatre cr\u00e9\u00e9es pendant le processus et lib\u00e8re l'objet vid\u00e9o. Elle affiche un message indiquant que la vid\u00e9o a \u00e9t\u00e9 sauvegard\u00e9e.</p> record_video<pre><code>def record_video(speed = 25):\n    print('Recording video ...')\n    frame = cv2.imread('DossierImages/simulation' + str(10) + '.jpg')\n    height, width, layers = frame.shape\n\n    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n    video = cv2.VideoWriter('video.avi', fourcc, speed, (width,height))\n\n    for k in range(N_iter):\n        video.write(cv2.imread('DossierImages/simulation' + str(k+1) + '.jpg'))\n\n    cv2.destroyAllWindows()\n    video.release()\n    print('Video saved.')\n</code></pre>"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#generate_indivn","title":"generate_indiv(N)","text":"<p>La fonction <code>generate_indiv(N)</code> cr\u00e9e une liste de N agents en v\u00e9rifiant qu'ils ne se chevauchent pas et ne traversent pas les obstacles. Voici les \u00e9tapes principales :</p> <ul> <li> <p> La fonction d\u00e9finit la taille de la sc\u00e8ne, ainsi que des variables pour la distance minimale entre les agents et pour le rayon de chaque agent.</p> </li> <li> <p> La fonction cr\u00e9e une liste vide L qui contiendra les agents, puis elle commence une boucle qui s'arr\u00eatera quand il y aura N agents dans la liste L.</p> </li> <li> <p> \u00c0 chaque it\u00e9ration de la boucle, la fonction g\u00e9n\u00e8re une position al\u00e9atoire pour un nouvel agent en utilisant des fonctions al\u00e9atoires et l'ajoute \u00e0 une liste temporaire q, qui contient les positions de tous les agents d\u00e9j\u00e0 cr\u00e9\u00e9s, ainsi que les rayons de ces agents, qui sont stock\u00e9s dans la liste R.</p> </li> <li> <p> Ensuite, la fonction v\u00e9rifie s'il y a une collision entre le nouvel agent et les agents d\u00e9j\u00e0 cr\u00e9\u00e9s. Si c'est le cas, la variable choc est d\u00e9finie sur True, ce qui signifie qu'il y a eu une collision et que le nouvel agent ne sera pas ajout\u00e9 \u00e0 la liste L.</p> </li> <li> <p> Ensuite, la fonction v\u00e9rifie si le nouvel agent entre en collision avec un obstacle. Si c'est le cas, la variable choc est d\u00e9finie sur True.</p> </li> <li> <p> Si le nouvel agent ne provoque pas de collision, il est ajout\u00e9 \u00e0 la liste L.</p> </li> <li> <p> Lorsque N agents ont \u00e9t\u00e9 cr\u00e9\u00e9s et ajout\u00e9s \u00e0 la liste L, la fonction retourne cette liste.</p> </li> </ul> generate_indiv<pre><code>def generate_indiv(N):\n\n    def rand_float_range(start, end):\n        return random.random() * (end - start) + start\n\n    a , b = size_scene\n    dst = 0.2\n    r = 0.2\n    L = list()\n\n    while len(L) &lt; N:\n\n        choc = False\n\n        q = [agent.position for agent in L]\n        R = [agent.size for agent in L]\n\n        x = rand_float_range(int(0),int(a))\n        y = rand_float_range(int(0),int(b))\n\n        q.append([x,y])\n        R.append(r)\n\n\n        for j in range(len(q)-1):\n            if dist(q[-1], q[j]) - (R[-1]+R[j]) &lt;= dst:\n                choc = True\n                break\n\n        #chocs obstacle\n        for obstacle in obstacles_cir:\n            [a0, b0], rayon = obstacle.position, obstacle.rayon\n            if (x-a0)**2 + (y-b0)**2 &lt; (rayon+3)**2 : choc = True\n\n        for obstacle in obstacles:\n            [a0, b0], w, l = obstacle.position, obstacle.width, obstacle.height\n            a1, b1 = a0 + w , b0 + l\n\n            if (a0&lt;=x&lt;=a1 and b0-r-0.5&lt;=y&lt;=b1+r+0.5) or (b0&lt;=y&lt;=b1 and a0-r-0.5&lt;=x&lt;=a1+r+0.5): choc = True\n            elif distance_vecteur_obs([x,y] , r, obstacle)[0] &lt; 0.5: choc = True\n\n        if not choc:\n            agent = myAgent((x,y))\n            agent.size = r\n            L.append(agent)\n\n    return L\n</code></pre>"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#maximini-plot_directions","title":"maxiMini &amp; plot_directions","text":"<p>La premi\u00e8re fonction, nomm\u00e9e <code>maxiMini(FX,FY)</code>, prend en entr\u00e9e deux listes FX et FY, contenant des valeurs de directions. Cette fonction parcourt les deux listes et recherche la valeur maximale et la valeur minimale des directions dans chaque liste. Elle retourne ensuite ces deux valeurs.</p> <p>La deuxi\u00e8me fonction, nomm\u00e9e <code>plot_directions(FX,FY)</code>, prend \u00e9galement en entr\u00e9e deux listes FX et FY. Cette fonction affiche deux graphiques c\u00f4te \u00e0 c\u00f4te : un pour les directions selon X et un pour les directions selon Y. Les directions sont repr\u00e9sent\u00e9es par des couleurs sur chaque graphique, et les couleurs correspondent \u00e0 des valeurs. Les valeurs minimales et maximales sont obtenues en appelant la fonction <code>maxiMini(FX,FY)</code>. Les graphiques sont affich\u00e9s \u00e0 l'aide de la biblioth\u00e8que Matplotlib. Enfin, cette fonction retourne les graphiques affich\u00e9s.</p> <p>En r\u00e9sum\u00e9, ces deux fonctions permettent de visualiser les directions de mouvement \u00e0 partir de listes de directions selon X et Y.</p> maxiMini &amp; plot_directions<pre><code>def maxiMini(FX,FY):\n  maxi = 0\n  Mini = 0\n  for i in range(n):\n    for j in range(len(FX[0])):\n      fx , fy = FX[i][j] , FY[i][j]\n      if fx != float('inf') and fx != -float('inf') and fy != float('inf') and fy != -float('inf') and not isnan(fx) and not isnan(fy):\n        if fx&gt;maxi :\n          maxi = fx\n        if fy&gt;maxi :\n          maxi = fy\n        if fx&lt;Mini : \n          Mini = fx\n        if fy&lt;Mini :\n          Mini = fy\n\n  return maxi , Mini\n\ndef plot_directions(FX,FY):\n  fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,15))\n  Z = [FX, FY]\n  text = ['Directions selon X', 'Directions selon Y']\n  maxi , Mini = maxiMini(FX,FY)\n\n  for ax, i in zip(axes.flat, range(2)):\n      im = ax.imshow(Z[i], interpolation=\"bicubic\", origin=\"upper\", vmin=Mini, vmax=maxi)\n      ax.title.set_text(text[i])\n\n  fig.subplots_adjust(right=0.8)\n  cbar_ax = fig.add_axes([0.85, 0.35, 0.05, 0.3])\n  fig.colorbar(im, cax=cbar_ax)\n\n  plt.show()\n</code></pre>"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#exit","title":"Exit","text":"<p>Ce code d\u00e9finit une classe <code>Exit</code> qui repr\u00e9sente une sortie. La classe poss\u00e8de un constructeur (init) qui prend en argument une position, une largeur et une hauteur de la sortie. La position est un tuple de deux \u00e9l\u00e9ments repr\u00e9sentant les coordonn\u00e9es (x, y) du coin sup\u00e9rieur gauche de la sortie.</p> <p>Le constructeur initialise les attributs position, width et height de la classe avec les valeurs pass\u00e9es en argument.</p> Exit<pre><code>class Exit:\n\n    def __init__(self,position,width,height):\n\n        self.position = position\n        self.width = width\n        self.height = height\n</code></pre>"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#obstacle","title":"Obstacle","text":"<p>La classe <code>Obstacle</code> a pour but de repr\u00e9senter un obstacle dans une simulation. Elle poss\u00e8de trois attributs : position, width et height, qui correspondent respectivement \u00e0 la position de l'obstacle et \u00e0 sa largeur et hauteur.</p> <p>La m\u00e9thode repr de la classe est une m\u00e9thode sp\u00e9ciale qui renvoie une cha\u00eene de caract\u00e8res repr\u00e9sentant l'objet. Dans ce cas pr\u00e9cis, elle renvoie une cha\u00eene de caract\u00e8res contenant la position de l'obstacle ainsi que les coordonn\u00e9es de ses coins (en supposant que la position correspond au coin en bas \u00e0 gauche).</p> Obstacle<pre><code>class Obstacle():\n\n    def __init__(self, position,width,height):\n\n        self.position=position\n        self.width=width\n        self.height=height\n\n    def __repr__(self):\n        return 'Obstacle'+'\\n'+'DL:'+str(self.position)+'DR:'+str((self.position[0]+self.width,self.position[1]))+'UR:'+str((self.position[0]+self.width,self.position[1]+self.height))+'UL:'+str((self.position[0]+self.width,self.position[1]))\n</code></pre>"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#obstacle_cir","title":"Obstacle_Cir","text":"<p>Ce code d\u00e9finit une classe <code>Obstacle_Cir</code> qui repr\u00e9sente un obstacle circulaire.</p> <p>La classe a un constructeur init qui prend deux param\u00e8tres, position et rayon, qui sont utilis\u00e9s pour initialiser les attributs de l'objet. L'attribut position est un tuple qui repr\u00e9sente la position du centre de l'obstacle sur l'espace de simulation et l'attribut rayon est un nombre flottant qui repr\u00e9sente le rayon de l'obstacle.</p> Obstacle_Cir<pre><code>class Obstacle_Cir():\n\n    def __init__(self, position,rayon):\n        self.position=position\n        self.rayon=rayon\n</code></pre>"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#fast-marching","title":"Fast Marching","text":"<p>PriorityQueue</p> <p>Cette classe est une impl\u00e9mentation d'une file de priorit\u00e9 (ou heap) en utilisant la biblioth\u00e8que heapq.</p> <p>init(self) : Constructeur de la classe qui initialise la file de priorit\u00e9 et un index pour suivre l'\u00e9l\u00e9ment courant.</p> <p>pop(self) : Cette m\u00e9thode supprime et renvoie l'\u00e9l\u00e9ment le plus petit de la file de priorit\u00e9.</p> <p>remove(self, nodeId) : Cette m\u00e9thode prend un noeud (identifi\u00e9 par nodeId) en entr\u00e9e et supprime cet \u00e9l\u00e9ment de la file de priorit\u00e9.</p> <p>iter(self) : Cette m\u00e9thode renvoie l'it\u00e9rateur sur l'instance de la file de priorit\u00e9.</p> <p>str(self) : Cette m\u00e9thode renvoie une repr\u00e9sentation sous forme de cha\u00eene de la file de priorit\u00e9.</p> <p>append(self, node) : Cette m\u00e9thode ajoute un \u00e9l\u00e9ment dans la file de priorit\u00e9.</p> <p>contains(self, key) : Cette m\u00e9thode renvoie True si la cl\u00e9 est pr\u00e9sente dans la file de priorit\u00e9, False sinon.</p> <p>eq(self, other) : Cette m\u00e9thode v\u00e9rifie si deux files de priorit\u00e9 sont \u00e9gales.</p> <p>getitem(self, nodeId) : Cette m\u00e9thode renvoie l'\u00e9l\u00e9ment correspondant \u00e0 l'ID du n\u0153ud donn\u00e9.</p> <p>clear(self) : Cette m\u00e9thode supprime tous les \u00e9l\u00e9ments de la file de priorit\u00e9.</p> <p>len(self) : Cette m\u00e9thode renvoie la longueur de la file de priorit\u00e9.</p> <p>next = next : Cette m\u00e9thode est utilis\u00e9e pour rendre la file de priorit\u00e9 iterable.</p> <pre><code>class PriorityQueue():\n\n\n    def __init__(self):\n        self.queue = []\n        self.current = 0\n\n    def pop(self):\n        return heapq.heappop(self.queue)\n\n    def remove(self, nodeId):\n        for i in range(len(self.queue)):\n            if self.queue[i][1]==nodeId:\n                self.queue.pop(i)\n                break;\n\n    def __iter__(self):\n        return self\n\n    def __str__(self):\n        return 'PQ:[%s]'%(', '.join([str(i) for i in self.queue]))\n\n    def append(self, node):\n        heapq.heappush(self.queue,node)\n\n    def __contains__(self, key):\n        self.current = 0\n        return key in [n for _,n in self.queue]\n\n    def __eq__(self, other):\n        self.curent = 0\n        return self == other\n\n    def __getitem__(self, nodeId):\n        for element in self.queue:\n            if element[1]==nodeId:\n                return element\n        return None\n\n    def clear(self):\n        self.queue = []\n\n    def __len__(self):\n        return len(self.queue)\n\n    __next__ = next\n</code></pre> <p>GridGraph</p> <p>Ce code d\u00e9finit une classe <code>GridGraph</code> qui repr\u00e9sente une grille. Cette grille est utilis\u00e9e pour simuler un environnement dans lequel une ou plusieurs entit\u00e9s se d\u00e9placent, en utilisant un algorithme de calcul de chemin pour d\u00e9terminer le chemin optimal entre deux points.</p> <p>La classe est initialis\u00e9e avec deux param\u00e8tres, size_scene qui est un tuple repr\u00e9sentant la taille de la sc\u00e8ne (la grille) en unit\u00e9s arbitraires, et precision qui d\u00e9termine le nombre de subdivisions dans la grille. La pr\u00e9cision est utilis\u00e9e pour d\u00e9finir la taille de chaque case dans la grille.</p> <p>La grille est mod\u00e9lis\u00e9e par deux matrices, indicator_map et distances. indicator_map est initialis\u00e9e avec des valeurs de 1 pour chaque case de la grille, et sera modifi\u00e9e plus tard pour inclure des obstacles et des sorties. distances est initialis\u00e9e avec des valeurs inf pour chaque case de la grille.</p> <p>La m\u00e9thode get_neighbours est utilis\u00e9e pour renvoyer les voisins d'un n\u0153ud donn\u00e9, repr\u00e9sent\u00e9 par un tuple d'entiers (x, y) indiquant les coordonn\u00e9es du n\u0153ud sur la grille.</p> <p>La m\u00e9thode to_node est utilis\u00e9e pour convertir des coordonn\u00e9es r\u00e9elles en coordonn\u00e9es de n\u0153uds sur la grille.</p> <p>La m\u00e9thode prepare_graph_for_fast_marching est utilis\u00e9e pour modifier indicator_map en y ajoutant des obstacles et des sorties, afin de pr\u00e9parer la grille pour l'algorithme de calcul de chemin. Les obstacles sont d\u00e9finis comme des rectangles ou des cercles, repr\u00e9sent\u00e9s par des objets Obstacle ou ObstacleCir, et les sorties sont repr\u00e9sent\u00e9es par des objets Exit.</p> <pre><code>class GridGraph:\n\n    global OBSTACLE\n    global EXIT\n    OBSTACLE = 0\n    EXIT = 2\n\n    def __init__(self,size_scene,precision):\n        self.precision = precision\n        self.horizontal_size = int(size_scene[0]*precision)+1\n        self.vertical_size = int(size_scene[1]*precision)+1\n        self.indicator_map = numpy.ones((self.vertical_size,self.horizontal_size))\n        self.distances = numpy.ones((self.vertical_size,self.horizontal_size))*float('inf')\n\n    def get_neighbours(self,node):\n        result = {};\n        if node[1]&lt;self.horizontal_size-1:\n            result['x+1']=(node[0],node[1]+1);\n        if node[1]&gt;0:\n            result['x-1']=(node[0],node[1]-1);\n        if node[0]&lt;self.vertical_size-1:\n            result['y+1']=(node[0]+1,node[1]);\n        if node[0]&gt;0:\n            result['y-1']=(node[0]-1,node[1]);\n        return result;\n\n    def to_node(self,coordinates):\n        return (int(coordinates[1]*self.precision),int(coordinates[0]*self.precision))\n\n    def prepare_graph_for_fast_marching(self,obstacles, obstacles_cir, exits):\n        for obstacle in obstacles:\n            dl = (obstacle.position[0],obstacle.position[1])\n            ur = (obstacle.position[0]+obstacle.width,obstacle.position[1]+obstacle.height)\n\n            for x in range(self.to_node(dl)[0]+1,self.to_node(ur)[0]):\n                for y in range(self.to_node(dl)[1]+1,self.to_node(ur)[1]):\n                    if x&gt;=0 and x&lt;self.indicator_map.shape[0] and y&gt;=0 and y&lt;self.indicator_map.shape[1]:\n                        self.indicator_map[x,y]=OBSTACLE\n\n        for obstacle_cir in obstacles_cir:\n            dl = (obstacle_cir.position[0] - obstacle_cir.rayon , obstacle_cir.position[1] - obstacle_cir.rayon)\n            ur = (obstacle_cir.position[0] + obstacle_cir.rayon , obstacle_cir.position[1] + obstacle_cir.rayon)\n\n            for x in range(self.to_node(dl)[0]+1,self.to_node(ur)[0]):\n                for y in range(self.to_node(dl)[1]+1,self.to_node(ur)[1]):\n                    if x&gt;=0 and x&lt;self.indicator_map.shape[0] and y&gt;=0 and y&lt;self.indicator_map.shape[1]:\n                        if (x/self.precision - obstacle_cir.position[1])**2 + (y/self.precision - obstacle_cir.position[0])**2 &lt;= obstacle_cir.rayon**2:\n                            self.indicator_map[x,y]=OBSTACLE\n\n        for exit_ in exits:\n            dl = (exit_.position[0],exit_.position[1])\n            ur = (exit_.position[0]+exit_.width,exit_.position[1]+exit_.height)\n            for x in range(self.to_node(dl)[0],self.to_node(ur)[0]+1):\n                for y in range(self.to_node(dl)[1],self.to_node(ur)[1]+1):\n                    if x&gt;=0 and x&lt;self.indicator_map.shape[0] and y&gt;=0 and y&lt;self.indicator_map.shape[1]:\n                        self.indicator_map[x,y]=EXIT\n</code></pre> <p>fast_marching_method</p> <p>Le code prend en entr\u00e9e un graphe et un point de d\u00e9part et retourne une carte de distance de tous les n\u0153uds du graphe au point de d\u00e9part.</p> <p>Le code commence par d\u00e9finir une fonction calculus_distance qui prend en entr\u00e9e un n\u0153ud, un graphe et des poids et renvoie la distance de ce n\u0153ud au point de d\u00e9part en utilisant la m\u00e9thode de marche rapide. Cette m\u00e9thode calcule la distance en utilisant la distance aux n\u0153uds voisins pond\u00e9r\u00e9e par des poids qui d\u00e9pendent de la g\u00e9om\u00e9trie du probl\u00e8me.</p> <p>Ensuite, le code initialise une file de priorit\u00e9 frontier, qui contiendra les n\u0153uds \u00e0 explorer, et une liste explored qui contiendra les n\u0153uds d\u00e9j\u00e0 explor\u00e9s. Les poids initiaux des n\u0153uds sont stock\u00e9s dans weights. Les points d'arriv\u00e9e sont trouv\u00e9s dans la carte indicator_map et ajout\u00e9s \u00e0 la file de priorit\u00e9 avec une distance initiale de 0. Les poids des points d'arriv\u00e9e sont \u00e9galement initialis\u00e9s \u00e0 0.</p> <p>La boucle principale commence avec l'extraction d'un n\u0153ud de la file de priorit\u00e9 frontier. La distance \u00e0 ce n\u0153ud est stock\u00e9e dans weights. Les voisins du n\u0153ud sont explor\u00e9s, et si un voisin n'a pas d\u00e9j\u00e0 \u00e9t\u00e9 explor\u00e9 et appartient \u00e0 la grille (indiqu\u00e9 par la carte indicator_map), sa distance au point de d\u00e9part est calcul\u00e9e en utilisant la m\u00e9thode calculus_distance. Si le voisin n'est pas d\u00e9j\u00e0 dans la file de priorit\u00e9, il est ajout\u00e9 avec sa nouvelle distance, sinon, si sa distance calcul\u00e9e est inf\u00e9rieure \u00e0 sa distance actuelle, sa distance et sa priorit\u00e9 dans la file de priorit\u00e9 sont mises \u00e0 jour. Les n\u0153uds explor\u00e9s sont ajout\u00e9s \u00e0 la liste explored.</p> <p>Une fois la file de priorit\u00e9 vid\u00e9e, la carte de distance est stock\u00e9e dans la variable distances de l'objet graphe et renvoy\u00e9e.</p> <pre><code>def fast_marching_method(graph,start):\n\n    def calculus_distance(node,graph,weights):\n        neighbours = graph.get_neighbours(node);\n        if 'y-1' in neighbours :\n            if 'y+1' in neighbours:\n                x1 = min(weights[neighbours['y-1']],weights[neighbours['y+1']]);\n            else :\n                x1 = weights[neighbours['y-1']];\n        else :\n            if 'y+1' in neighbours:\n                x1 = weights[neighbours['y+1']];\n        if 'x-1' in neighbours:\n            if 'x+1' in neighbours:\n                x2 = min(weights[neighbours['x-1']],weights[neighbours['x+1']]);\n            else :\n                x2 = weights[neighbours['x-1']];\n        else :\n            if 'x+1' in neighbours:\n                x2 = weights[neighbours['x+1']];\n\n        if 2*h**2-(x1-x2)**2&gt;=0:\n            return (x1+x2+(2*h**2-(x1-x2)**2)**0.5)/2\n        else:\n            return min(x1,x2)+h\n\n\n    frontier = PriorityQueue();\n    weights = graph.distances;\n\n    explored = []\n\n    goals = numpy.where(graph.indicator_map==2)\n    goals_x = goals[0]\n    goals_y = goals[1]\n    for i in range(goals_x.size):\n        frontier.append([0,(goals_x[i],goals_y[i])])\n        weights[(goals_x[i],goals_y[i])] = 0\n\n\n    while frontier:\n        node = frontier.pop();\n        explored.append(node[1])\n        #if node[1]==start:\n        #   return weights\n        neighbours = graph.get_neighbours(node[1]);\n        for neighbour in neighbours.values():\n            if neighbour not in explored and graph.indicator_map[neighbour]:\n                if not neighbour in frontier:\n                    frontier.append([calculus_distance(neighbour,graph,weights),neighbour])\n                    weights[neighbour]=calculus_distance(neighbour,graph,weights)\n                elif weights[neighbour] &gt; calculus_distance(neighbour,graph,weights):\n                    frontier[neighbour][0]=calculus_distance(neighbour,graph,weights)\n                    weights[neighbour]=calculus_distance(neighbour,graph,weights)\n    graph.distances = weights\n</code></pre> <p>adjust_FM</p> <p>Ce code permet d'ajuster les fronts d'onde g\u00e9n\u00e9r\u00e9s par la m\u00e9thode de Fast Marching.</p> <p>Le code commence par initialiser deux listes vides, Lx_gauche et Lx_droite. Ces listes vont contenir les coordonn\u00e9es des points du front d'onde qui sont \u00e0 gauche ou \u00e0 droite d'un point infini ou ind\u00e9fini.</p> <p>Ensuite, le code parcourt les fronts d'onde et ajoute les coordonn\u00e9es des points \u00e0 la liste Lx_gauche ou Lx_droite si ces points sont \u00e0 gauche ou \u00e0 droite d'un point infini ou ind\u00e9fini. Il en fait de m\u00eame pour les coordonn\u00e9es des points du front d'onde qui sont en haut ou en bas d'un point infini ou ind\u00e9fini, qu'il ajoute aux listes Ly_haut et Ly_bas.</p> <p>Enfin, le code remplace les valeurs des points des fronts d'onde contenus dans les listes Lx_gauche, Lx_droite, Ly_haut et Ly_bas par les valeurs de leurs voisins les plus proches, en parcourant les listes et en acc\u00e9dant aux valeurs des tableaux FX et FY correspondant aux fronts d'onde en question.</p> <pre><code>def adjust_FM():\n\n    Lx_gauche = []\n    Lx_droite = []\n\n    for i in range(1,n):\n      for j in range(1,len(FX[0])-1):\n\n        u , v = FX[i][j] , FX[i][j+1]\n\n        if u == float('inf') or u == -float('inf'):\n          if v != float('inf') and v != -float('inf') and not isnan(v):\n            Lx_gauche.append((i,j))\n\n        if v == float('inf') or v == -float('inf'):\n          if u != float('inf') and u != -float('inf') and not isnan(u):\n            Lx_droite.append((i,j+1))\n\n    for cellule in Lx_gauche:\n      i, j = cellule\n      FX[i][j] = FX[i][j+1]\n\n    for cellule in Lx_droite:\n      i, j = cellule\n      FX[i][j] = FX[i][j-1]\n\n    Ly_haut = []\n    Ly_bas = []\n\n    for i in range(1,n-1):\n      for j in range(1,len(FY[0])):\n\n        u , v = FY[i][j] , FY[i+1][j]\n\n        if u == float('inf') or u == -float('inf'):\n          if v != float('inf') and v != -float('inf') and not isnan(v):\n            Ly_haut.append((i,j))\n\n        if v == float('inf') or v == -float('inf'):\n          if u != float('inf') and u != -float('inf') and not isnan(u):\n            Ly_bas.append((i+1,j))\n\n\n    for cellule in Ly_haut:\n      i, j = cellule\n      FY[i][j] = FY[i+1][j]\n\n    for cellule in Ly_bas:\n      i, j = cellule\n      FY[i][j] = FY[i-1][j]\n</code></pre>"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#myagent","title":"MyAgent","text":"<p>myAgent</p> <p>Ce code d\u00e9finit la classe <code>myAgent</code>, qui repr\u00e9sente un agent dans notre environnement de simulation. Chaque instance de cette classe contient les attributs suivants :</p> <p>position: un vecteur 2D repr\u00e9sentant la position de l'agent dans l'environnement.</p> <p>speed: un vecteur 2D repr\u00e9sentant la vitesse actuelle de l'agent.</p> <p>D_S: un vecteur 2D repr\u00e9sentant la direction d\u00e9sir\u00e9e de l'agent (c'est-\u00e0-dire la direction vers laquelle il souhaite se d\u00e9placer).</p> <p>size: la taille de l'agent.</p> <p>has_reached_exit: un bool\u00e9en qui indique si l'agent a atteint la sortie ou non.</p> <p>near_to_exit: un bool\u00e9en qui indique si l'agent est proche de la sortie ou non.</p> <p>masse: la masse de l'agent.</p> <p>color: la couleur de l'agent.</p> <p>La classe myAgent contient \u00e9galement plusieurs m\u00e9thodes :</p> <p>desired_direction: Cette m\u00e9thode calcule la direction d\u00e9sir\u00e9e de l'agent en fonction de la position actuelle de l'agent dans l'environnement et de la carte de flux (contenue dans les matrices FX et FY).</p> <p>update_D_S: Cette m\u00e9thode met \u00e0 jour le vecteur D_S en appelant la m\u00e9thode desired_direction.</p> <p>update_Speed: Cette m\u00e9thode met \u00e0 jour la vitesse de l'agent en fonction d'un vecteur de vitesse donn\u00e9 en argument.</p> <p>reach_exit: Cette m\u00e9thode v\u00e9rifie si l'agent a atteint l'une des sorties de l'environnement et met \u00e0 jour l'attribut has_reached_exit en cons\u00e9quence.</p> <p>update_Position: Cette m\u00e9thode met \u00e0 jour la position de l'agent en fonction d'un vecteur de position donn\u00e9 en argument et appelle la m\u00e9thode reach_exit pour mettre \u00e0 jour l'attribut has_reached_exit.</p> <pre><code>class myAgent():\n\n    def __init__(self, position):\n        self.position = numpy.array(position)\n        self.speed = (0,0)\n        self.D_S = (0,0)\n        self.size = 0.2\n        self.has_reached_exit = False\n        self.near_to_exit = False\n        self.masse = 80\n        self.color = 'red'\n\n    def desired_direction(self):\n        x, y = self.position\n        a, b = size_scene\n        n , m = int(x/h) , int((b-y)/h)\n        if n &lt; 0 : n = 0\n        if m &lt; 0 : m = 0\n        if n &gt; len(FX[0])-1 : n = len(FX[0])-1\n        if m &gt; len(FX)-1 : m = len(FX)-1\n        v = numpy.array((FX[m][n], FY[m][n]))\n        if norm(v)==0: return numpy.array((0,0))\n        return v / norm(v)\n\n    def update_D_S(self):\n        self.D_S = self.desired_direction()\n\n    def update_Speed(self, v):\n        self.speed = (v[0],v[1])\n\n    def reach_exit(self):\n        for ex in exits:\n            d , _ = distance_vecteur_obs(self.position , self.size, ex)\n            if d &lt;= 0.2:\n                self.has_reached_exit = True\n                break\n\n    def update_Position(self, q):\n        self.position = q\n        self.reach_exit()\n</code></pre>"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#fonctions","title":"Fonctions","text":"<p>f_motrice</p> <p>La fonction <code>f_motrice(agent)</code> calcule la force motrice qui sera appliqu\u00e9e \u00e0 l'agent.</p> <p>Elle prend en entr\u00e9e l'objet agent qui doit poss\u00e9der au moins un attribut D_S (vecteur unitaire repr\u00e9sentant la direction d\u00e9sir\u00e9e par l'agent) et speed (vecteur vitesse de l'agent).</p> <p>La force motrice est calcul\u00e9e comme suit :</p> <ul> <li> <p>Le coefficient de relaxation tau est d\u00e9fini \u00e0 0.5.</p> </li> <li> <p>La force motrice est donn\u00e9e par l'expression : (2 x direction d\u00e9sir\u00e9e - vitesse courante) / tau</p> </li> <li> <p>Le r\u00e9sultat est un vecteur qui repr\u00e9sente la force motrice \u00e0 appliquer \u00e0 l'agent.</p> </li> </ul> <p>La force motrice est la force qui pousse l'agent \u00e0 suivre la direction d\u00e9sir\u00e9e, en prenant en compte sa vitesse courante pour \u00e9viter les changements brutaux de direction. Elle permet de mod\u00e9liser le comportement des agents qui avancent dans une direction donn\u00e9e tout en essayant de minimiser les changements de direction brusques.</p> <pre><code>#force motrice\ndef f_motrice(agent):\n    tau = 0.5\n    return (numpy.array(agent.D_S)*2 - numpy.array(agent.speed))/tau\n</code></pre> <p>dist &amp; distance_vecteur_obj &amp; distance_vecteur_obs_cir &amp; distance_vecteur_obs</p> <p>Ces fonctions sont toutes des fonctions de calcul de distance entre deux points ou un point et un obstacle.</p> <ul> <li> <p>La fonction <code>dist(p1, p2)</code> prend deux points p1 et p2 et retourne la norme de leur diff\u00e9rence. Cette norme est calcul\u00e9e en utilisant la fonction numpy.array() pour cr\u00e9er des tableaux numpy \u00e0 partir des points, puis en calculant la diff\u00e9rence entre ces tableaux \u00e0 l'aide de l'op\u00e9rateur - et en utilisant la fonction norm() pour calculer la norme.</p> </li> <li> <p>La fonction <code>distance_vecteur_obj(q1, q2, r1, r2)</code> prend deux points q1 et q2, ainsi que deux rayons r1 et r2 et calcule la distance entre ces deux objets. La distance est calcul\u00e9e comme la distance entre q1 et q2 moins la somme des rayons r1 et r2. La fonction renvoie \u00e9galement le vecteur normalis\u00e9 allant de q2 \u00e0 q1.</p> </li> <li> <p>La fonction <code>distance_vecteur_obs_cir(q, r, obstacle)</code> prend un point q, un rayon r et un objet circulaire obstacle (repr\u00e9sent\u00e9 par sa position et son rayon) et calcule la distance entre le point et l'obstacle. La distance est calcul\u00e9e comme la distance entre le point et le centre de l'obstacle, moins la somme des rayons. La fonction renvoie \u00e9galement le vecteur normalis\u00e9 allant du centre de l'obstacle \u00e0 q.</p> </li> <li> <p>La fonction <code>distance_vecteur_obs(q, r, obstacle)</code> prend un point q, un rayon r et un obstacle rectangulaire obstacle (repr\u00e9sent\u00e9 par sa position, sa largeur et sa hauteur) et calcule la distance entre le point et l'obstacle. La distance est calcul\u00e9e comme la distance entre q et le point de l'obstacle le plus proche de q. Ce point est calcul\u00e9 en projetant q sur le rectangle et en s\u00e9lectionnant le point projet\u00e9 qui est le plus proche de q. La fonction renvoie \u00e9galement le vecteur normalis\u00e9 allant du point le plus proche de q sur l'obstacle \u00e0 q.</p> </li> </ul> <pre><code>def dist(p1,p2):\n    return norm(numpy.array(p1)-numpy.array(p2))\n\ndef distance_vecteur_obj(q1, q2, r1, r2):\n    d = dist(q1, q2)\n\n    n = -(numpy.array(q2) - numpy.array(q1))/d\n\n    d = d - (r1 + r2)\n\n    return d , n\n\ndef distance_vecteur_obs_cir(q , r, obstacle):\n    [a0, b0], rayon = obstacle.position, obstacle.rayon\n    x , y = q\n\n    d = ((x-a0)**2 + (y-b0)**2)**0.5 \n    n = -(numpy.array(obstacle.position) - numpy.array(q))/d\n    d = d - (rayon + r)\n\n    return d , n\n\ndef distance_vecteur_obs(q , r, obstacle):\n    [a0, b0], L, l = obstacle.position, obstacle.width, obstacle.height\n    a1, b1 = a0 + L , b0 + l\n    x , y = q\n    point = []\n\n    if x&lt;=a0:\n      if y&gt;=b1:\n        point = [a0, b1]\n\n      elif b0&lt;y&lt;b1:\n        point = [a0, y]\n\n      else:\n        point = [a0, b0]\n\n    elif a0&lt;x&lt;a1:\n      if y&gt;=b1:\n        point = [x, b1]\n\n      elif b0&lt;y&lt;b1:\n        point = [x, b1]\n\n      else:\n        point = [x, b0]\n\n    else:\n      if y&gt;=b1:\n        point = [a1, b1]\n\n      elif b0&lt;y&lt;b1:\n        point = [a1, y]\n\n      else:\n        point = [a1, b0]\n\n    d = dist(point , q)\n    n = (numpy.array(q) - numpy.array(point))/d\n\n    return d - r , n\n</code></pre> <p>matrice_normals</p> <p>Cette fonction <code>matrice_normals(q, R)</code> calcule les vecteurs normaux pour chaque collision possible entre les agents et les obstacles dans un environnement donn\u00e9.</p> <p>La fonction prend en entr\u00e9e deux listes : q qui est la liste des positions des agents et R qui est la liste des rayons de chaque agent.</p> <p>La fonction retourne une matrice numpy, Normals, qui contient les vecteurs normaux de chaque collision, o\u00f9 chaque ligne repr\u00e9sente un vecteur normal pour un choc possible et chaque colonne repr\u00e9sente un agent (donc 2*m colonnes pour m agents). La fonction retourne \u00e9galement une liste, agents_en_chocs, qui contient les indices des agents impliqu\u00e9s dans au moins une collision.</p> <p>La fonction parcourt tous les agents et v\u00e9rifie s'il y a une collision avec un autre agent ou un obstacle. Si une collision est d\u00e9tect\u00e9e, la fonction calcule le vecteur normal correspondant \u00e0 cette collision \u00e0 l'aide de distance_vecteur_obj() pour une collision entre deux agents, distance_vecteur_obs() pour une collision entre un agent et un obstacle rectangulaire et distance_vecteur_obs_cir() pour une collision entre un agent et un obstacle circulaire.</p> <p>Les vecteurs normaux sont stock\u00e9s dans la matrice Normals et les indices des agents impliqu\u00e9s dans des collisions sont stock\u00e9s dans la liste agents_en_chocs.</p> <p>En fin de parcours, la fonction renvoie la matrice Normals et la liste agents_en_chocs.</p> <pre><code>def matrice_normals(q, R):\n\n    Normals = []\n    agents_en_chocs = []\n    m = len(q)\n\n    #chocs agents\n    for i in range(m):\n\n        N = numpy.zeros(2*m)\n\n        for j in range(m):\n          if j != i:\n            d , n = distance_vecteur_obj(q[i], q[j], R[i], R[j])\n            if d &lt;= 0.2:\n              N[2*i], N[2*i+1], N[2*j], N[2*j+1] = n[0], n[1], -n[0], -n[1]\n\n        if not all(v == 0 for v in N):\n          Normals.append(N)\n          agents_en_chocs.append(i)\n\n    #chocs obstacle\n    for obstacle in obstacles:\n\n        N = numpy.zeros(2*m)\n\n        for i in range(m):\n          d , n = distance_vecteur_obs(q[i] , R[i], obstacle)\n          if d &lt;= 0.2:\n            N[2*i], N[2*i+1] = n[0], n[1]\n            if N[2*i] != 0 or N[2*i+1] != 0:\n              agents_en_chocs.append(i)\n\n        if not all(v == 0 for v in N):\n          Normals.append(N)\n\n    #chocs obstacle circulaire\n    for obstacle in obstacles_cir:\n\n        N = numpy.zeros(2*m)\n\n        for i in range(m):\n          d , n = distance_vecteur_obs_cir(q[i] , R[i], obstacle)\n          if d &lt;= .2:\n            N[2*i], N[2*i+1] = n[0], n[1]\n            if N[2*i] != 0 or N[2*i+1] != 0:\n              agents_en_chocs.append(i)\n\n        if not all(v == 0 for v in N):\n          Normals.append(N)\n\n    return numpy.array(Normals) , agents_en_chocs\n</code></pre> <p>detection_de_chocs</p> <p>La fonction <code>detection_de_chocs(Q, R)</code> qui prend en entr\u00e9e deux listes Q et R contenant respectivement les positions et les rayons de tous les agents et qui renvoie True si deux agents ou un agent et un obstacle se trouvent \u00e0 une distance inf\u00e9rieure \u00e0 une marge de collision marge, et False sinon.</p> <p>La fonction parcourt d'abord tous les obstacles rectangulaires et circulaires stock\u00e9s dans les variables obstacles et obstacles_cir, respectivement, pour v\u00e9rifier s'il y a une collision entre l'agent et l'un de ces obstacles en comparant les coordonn\u00e9es de l'agent \u00e0 celles des coins de l'obstacle et \u00e0 la distance de l'agent au centre de l'obstacle. Ensuite, la fonction compare la distance entre l'agent courant et tous les autres agents pour v\u00e9rifier s'il y a une collision entre eux.</p> <p>Si une collision est d\u00e9tect\u00e9e, la fonction retourne True, sinon elle retourne False.</p> <pre><code>def detection_de_chocs(Q, R):\n\n  m = len(agents)\n\n  for i in range(m):\n    [x , y], r = Q[i], R[i]\n    marge = .2\n\n    #chocs obstacle\n    for obstacle in obstacles:\n        [a0, b0], L, l = obstacle.position, obstacle.width, obstacle.height\n        a1, b1 = a0 + L , b0 + l\n\n        if a0&lt;=x&lt;=a1 and b0-r-marge&lt;=y&lt;=b1+r+marge: return True\n        if b0&lt;=y&lt;=b1 and a0-r-marge&lt;=x&lt;=a1+r+marge: return True\n\n    for obst in obstacles_cir:\n        [a0, b0], rayon = obst.position, obst.rayon\n        d = ((x - a0)**2 + (y - b0)**2)**0.5\n        if d - (rayon+r) &lt; 2 : return True\n\n    #chocs agents\n    for j in range(m):\n      if j != i:\n        if dist(Q[i], Q[j]) - (R[i]+R[j]) &lt;= marge: return True\n\n  return False\n</code></pre> <p>predict_position2</p> <p>La fonction <code>predict_position2(V)</code> permet de pr\u00e9dire la position des agents \u00e0 l'instant suivant en fonction de leur vitesse actuelle et leur vitesse future, ainsi que de leur position actuelle. Elle prend en entr\u00e9e une liste V de la vitesse de chaque agent (vecteur de dimension 2 pour chaque agent) \u00e0 l'instant actuel.</p> <p>Le premier \u00e9l\u00e9ment de la fonction convertit la liste V en un tableau V_future de dimension p x 2 o\u00f9 p est le nombre d'agents dans la simulation. Chaque ligne de V_future contient la vitesse future d'un agent sous la forme d'un vecteur de dimension 2.</p> <p>Le deuxi\u00e8me \u00e9l\u00e9ment de la fonction cr\u00e9e un tableau V_passe de dimension m x 2, o\u00f9 m est le nombre total d'agents dans la simulation. Chaque ligne de V_passe contient la vitesse actuelle de chaque agent sous la forme d'un vecteur de dimension 2.</p> <pre><code>def predict_position2(V):\n  p = int(len(V)/2)\n  V_future =  numpy.array([ numpy.array([V[2*j], V[2*j+1]]) for j in range(p) ])\n  V_passe =   numpy.array([ numpy.array(agent.speed) for agent in agents ])\n\n  return [numpy.array(agent.position) + dt*(V_future[agents.index(agent)] + V_passe[agents.index(agent)])/2 for agent in agents]\n</code></pre> <p>correction_vitesses</p> <p>Cette fonction prend en entr\u00e9e la vitesse actuelle de chaque agent, la force ext\u00e9rieure appliqu\u00e9e \u00e0 chaque agent et le coefficient de restitution entre les agents. Elle calcule ensuite la nouvelle vitesse pour chaque agent en fonction des chocs d\u00e9tect\u00e9s en appelant la fonction matrice_normals qui retourne la matrice des normales pour chaque agent en collision avec un autre agent ou un obstacle.</p> <p>Dans la premi\u00e8re partie de la fonction, la fonction predict_position2 est appel\u00e9e pour pr\u00e9dire la position future des agents. Ensuite, la fonction detection_de_chocs est appel\u00e9e pour v\u00e9rifier s'il y a collision entre les agents et les obstacles.</p> <p>Si une collision est d\u00e9tect\u00e9e, la fonction calcule la matrice de masse M pour chaque agent et la matrice de normales C_N pour chaque collision. Ensuite, elle calcule la matrice U en multipliant la transpos\u00e9e de C_N avec C_N. Cette matrice est utilis\u00e9e pour calculer la matrice de contrainte P.</p> <pre><code>def correction_vitesses(V, Pext, K_n):\n    V, Pext = numpy.array(V), numpy.array(Pext)\n    p = len(agents)\n    agents_en_chocs = []\n\n    q = predict_position2(V)\n    R = [agent.size for agent in agents]\n\n    if detection_de_chocs(q, R):\n        # Matrice Masse\n        M = numpy.zeros((2*p, 2*p))\n        for i in range(p):\n            M[2*i][2*i] = agents[i].masse\n            M[2*i+1][2*i+1] = agents[i].masse\n\n        # Matrice Normales\n        C_N , agents_en_chocs = matrice_normals(q, R)\n\n        U = dot(C_N.transpose(), C_N)\n\n        P = matrix(numpy.array(M) + 0.5 * K_n * U , tc='d')\n        q = matrix(numpy.array(dot(M - 0.5 * K_n * U , V) + dt * Pext), tc='d')\n        G = matrix(numpy.array(C_N), tc='d')\n        h = matrix(numpy.array(numpy.zeros(len(C_N))), tc='d')\n\n        solvers.options['show_progress'] = False\n\n        return list(solvers.qp(P,-q,-G,h)['x']) , agents_en_chocs\n\n    else:\n        return V , agents_en_chocs\n</code></pre> <p>matrice_DistancesEtNormaux &amp; matrice_DistancesEtNormaux_danger</p> <p>Ces deux fonctions g\u00e9n\u00e8rent une matrice de distances et une matrice de normales entre les agents (ou les dangers) du sc\u00e9nario.</p> <p>La fonction <code>matrice_DistancesEtNormaux(agents)</code> prend en entr\u00e9e une liste d'objets agents et renvoie une matrice de distance matrice_distance et une matrice de normales matrice_normaux. Les matrices sont carr\u00e9es et de taille \u00e9gale au nombre d'agents dans la liste agents. La matrice de distance matrice_distance contient les distances entre chaque paire d'agents, et la matrice de normales matrice_normaux contient les normales correspondantes.</p> <p>La fonction <code>matrice_DistancesEtNormaux_danger(agents)</code> prend en entr\u00e9e une liste d'objets agents et renvoie une matrice de distance matrice_distance et une matrice de normales matrice_normaux entre chaque agent de la liste et le danger Dangers[0]. La matrice de distance matrice_distance contient les distances entre chaque agent et le danger, et la matrice de normales matrice_normaux contient les normales correspondantes.</p> <pre><code>def matrice_DistancesEtNormaux(agents):\n    N_ind = len(agents)\n    matrice_distance = numpy.zeros((N_ind, N_ind))\n    matrice_normaux = numpy.zeros((N_ind, N_ind,2))\n    for i in range(N_ind):\n        for j in range(N_ind):\n            if i &gt; j:\n                d, n = distance_vecteur_obj(agents[i].position, agents[j].position, agents[i].size, agents[j].size)\n                matrice_distance[i][j] = d\n                matrice_distance[j][i] = d\n                matrice_normaux[i][j] = n\n                matrice_normaux[j][i] = -n\n    return matrice_distance , matrice_normaux\n\ndef matrice_DistancesEtNormaux_danger(agents):\n    N_ind = len(agents)\n    matrice_distance = numpy.zeros(N_ind)\n    matrice_normaux = numpy.zeros((N_ind, 2))\n    for i in range(N_ind):\n        d = dist(Dangers[0], agents[i].position)\n        n = norm(numpy.array(Dangers[0]) - numpy.array(agents[i].position))\n        matrice_distance[i] = d\n        matrice_normaux[i] = n\n    return matrice_distance , matrice_normaux\n</code></pre>"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#configuration","title":"Configuration","text":"<pre><code>a , b , eps = 10 , 10 , 0.2\nsize_scene = (a,b)\n\nobstacles = [Obstacle((0,0),a,eps), Obstacle((0,eps),eps,b-eps), Obstacle((eps,b-eps),a-eps,eps), Obstacle((a-eps, eps),eps, b-2*eps)]\n\nexits = [Exit((4,a-eps), 1, eps)]\n\nobstacles_cir = []\n\ndraw(exits, obstacles, obstacles_cir, size_scene, [], 0, 'gemoetrie.png', play=True)\n</code></pre> Output"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#champs-de-directions","title":"Champs de directions","text":"<pre><code>h = .5 #pas de discritisation du FAst Marching\n\ngraph = GridGraph(size_scene,1/h)\n\ngraph.prepare_graph_for_fast_marching(obstacles, obstacles_cir, exits)\n\nfast_marching_method(graph, (0,0))\n</code></pre> <pre><code>d = graph.distances\nd_tr = []\nn = len(d)\n\nfor i in range(n):\n    d_tr.append(d[n-i-1])\n\nFY, FX = numpy.gradient(numpy.array(d_tr))\n\nFX = -FX\n\nadjust_FM()\n</code></pre> Output"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#simulation","title":"Simulation","text":"<pre><code>N_pop = 10\ntemps_de_sim = 1*60 #secondes\ndt = 5e-2\nN_iter = int(temps_de_sim / dt)\n\nagents = generate_indiv(N_pop)\n\ndraw(exits, obstacles, obstacles_cir, size_scene, agents, 0, 'config_init.png', play=True)\n</code></pre> Output <pre><code>K_n = 0\n\nR = [agent.size for agent in agents]\n\n!mkdir DossierImages\nfor image in os.listdir('DossierImages'):\n    os.remove('DossierImages/' + image)\n\nfor n in tqdm(range(N_iter)):\n\n    if len(agents)==0:break\n\n    V_avant_correction = []\n    P = []\n    matrice_distance , matrice_normaux = matrice_DistancesEtNormaux(agents)\n\n    for agent in agents:\n\n        agent.update_D_S()\n        p_ext = f_motrice(agent)\n        vi = agent.speed + dt*p_ext/agent.masse\n        V_avant_correction.extend(vi)\n        P.extend(p_ext)\n\n    V_new , agents_en_chocs = correction_vitesses(V_avant_correction, P, K_n)\n    q = predict_position2(V_new)\n\n    for agent in agents:\n        k = agents.index(agent)\n        agent.update_Speed([V_new[2*k] , V_new[2*k+1]])\n        agent.update_Position(q[k])\n\n    for agent in agents:\n        if agent.has_reached_exit: agents.remove(agent)\n\n    path = 'DossierImages/simulation' + str(n) + '.jpg'\n    draw(exits, obstacles, obstacles_cir, size_scene, agents,round(n*dt, 2), savepath=path, play = False)\n\nprint('Simulation finished.')\nrecord_video(speed = 25)\n</code></pre> Output"},{"location":"projects/abstractive%20summarization/","title":"Abstractive Summarization","text":""},{"location":"projects/abstractive%20summarization/#introduction","title":"Introduction","text":"<p><code>Abstractive Summarization</code> is a Natural Language Processing (NLP) task that aims to generate a concise summary of a source text. Unlike extractive summarization, Abstractive Summarization doesn't merely copy important sentences from the source text but can also create new, relevant sentences, which can be considered paraphrases. Abstractive Summarization has numerous applications in various domains, from books and literature to science and R&amp;D, financial research, and legal document analysis.</p> <p>So far, the most recent and effective approach to Abstractive Summarization is to use transformation models specifically tailored to a summary dataset. In this study, we demonstrate how you can easily summarize a text using a powerful model in a few simple steps. First, we'll use two models that are already pre-trained, so no additional training is needed. Then, we'll fine-tune one of these models on our dataset.</p> <p>Without further ado, let's get started!</p>"},{"location":"projects/abstractive%20summarization/#importing-data","title":"Importing Data","text":"<pre><code>import pandas as pd\ndata = pd.read_json(\"/content/sample_data/AgrSmall.json\")\ndata.head()\n</code></pre>"},{"location":"projects/abstractive%20summarization/#using-bart-large-cnn-t5-base-transformers","title":"Using bart-large-cnn &amp; t5-base Transformers","text":""},{"location":"projects/abstractive%20summarization/#installing-the-transformers-library","title":"Installing the Transformers Library","text":"<p>The library we're going to use is Transformers by Huggingface.</p> <p>To install Transformers, simply run this cell:</p> <pre><code>pip install transformers\n</code></pre> <p>Note</p> <p>Transformers requires the prior installation of PyTorch. If you haven't already installed PyTorch, visit the official PyTorch website and follow the instructions to install it.</p>"},{"location":"projects/abstractive%20summarization/#importing-libraries","title":"Importing Libraries","text":"<p>After successfully installing Transformers, we can now start importing it into your Python script. We can also import <code>os</code> to set the environment variable to be used by the GPU in the next step.</p> <pre><code>from transformers import pipeline\nimport os\n</code></pre> <p>Now, we're ready to select the summarization model to use. Huggingface provides two powerful summarization models to use: <code>BART</code> (bart-large-cnn) and <code>t5</code> (t5-small, t5-base, t5-large, t5-3b, t5-11b). For more information about these models, please refer to their official documents (BART document, t5 document).</p> <p>To use the BART model, which is trained on the CNN/Daily Mail News Dataset, we directly use the default parameters via the built-in Huggingface pipeline module:</p> <pre><code>summarizer = pipeline(\"summarization\")\n</code></pre> <p>To use the t5 model (e.g., t5-base), trained on the c4 Common Crawl web corpus, we proceed as follows:</p> <pre><code>summarizer = pipeline(\"summarization\", model=\"t5-base\", tokenizer=\"t5-base\", framework=\"tf\")\n</code></pre> <p>For more information, please refer to the Huggingface documentation.</p>"},{"location":"projects/abstractive%20summarization/#entering-text-to-summarize","title":"Entering Text to Summarize","text":"<p>Now that our model is ready, we can start selecting the texts we want to summarize. We suggest choosing the first 4 abstracts in our dataset:</p> <p>We define our variables:</p> <pre><code>text_1 = data[\"abstracts\"][0]\nprint(text_1)\n</code></pre> Output text_1 <p>Most people in rural areas in South Africa (SA) rely on untreated drinking groundwater sources and pit latrine sanitations. A minimum basic sanitation facility should enable safe and appropriate removal of human waste, and although pit latrines provide this, they are still contamination concerns. Pit latrine sludge in SA is mostly emptied and disposed off-site as waste or buried in-situ. Despite having knowledge of potential sludge benefits, most communities in SA are reluctant to use it. This research captured social perceptions regarding latrine sludge management in Monontsha village in the Free State Province of SA through key informant interviews and questionnaires. A key informant interview and questionnaire was done in Monontsha, SA. Eighty participants, representing 5% of all households, were selected. Water samples from four boreholes and four rivers were analyzed for faecal coliforms and E.coli bacteria. On average, five people in a household were sharing a pit latrine. Eighty-three percent disposed filled pit latrines while 17% resorted to closing the filled latrines. Outbreaks of diarrhoea (69%) and cholera (14%) were common. Sixty percent were willing to use treated faecal sludge in agriculture. The binary logistic regression model indicated that predictor variables significantly (p \u02c2 0.05) described water quality, faecal sludge management, sludge application in agriculture and biochar adaption. Most drinking water sources in the study had detections \u02c2 1 CFU/100 mL. It is therefore imperative to use both qualitative surveys and analytical data. Awareness can go a long way to motivate individuals to adopt to a new change. View Full-Text</p> <pre><code>text_2 = data[\"abstracts\"][1]\nprint(text_2)\n</code></pre> Output text_2 <p>The aim of this study was to highlight the importance of socioeconomic and psychosocial factors in the adoption of sustainable agricultural practices (SAPs) in banana farm production. To this end, data from 300 randomly selected farm households from Pakistan were collected through a structured self-report questionnaire. Using logistic regression (LR) and structural equation modeling (SEM), socioeconomic and psychosocial effects were evaluated. The results show that economic status, watching agricultural training programs, newspaper and radio awareness campaigns, participation in extension programs, perceptions of sustainable agriculture and the feasibility of SAPs were significant factors in farmers\u2019 adoption of sustainable agriculture practices. Also, consistent with the theory of planned behavior (TPB), all its dimensions (attitude, subjective norms and perceived behavioral control) affected the adoption of SAPs. This finding highlights the importance of socioeconomic and psychosocial factors in promoting sustainable agricultural practice among banana production farmers. This is the first study which attempts to provide empirical evidence using a robust procedure (two models\u2014LR and SEM). The practical implication is that, when socioeconomic and psychosocial factors are well supported by satisfactory policy measures, SAP adoption is more than likely, which eventually increases farmers\u2019 adaptive capacity to the changing environment. Ultimately, this leads to sustainable banana production, which has great potential to contribute towards poverty eradication. View Full-Text</p> <pre><code>text_3 = data[\"abstracts\"][2]\nprint(text_3)\n</code></pre> Output text_3 <p>Urban agriculture and gardening provide many health benefits, but the soil is sometimes at risk of heavy metal and metalloid (HMM) contamination. HMM, such as lead and arsenic, can result in adverse health effects for humans. Gardeners may face exposure to these contaminants because of their regular contact with soil and consumption of produce grown in urban areas. However, there is a lack of research regarding whether differential exposure to HMM may be attributed to differential knowledge of exposure sources. In 2018, industrial slag and hazardous levels of soil contamination were detected in West Atlanta. We conducted community-engaged research through surveys and follow-up interviews to understand awareness of slag, HMM in soil, and potential remediation options. Home gardeners were more likely to recognize HMM health effects and to cite health as a significant benefit of gardening than community gardeners. In terms of knowledge, participants were concerned about the potential health effects of contaminants in soil yet unconcerned with produce in their gardens. Gardeners\u2019 knowledge on sources of HMM exposure and methods for remediation were low and varied based on racial group. View Full-Text</p> <pre><code>text_4 = data[\"abstracts\"][3]\nprint(text_4)\n</code></pre> Output text_4 <p>Waste management has become pertinent in urban regions, along with rapid population growth. The current ways of managing waste, such as refuse collection and recycling, are failing to minimise waste in cities. With urban populations growing worldwide, there is the challenge of increased pressure to import food from rural areas. Urban agriculture not only presents an opportunity to explore other means of sustainable food production, but for managing organic waste in cities. However, this opportunity is not taken advantage of. Besides, there is a challenge of mixed reactions from urban planners and policymakers concerning the challenges and benefits presented by using organic waste in urban agriculture. The current paper explores the perceived challenges and opportunities for organic waste utilisation and management through urban agriculture in the Durban South Basin in eThekwini Municipality in KwaZulu-Natal (KZN) Province of South Africa. It is anticipated that this information will be of use to the eThekwini Municipality, policymakers, researchers, urban agriculture initiatives, households and relevant stakeholders in the study areas and similar contexts globally. Two hundred (200) households involved in any urban farming activity and ten (10) key informants (six (6) staff from the Cleaning and Solid Waste Unit of the eThekwini Municipality and four (4) from the urban agricultural initiative) were selected using convenient sampling. Descriptive statistics and inductive thematic analysis were used to analyse data. The significant perceived challenges and risks associated with the utilisation of organic waste through urban agriculture included lack of a supporting policy, climatic variation, lack of land tenure rights, soil contamination and food safety concerns. Qualitative data further showed that the difficulty in segregating waste, water scarcity, difficulty in accessing inputs, limited transportation of organic waste, inadequate handling and treatment of organic waste, and being a health hazard were some important challenges. On the other hand, the significant perceived benefits associated with the utilisation of organic waste through urban agriculture were enhanced food and nutrition security, and opportunities for business incubation. Other important benefits established through qualitative data were an improved market expansion for farmers and improved productivity. Overall, despite the perceived challenges and risks, there is an opportunity to manage organic waste through urban agriculture. It is imperative for an integrated policy encompassing the food, climate and waste management to be developed to support this strategy. All stakeholders\u2014the government, municipal authorities and urban agricultural initiatives should also, guided by the policy, support urban farmers, for example, through pieces of training on how to properly manage and recycle organic waste, land distribution, inputs availability and water usage rights among other things. View Full-Text</p>"},{"location":"projects/abstractive%20summarization/#summary-generation","title":"Summary Generation","text":"<p>Finally, we can start summarizing the input texts. Here, we specify the minimum and maximum length we want for the summary output and disable sampling to generate fixed summaries. You can do this by running the following commands:</p> <pre><code>summary_text_1 = summarizer(text, max_length=100, min_length=5, do_sample=False)[0]['summary_text']\nprint(summary_text_1)\n</code></pre> <p>There you have it! We get the summary of the first text:</p> Output <p>Most people in rural areas in South Africa rely on untreated drinking groundwater sources and pit latrine sanitations . Outbreaks of diarrhoea (69%) and cholera (14%) were common. Sixty percent were willing to use treated faecal sludge in agriculture .</p> <pre><code>summary_text_2 = summarizer(text_2, max_length=100, min_length=5, do_sample=False)[0]['summary_text']\nprint(summary_text_2)\n</code></pre> <p>There you have it! We get the summary of the second text:</p> Output <p>The aim of this study was to highlight the importance of socioeconomic and psychosocial factors in the adoption of sustainable agricultural practices (SAPs) in banana farm production . Economic status, watching agricultural training programs, newspaper and radio awareness campaigns, perceptions of sustainable agriculture and the feasibility of SAPs were significant factors .</p> <pre><code>summary_text_3 = summarizer(text_3, max_length=100, min_length=5, do_sample=False)[0]['summary_text']\nprint(summary_text_3)\n</code></pre> <p>There you have it! We get the summary of the third text:</p> Output <p>Heavy metal and metalloid (HMM) contamination can result in adverse health effects for humans . In 2018, industrial slag and hazardous levels of soil contamination were detected in West Atlanta . Home gardeners were more likely to recognize HMM health effects than community gardeners .</p> <pre><code>summary_text_4 = summarizer(text_4, max_length=100, min_length=5, do_sample=False)[0]['summary_text']\nprint(summary_text_4)\n</code></pre> <p>There you have it! We get the summary of the third text:</p> Output <p>Waste management has become pertinent in urban regions, along with rapid population growth . The current ways of managing waste, such as refuse collection and recycling, are failing to minimise waste in cities . With urban populations growing worldwide, there is the challenge of increased pressure to import food from rural areas .</p>"},{"location":"projects/abstractive%20summarization/#fine-tuning-simplet5","title":"Fine-tuning SimpleT5","text":"<pre><code>!pip install simplet5\n</code></pre> <pre><code>import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\npath = \"/content/sample_data/AgrSmall.json\"\ndf = pd.read_json(path)\ndf.head()\n</code></pre> <pre><code># simpleT5 expects dataframe to have 2 columns: \"source_text\" and \"target_text\"\ndf = df.rename(columns={\"titles\":\"target_text\", \"abstracts\":\"source_text\"})\ndf = df[['source_text', 'target_text']]\n\n# T5 model expects a task related prefix: since it is a summarization task, we will add a prefix \"summarize: \"\ndf['source_text'] = \"summarize: \" + df['source_text']\ndf\n</code></pre> <pre><code>train_df, test_df = train_test_split(df, test_size=0.2)\ntrain_df.shape, test_df.shape\n</code></pre> <pre><code>from simplet5 import SimpleT5\n\nmodel = SimpleT5()\nmodel.from_pretrained(model_type=\"t5\", model_name=\"t5-base\")\nmodel.train(train_df=train_df[:3000],\n            eval_df=test_df[:100], \n            source_max_token_len=128, \n            target_max_token_len=50, \n            batch_size=8, max_epochs=3, use_gpu=True)\n</code></pre> <pre><code># let's load the trained model for inferencing:\nmodel.load_model(\"t5\",\"/content/outputs/simplet5-epoch-0-train-loss-2.806-val-loss-2.5596\", use_gpu=True)\n\ntext_1 = data[\"abstracts\"][0]\ntext_2 = data[\"abstracts\"][1]\ntext_3 = data[\"abstracts\"][2]\ntext_4 = data[\"abstracts\"][3]\n</code></pre> <pre><code>model.predict(text_1)\n</code></pre> Output <p>['latrine sludge management in Monontsha, Free State Province of South Africa. Key informant interviews and questionnaires']</p> <pre><code>model.predict(text_2)\n</code></pre> Output <p>['sustainable agriculture practices among banana production farmers in Pakistan: Evidence from LR and SEM']</p> <pre><code>model.predict(text_3)\n</code></pre> Output <p>['soil contamination from industrial slag and hazardous levels of metalloid (HMM) contamination in West Atlanta, Georgia. Community-engaged research']</p> <pre><code>model.predict(text_4)\n</code></pre> Output <p>['challenges and opportunities for organic waste utilisation and management through urban agriculture in the Durban South Basin, KwaZulu-Natal Province of South Africa']</p>"},{"location":"projects/big%20data%20for%20iot/","title":"Big-Data For IOT","text":"<p>Membres du groupe</p> <ul> <li>Hermann Agossou</li> <li>Abdellatif BELMADY</li> <li>Fatine BOUSSATTINE</li> <li>Hamza HAJJINI</li> <li>Salma KHMASSI</li> <li>Mohamed Lamine BAMBA</li> <li>Hamza Dribine</li> </ul>"},{"location":"projects/big%20data%20for%20iot/#introduction","title":"Introduction","text":"<p>Ce projet a pour but de pr\u00e9senter les concepts cl\u00e9s du <code>Big Data</code> et de <code>l'IoT</code>, ainsi que leur importance dans le monde actuel. Il a \u00e9galement explor\u00e9 les diff\u00e9rentes approches et outils utilis\u00e9s pour g\u00e9rer ces donn\u00e9es massives, les enjeux et les d\u00e9fis li\u00e9s \u00e0 leur utilisation, les applications de l'IA dans le Big Data et l'IoT, et les perspectives futures de ces technologies.</p>"},{"location":"projects/big%20data%20for%20iot/#definition-du-big-data-et-de-liot","title":"D\u00e9finition du Big Data et de l'IoT","text":"<p>Info</p> <p>Pr\u00e9sentation de ces deux concepts cl\u00e9s et de leur importance dans le monde actuel.</p> <p><code>L'internet des objets (IoT)</code> a gagn\u00e9 en utilisation et en popularit\u00e9 au cours de la derni\u00e8re d\u00e9cennie, indiquant de nouvelles orientations productives et passionnantes pour toute une g\u00e9n\u00e9ration de dispositifs d'information. Les concepts fondamentaux de l'IoT ont \u00e9t\u00e9 invent\u00e9s par Kevin Ashton en 1999, lorsqu'il a introduit la communication entre appareils \u00e0 une \u00e9chelle plus large que celle qui \u00e9tait possible auparavant. Atzori et al. ont depuis d\u00e9clar\u00e9 que \"l'IoT est le r\u00e9sultat de la convergence de trois visions : orient\u00e9e vers les objets, orient\u00e9e vers l'internet et orient\u00e9e vers la s\u00e9mantique\". En termes de s\u00e9mantique sp\u00e9cifiquement, l'IoT est un \"r\u00e9seau mondial d'objets interconnect\u00e9s\". L'IoT peut \u00eatre d\u00e9fini comme \"une infrastructure de r\u00e9seau mondial dynamique, en tant que telle, elle peut identifier, contr\u00f4ler et surveiller chaque objet sur terre via l'internet selon un protocole d'accord sp\u00e9cifique, et par l'interconnexion de choses physiques et virtuelles bas\u00e9e sur l'interop\u00e9rabilit\u00e9 des technologies de l'information et de la communication\". L'objectif principal de l'IoT est d'aider \u00e0 partager des informations en temps r\u00e9el par le biais d'acteurs autonomes en r\u00e9seau. La figure 1 explique le concept de l'IoT. Un capteur dot\u00e9 de capacit\u00e9s de calcul intelligentes est plac\u00e9 \u00e0 un endroit o\u00f9 se trouve une connexion Internet. Ce capteur sera capable de communiquer avec n'importe quoi, \u00e0 tout moment et de n'importe quel endroit du r\u00e9seau. Les syst\u00e8mes de collecte de donn\u00e9es localisent et transf\u00e8rent les donn\u00e9es par le biais d'un grand nombre de ces dispositifs de communication au sein de l'infrastructure IoT, ce qui facilite le processus de collecte des donn\u00e9es. Plusieurs solutions de communication, telles que WIFI, ZigBee, Bluetooth et GSM, permettent l'interconnexion de dispositifs utilisant divers r\u00e9seaux d'acc\u00e8s, notamment l'identification par radiofr\u00e9quence (RFID), les dispositifs dot\u00e9s de capteurs sans fil et tout objet intelligent connect\u00e9 \u00e0 l'internet par IP physique.</p> <p>De nos jours, d'\u00e9normes volumes de donn\u00e9es sont g\u00e9n\u00e9r\u00e9s par l'IoT. Ces donn\u00e9es, souvent appel\u00e9es <code>big data</code>, font r\u00e9f\u00e9rence \u00e0 une grande \u00e9chelle de donn\u00e9es qui exige de nouvelles architectures et technologies pour la gestion des donn\u00e9es (capture et traitement) afin de permettre l'extraction de valeur pour une meilleure compr\u00e9hension et prise de d\u00e9cision. Le big data se caract\u00e9rise par diverses propri\u00e9t\u00e9s de haut volume, de haute v\u00e9locit\u00e9, de haute vari\u00e9t\u00e9 et de haute v\u00e9racit\u00e9. D'ici 2020, l'IoT devrait connecter 50 milliards de dispositifs ou plus, en raison de l'afflux consid\u00e9rable de nouveaux objets intelligents et de l'augmentation exponentielle de la demande de leurs services.</p> <p> <p></p> <p>Fig. 1. Internet of things concept.</p> <p></p> <p>R\u00e9cemment, <code>l'IoT</code> a \u00e9t\u00e9 appliqu\u00e9 dans les environnements intelligents, qui permettent aux utilisateurs de mieux comprendre et contr\u00f4ler leur environnement gr\u00e2ce \u00e0 une gamme de dispositifs interconnect\u00e9s. Dans les applications d'environnement intelligent, l'IoT est employ\u00e9 pour construire un r\u00e9seau de surveillance \u00e9cologique complet, \u00e0 plusieurs niveaux et enti\u00e8rement couvert, qui peut \u00eatre r\u00e9alis\u00e9 en utilisant l'int\u00e9gration de capteurs \u00e0 tous les niveaux en tirant parti de l'IoT avec des informations spatiales et temporelles, et en construisant une plate-forme massive avec un centre de donn\u00e9es et un support de service unifi\u00e9. La technologie IoT et son int\u00e9gration avec le big data ont \u00e9t\u00e9 largement appliqu\u00e9es dans divers domaines tels que les villes intelligentes, les soins de sant\u00e9 intelligents, les syst\u00e8mes d'alerte intelligents et la gestion des catastrophes. Par cons\u00e9quent, la construction et l'application de l'IoT et du big data dans les domaines environnementaux sont devenues une mesure cruciale, notamment pour le d\u00e9veloppement, la promotion et la gestion d'un nouvel environnement strat\u00e9gique dans l'industrie.</p>"},{"location":"projects/big%20data%20for%20iot/#exemples-concrets-dutilisation-du-big-data-et-de-liot","title":"Exemples concrets d'utilisation du Big Data et de l'IoT","text":""},{"location":"projects/big%20data%20for%20iot/#les-voitures-intelligentes","title":"Les voitures intelligentes","text":"<p>Les voitures intelligentes utilisent l\u2019IoT pour \u00e9changer des informations li\u00e9es au fonctionnement et l\u2019environnement de la voitures, tel que l\u2019emplacement, la vitesse, la dynamique\u2026. Grace \u00e0 l\u2019IoT, on peut d\u00e9terminer l\u2019itin\u00e9raire le plus optimale, aussi, on peut localiser une place libre dans un parking. De plus, Il peut aider dans la r\u00e9paration et l\u2019entretien des v\u00e9hicules, en fait, il informe l\u2019utilisateur de la date de maintenance pr\u00e9vue, et il aide dans la r\u00e9paration avec une direction ad\u00e9quate. Ainsi, il permet aux voitures de faire des taches lourdes comme \u00e9viter les collisions et arr\u00eater le trafic inutile.</p> <p>Ces voitures intelligentes sont \u00e9quip\u00e9es de cam\u00e9ras et de capteurs qui peuvent collecter des donn\u00e9es sur l'environnement de la voiture. Cela peut inclure des \u00e9l\u00e9ments tels que les sch\u00e9mas de circulation, les conditions m\u00e9t\u00e9orologiques et m\u00eame l'emplacement et la vitesse des autres v\u00e9hicules dans la r\u00e9gion. Ce qui conduit \u00e0 la collecte d\u2019un volume important de donn\u00e9es. </p>"},{"location":"projects/big%20data%20for%20iot/#les-villes-intelligentes","title":"Les villes intelligentes","text":"<p>Les villes intelligentes utilisent l\u2019IoT sur plusieurs aspects tel que : les transports automatiques, les syst\u00e8mes intelligents de gestion de l\u2019\u00e9nergie et de distribution de l\u2019eau, la s\u00e9curit\u00e9 urbaine et la surveillance de l\u2019environnement. Ces villes utilisent l\u2019IoT et le Big Data pour collecter et analyser des donn\u00e9es provenant de diverses sources, telles que des capteurs et des cam\u00e9ras installer partout dans la ville, afin de r\u00e9soudre les probl\u00e8mes rencontr\u00e9s par les citoyens, nous citons comme exemples :  </p> <p>\u2022   Les syst\u00e8mes intelligents de gestion du trafic qui utilisent les donn\u00e9es des capteurs de trafic pour optimiser la circulation et r\u00e9duire les embouteillages.</p> <p>\u2022   Les syst\u00e8mes d'\u00e9clairage intelligents qui utilisent des donn\u00e9es provenant de capteurs pour ajuster la luminosit\u00e9 et la synchronisation des lampadaires.</p> <p>\u2022   Les syst\u00e8mes intelligents de gestion des d\u00e9chets qui utilisent les donn\u00e9es de capteurs de niveau de d\u00e9chets pour optimiser les itin\u00e9raires de collecte des ordures.</p> <p>\u2022   Les syst\u00e8mes de stationnement intelligents qui utilisent les donn\u00e9es fournies par des capteurs pour guider les conducteurs vers les places de stationnement disponibles et r\u00e9duire les embouteillages.</p> <p>\u2022   Les syst\u00e8mes de surveillance de la qualit\u00e9 de l'air et de l'eau qui utilisent des capteurs IoT pour d\u00e9tecter et alerter les responsables de la ville des dangers potentiels. </p> <p>Certains rapports estiment que les villes intelligentes peuvent g\u00e9n\u00e9rer jusqu'\u00e0 t\u00e9rabytes de donn\u00e9es par jour, ce volume de donn\u00e9es est en constante augmentation en raison de la croissance de l'Internet des objets (IoT) et de la 5G.</p>"},{"location":"projects/big%20data%20for%20iot/#la-domotique","title":"La domotique","text":"<p>Les syst\u00e8mes domotiques ou les maisons intelligentes contient des appareilles qui fonctionnent \u00e0 base de l\u2019IoT, comme les climatiseurs, les lumi\u00e8res et les ventilateurs. Cela donne la possibilit\u00e9 \u00e0 l\u2019utilisateur de contr\u00f4ler sa maison \u00e0 une distance \u00e9tendue, en fait, il peut contr\u00f4ler la temp\u00e9rature, l\u2019\u00e9clairage, la gestion de l\u2019\u00e9nergie, l\u2019expansion, le syst\u00e8me de s\u00e9curit\u00e9, et l\u2019acc\u00e8s \u00e0 distance.</p> <p>La domotique utilise des capteurs, des actionneurs, des r\u00e9seaux de communication et des syst\u00e8mes de contr\u00f4le pour automatiser les t\u00e2ches m\u00e9nag\u00e8res et am\u00e9liorer le confort et la s\u00e9curit\u00e9 des r\u00e9sidents. La domotique utilise les technologies du Big Data, et des algorithmes d\u2019analyse des donn\u00e9es pour pr\u00e9voir les besoins futurs et anticiper les probl\u00e8mes. Par exemple, en utilisant des donn\u00e9es sur les tendances de consommation d'\u00e9nergie, les syst\u00e8mes de domotique peuvent ajuster automatiquement les param\u00e8tres de chauffage et de climatisation pour r\u00e9duire la consommation d'\u00e9nergie.</p> <p>En conclusion, la domotique et le BIG Data sont \u00e9troitement li\u00e9s car ces derniers permettent de collecter, stocker et utiliser des donn\u00e9es pour am\u00e9liorer les performances des syst\u00e8mes de domotique en termes de confort, s\u00e9curit\u00e9 et \u00e9conomie d'\u00e9nergie.</p>"},{"location":"projects/big%20data%20for%20iot/#les-appareils-portables","title":"Les appareils portables","text":"<p>De nos jours, l\u2019IoT a \u00e9t\u00e9 int\u00e9gr\u00e9 dans la plupart des appareils portable, ces derni\u00e8res contient des cam\u00e9ras, des capteurs de son, les r\u00e9seaux et la connexion \u00e0 internet, qui utilisent pour collecter certaines informations sur l\u2019utilisateurs, notamment : </p> <p>\u2022   <code>Les donn\u00e9es de localisation</code> : les smartphones utilisent des technologies comme GPS, Wi-Fi et les r\u00e9seaux cellulaires pour d\u00e9terminer la position de l'utilisateur.</p> <p>\u2022   <code>Les donn\u00e9es de navigation</code> : les smartphones enregistrent les sites web et les applications que l'utilisateur a visit\u00e9s.</p> <p>\u2022   <code>Les donn\u00e9es de contacts</code> : les smartphones stockent les informations de contact de l'utilisateur, comme les num\u00e9ros de t\u00e9l\u00e9phone et les adresses e-mail.</p> <p>\u2022   <code>Les donn\u00e9es de messages</code> : les smartphones peuvent stocker les messages texte et les conversations de messagerie instantan\u00e9e de l'utilisateur.</p> <p>\u2022   <code>Les donn\u00e9es de m\u00e9dias</code> : les smartphones peuvent stocker les photos, les vid\u00e9os et les fichiers audio pris ou enregistr\u00e9s par l'utilisateur.</p> <p>Les rapports informent que aujourd\u2019hui les serveurs de Facebook doivent analyser tous les demi-heure l\u2019\u00e9quivalent de 105 To de donn\u00e9es (Botton \u2018\u2019j\u2019aime\u2019\u2019, photos, requ\u00eate \u2026 ).</p>"},{"location":"projects/big%20data%20for%20iot/#approches-et-outils-pour-gerer-le-big-data-et-liot","title":"Approches et outils pour g\u00e9rer le Big Data et l'IoT","text":"<p>Info</p> <p>Pr\u00e9sentation des diff\u00e9rents approches et outils utilis\u00e9s pour g\u00e9rer et analyser le Big Data et l'IoT, tels que les plateformes de gestion de donn\u00e9es, les outils d'analyse de donn\u00e9es en temps r\u00e9el, etc.</p> <p>Le Big Data et l'IoT (Internet des objets) sont deux domaines qui ont connu une croissance explosive ces derni\u00e8res ann\u00e9es et qui continuent de se d\u00e9velopper rapidement. Le Big Data fait r\u00e9f\u00e9rence \u00e0 l'ensemble des donn\u00e9es g\u00e9n\u00e9r\u00e9es par les entreprises, les organisations et les individus, tandis que l'IoT d\u00e9signe l'ensemble des objets connect\u00e9s \u00e0 Internet qui sont capables de collecter et de transmettre des donn\u00e9es. La gestion de ces deux domaines peut \u00eatre complexe, mais il existe plusieurs approches et outils qui peuvent aider les entreprises \u00e0 y parvenir.</p> <p>Une approche courante pour g\u00e9rer le Big Data consiste \u00e0 utiliser des technologies de gestion de donn\u00e9es distribu\u00e9es, telles que Hadoop ou Spark. Ces technologies permettent de traiter de grandes quantit\u00e9s de donn\u00e9es de mani\u00e8re efficace et \u00e0 bas co\u00fbt en r\u00e9partissant le travail sur plusieurs n\u0153uds de calcul.</p> <p>Il est \u00e9galement possible de g\u00e9rer le Big Data en utilisant des bases de donn\u00e9es en m\u00e9moire, comme Redis ou Memcached, qui permettent de traiter les donn\u00e9es de mani\u00e8re plus rapide que les bases de donn\u00e9es traditionnelles. Cependant, ces bases de donn\u00e9es sont g\u00e9n\u00e9ralement moins adapt\u00e9es aux grands volumes de donn\u00e9es et ne conviennent pas toujours \u00e0 tous les types de donn\u00e9es.</p> <p>Pour g\u00e9rer l'IoT, il est courant d'utiliser des plateformes de gestion de l'IoT, telles que AWS IoT ou Azure IoT, qui permettent de collecter, de stocker et de traiter les donn\u00e9es provenant d'objets connect\u00e9s. Ces plateformes offrent \u00e9galement des outils pour la gestion de l'IoT, tels que la gestion des appareils, la s\u00e9curit\u00e9 et la conformit\u00e9.</p> <p>On note \u00e9galement l'utilisation de capteurs (par exemple, capteurs de temp\u00e9rature, de mouvement, de pression) ainsi que des protocoles de communication sans fil (par exemple, Bluetooth, Wi-Fi, LTE).Ces appareils permettent de collecter des donn\u00e9es environnementales ou de contr\u00f4ler des objets physiques \u00e0 distance. Pour cela, ils utilisent des protocoles qui permettent \u00e0 diff\u00e9rents appareils de communiquer entre eux et de se connecter \u00e0 Internet. Ils sont souvent utilis\u00e9s pour la communication entre appareils IoT.</p> <p>En conclusion, il existe de nombreux approches et outils pour g\u00e9rer le Big Data et l'IoT. Le choix de la solution d\u00e9pend de l'environnement de l'entreprise et de ses besoins en mati\u00e8re de traitement de donn\u00e9es. Il est important de prendre le temps de bien comprendre les options disponibles et de choisir la solution qui convient le mieux \u00e0 l'entreprise afin de maximiser l'efficacit\u00e9 et l'efficience de la gestion des donn\u00e9es.</p>"},{"location":"projects/big%20data%20for%20iot/#enjeux-et-defis-lies-au-big-data-et-a-liot","title":"Enjeux et d\u00e9fis li\u00e9s au Big Data et \u00e0 l'IoT","text":"<p>Info</p> <p>Le recours au big data s'av\u00e8re ainsi substantiel pour l'exploitation et le traitement des vastes quantit\u00e9s de donn\u00e9es collect\u00e9es par les dispositifs connect\u00e9s (iot), dont les enjeux sont list\u00e9s ci-dessous :</p>"},{"location":"projects/big%20data%20for%20iot/#1-confidentialite-et-securite","title":"1. Confidentialit\u00e9 et s\u00e9curit\u00e9","text":"<p>Les donn\u00e9es collect\u00e9es par les objets connect\u00e9s peuvent \u00eatre utilis\u00e9es pour suivre les activit\u00e9s des personnes, \u00e0 savoir des comptes utilisateurs, de consommateurs. Pourtant, elles peuvent \u00eatre utilis\u00e9es \u00e0 des fins malveillantes ou sans le consentement des personnes concern\u00e9es. De plus, lesdits objets  peuvent \u00eatre la cible de diff\u00e9rentes formes d'attaques, comme les attaques de d\u00e9ni de service, les attaques de fuites de donn\u00e9es ou les attaques de piratage, et par cons\u00e9quent, la gestion de la s\u00e9curit\u00e9 des donn\u00e9es massives et confidentielles demeure un d\u00e9fi en raison de la quantit\u00e9 de donn\u00e9es \u00e0 prot\u00e9ger et des risques potentiels pouvant affecter les donn\u00e9es.</p>"},{"location":"projects/big%20data%20for%20iot/#2-varietes-de-donnees","title":"2. Vari\u00e9t\u00e9s de donn\u00e9es","text":"<p>Les donn\u00e9es massives collect\u00e9es via les appareils connect\u00e9s peuvent \u00eatre de diff\u00e9rents types (structur\u00e9es, non structur\u00e9es, semi-structur\u00e9es) et provenir de diff\u00e9rentes sources. Par exemple, la plupart des donn\u00e9es collect\u00e9es peuvent \u00eatre sous format d'images, de fichiers audio, de documents, de fichiers texte, etc. qui ne sont pas structur\u00e9es et ne se trouvent pas dans des bases de donn\u00e9es. Il sera donc difficile d'extraire et d'analyser par la suite toutes ces donn\u00e9es non structur\u00e9es.</p>"},{"location":"projects/big%20data%20for%20iot/#3-la-vitesse-de-gestion-des-megadonnees","title":"3. La vitesse de gestion des m\u00e9gadonn\u00e9es","text":"<p>Ceci est consid\u00e9r\u00e9 comme un enjeu crucial vu que les donn\u00e9es massives collect\u00e9es sur Internet peuvent \u00eatre g\u00e9n\u00e9r\u00e9es et mises \u00e0 jour tr\u00e8s rapidement. Cela peut rendre difficile le traitement en temps r\u00e9el des donn\u00e9es et l'obtention de r\u00e9sultats rapides. Par exemple, si les donn\u00e9es sont utilis\u00e9es pour prendre des d\u00e9cisions commerciales importantes, il est crucial d'avoir acc\u00e8s \u00e0 des donn\u00e9es \u00e0 jour et de pouvoir traiter rapidement ces donn\u00e9es pour obtenir des r\u00e9sultats en temps opportun.</p>"},{"location":"projects/big%20data%20for%20iot/#4-stockage-et-infrastructure-des-donnees","title":"4. Stockage et infrastructure des donn\u00e9es","text":"<p>Le stockage et l'infrastructure des donn\u00e9es sont des enjeux importants pour l'usage du big data au service de l'IoT car celui-ci implique la collecte et le traitement de grandes quantit\u00e9s de donn\u00e9es en temps r\u00e9el, qui peuvent provenir de diff\u00e9rents types de capteurs et de dispositifs connect\u00e9s. Ces donn\u00e9es peuvent \u00eatre utilis\u00e9es pour diverses fins, telles que l'optimisation de la production, l'am\u00e9lioration de la maintenance pr\u00e9ventive ou l'analyse de la performance des syst\u00e8mes. Par cons\u00e9quent, la gestion efficace de ces donn\u00e9es repose sur une infrastructure de stockage et de traitement de donn\u00e9es ad\u00e9quates ( bases de donn\u00e9es distribu\u00e9es, syst\u00e8mes de fichiers distribu\u00e9s, \u2026).</p>"},{"location":"projects/big%20data%20for%20iot/#applications-de-lia-dans-le-big-data-et-liot","title":"Applications de l'IA dans le Big Data et l'IoT","text":"<p>Info</p> <p>Pr\u00e9sentation des diff\u00e9rentes applications de l'intelligence artificielle dans le Big Data et l'IoT, ainsi que leur impact sur l'analyse et la prise de d\u00e9cision.</p> <p>L'intelligence artificielle (IA) est de plus en plus utilis\u00e9e pour traiter les donn\u00e9es massives g\u00e9n\u00e9r\u00e9es par les objets connect\u00e9s dans l'Internet des objets (IoT). La combinaison de l'IA et du Big Data permet d'optimiser les processus d'analyse et de pr\u00e9diction, offrant ainsi de nouvelles possibilit\u00e9s pour les entreprises et les organisations.</p> <p>Une des principales applications de l'IA dans le Big Data et l'IoT est l'analyse pr\u00e9dictive. Les mod\u00e8les de pr\u00e9diction bas\u00e9s sur l'IA peuvent \u00eatre utilis\u00e9s pour pr\u00e9voir la maintenance des \u00e9quipements, la consommation d'\u00e9nergie ou encore les tendances de vente. Cela permet aux entreprises de planifier efficacement leur maintenance et de maximiser leur rendement. En outre, cela permet d'anticiper les besoins en consommation d'\u00e9nergie et de planifier la production d'\u00e9nergie en cons\u00e9quence. Les tendances de vente peuvent \u00e9galement \u00eatre pr\u00e9vues pour adapter les strat\u00e9gies de marketing et de production.</p> <p>La maintenance pr\u00e9ventive est une autre application importante de l'IA dans le Big Data et l'IoT. Les capteurs int\u00e9gr\u00e9s dans les \u00e9quipements industriels peuvent collecter des donn\u00e9es en temps r\u00e9el sur leur performance. L'IA peut ensuite \u00eatre utilis\u00e9e pour d\u00e9tecter les anomalies et les signes de d\u00e9t\u00e9rioration, permettant ainsi une maintenance pr\u00e9ventive pour \u00e9viter les pannes. Cela permet aux entreprises de r\u00e9duire les co\u00fbts li\u00e9s aux pannes inattendues et de maximiser la disponibilit\u00e9 de leurs \u00e9quipements. Cela contribue \u00e9galement \u00e0 la s\u00e9curit\u00e9 des employ\u00e9s en r\u00e9duisant les risques d'accidents li\u00e9s \u00e0 des \u00e9quipements d\u00e9fectueux.</p> <p>L'IA peut \u00e9galement \u00eatre utilis\u00e9e pour optimiser les r\u00e9seaux de transport et de distribution d'\u00e9nergie. Les donn\u00e9es recueillies par les objets connect\u00e9s peuvent \u00eatre utilis\u00e9es pour planifier les itin\u00e9raires de transport les plus efficaces, ou encore pour r\u00e9guler la production d'\u00e9nergie \u00e9olienne et solaire. Cela permet d'optimiser les itin\u00e9raires de transport, de r\u00e9duire les co\u00fbts de transport et d'am\u00e9liorer la qualit\u00e9 des services de transport. L'IA peut \u00e9galement \u00eatre utilis\u00e9e pour r\u00e9guler la production d'\u00e9nergie renouvelable en fonction des besoins en \u00e9nergie pour maximiser l'utilisation des ressources.</p> <p>Enfin, l'IA peut \u00eatre utilis\u00e9e pour am\u00e9liorer la qualit\u00e9 de vie des individus. Les objets connect\u00e9s peuvent collecter des donn\u00e9es sur les habitudes de vie des individus, permettant ainsi une meilleure compr\u00e9hension de leurs besoins. L'IA peut \u00eatre utilis\u00e9e pour d\u00e9velopper des solutions personnalis\u00e9es en mati\u00e8re de sant\u00e9, de logement ou encore de consommation d'\u00e9nergie. Cela permet de cr\u00e9er des environnements de vie plus confortables et plus sains pour les individus.</p>"},{"location":"projects/big%20data%20for%20iot/#perspectives-futures-du-big-data-et-de-liot","title":"Perspectives futures du Big Data et de l'IoT","text":"<p>Info</p> <p>Pr\u00e9sentation des tendances et perspectives futures du Big Data et de l'IoT, ainsi que leur impact sur les entreprises et la soci\u00e9t\u00e9 en g\u00e9n\u00e9ral.</p> <p>L\u2019internet des objets est l\u2019une des innovations qui fa\u00e7onneront fortement notre avenir. Grace \u00e0 son fort progr\u00e8s au cours du temps, il serait possible de connecter la majorit\u00e9 des appareils qui nous entourent et ainsi exploiter le Big Data partag\u00e9 dans tous les aspects de notre vie. Voici les principales fa\u00e7ons dont l\u2019IOT et le Big Data impacteront les entreprises en particulier et la soci\u00e9t\u00e9 en g\u00e9n\u00e9ral :</p>"},{"location":"projects/big%20data%20for%20iot/#marketing-personnalise","title":"Marketing personnalis\u00e9","text":"<p>Gr\u00e2ce aux donn\u00e9es g\u00e9n\u00e9r\u00e9es par les appareils interconnect\u00e9s, il serait possible de cibler le bon public et de lui transmettre le bon message au moment le plus id\u00e9al. Ainsi, les gens recevront toute sorte de publicit\u00e9 ou promotion qui correspond parfaitement \u00e0 leurs comportements d\u2019achat et \u00e0 leurs int\u00e9r\u00eats, ce qui rend les chances de se rapprocher d\u2019un client plus probables, certaines et m\u00eame inimaginables.  D\u2019ailleurs, les entreprises d\u2019aujourd\u2019hui essaient de tirer profit au maximum de l\u2019ensemble des technologies \u00e9mergentes afin d\u2019augmenter les r\u00e9sultats et d\u00e9velopper des campagnes marketing tr\u00e8s efficace capables de bien g\u00e9rer le budget qui leur est d\u00e9di\u00e9.</p>"},{"location":"projects/big%20data%20for%20iot/#villes-intelligentes","title":"Villes intelligentes","text":"<p>L\u2019IOT et le Big Data participeront fortement \u00e0 la modernisation de nos villes via l\u2019adoption de certaines appareils interconnect\u00e9s capables de collecter un maximum de donn\u00e9es en temps r\u00e9el et l\u2019application majeure de l\u2019intelligence artificielle dans le but de rendre les technologies existantes plus intelligentes et ad\u00e9quates. Ainsi, la ville de demain sera \u00e9quip\u00e9e par des contr\u00f4leurs du trafic servant \u00e0 la pr\u00e9diction du danger sur la route, des routes solaires contenant des panneaux photovolta\u00efques pour avertir les conducteurs en cas d\u2019obstacle ou animal, des arr\u00eats de bus intelligents qui activent et d\u00e9sactivent le chauffage et la climatisation de fa\u00e7on automatique\u2026</p>"},{"location":"projects/big%20data%20for%20iot/#prise-de-decision-amelioree","title":"Prise de d\u00e9cision am\u00e9lior\u00e9e","text":"<p>L\u2019acc\u00e8s en temps r\u00e9el \u00e0 un maximum d\u2019informations tangibles permettra aux entreprises et aux d\u00e9tenteurs de magasin de prendre la bonne d\u00e9cision, d\u2019anticiper les risques les plus mena\u00e7ants et d\u2019\u00e9conomiser les d\u00e9penses. Ils sauront interpr\u00e9ter et surveiller l\u2019ensemble des donn\u00e9es r\u00e9colt\u00e9es par les capteurs IOT pour d\u00e9duire le bon volume \u00e0 produire, les types de produits les plus vendus, la saisonnalit\u00e9 des ventes\u2026, ce qui conduira \u00e0 une efficacit\u00e9 accrue, \u00e0 des couts op\u00e9rationnels r\u00e9duits et \u00e0 un retour sur investissement plus \u00e9lev\u00e9.</p>"},{"location":"projects/big%20data%20for%20iot/#chaine-dapprovisionnement-optimisee","title":"Chaine d\u2019approvisionnement optimis\u00e9e","text":"<p>La mise en \u0153uvre de l\u2019IOT et du Big Data permettra de bien contr\u00f4ler le flux du produit : de l\u2019approvisionnement en mati\u00e8res premi\u00e8res jusqu\u2019\u00e0 la distribution du produit final. En connectant les processus et les personnes, il serait possible de mesurer les informations collect\u00e9es, de les \u00e9changer et de les analyser par des tableaux de bord afin de prendre des d\u00e9cisions proactives bas\u00e9es sur les donn\u00e9es et superviser la chaine d\u2019approvisionnement dans sa totalit\u00e9.</p>"},{"location":"projects/big%20data%20for%20iot/#organisations-et-systemes-de-sante-developpes","title":"Organisations et syst\u00e8mes de sant\u00e9 d\u00e9velopp\u00e9s","text":"<p>Les soins pour les patients peuvent \u00eatre, gr\u00e2ce \u00e0 la m\u00e9decine de pr\u00e9cision favoris\u00e9e par l\u2019IOT et le Big Data, consid\u00e9rablement am\u00e9lior\u00e9s comme leurs qualit\u00e9s de vie. Il serait possible de collecter un maximum de donn\u00e9es sur leurs programmes de m\u00e9dicament via des capteurs ou montres intelligents sans n\u00e9cessit\u00e9 de recourir constamment aux analyses et aux m\u00e9decins. De plus, il serait possible de localiser avec un simple clic les h\u00f4pitaux et les ambulances qui sont les plus proches, de pr\u00e9dire avec pr\u00e9cision les maladies et de d\u00e9velopper de nouveaux m\u00e9dicaments en se basant sur l\u2019analyse des donn\u00e9es cliniques.</p>"},{"location":"projects/big%20data%20for%20iot/#agriculture-connectee","title":"Agriculture connect\u00e9e","text":"<p>Le Big Data collect\u00e9 via les tracteurs, animaux, drones et machines de r\u00e9colte connect\u00e9s permettra aux agriculteurs dans le futur proche d\u2019am\u00e9liorer le rendement de leurs terres et fermes. Ils seront capables d\u2019acc\u00e9der en temps r\u00e9el aux informations qui lui sont assez importantes, d\u2019anticiper les maladies des cultures pour faire les pr\u00e9cautions n\u00e9cessaires et d\u2019optimiser l\u2019irrigation et l\u2019emploi des fertilisants. D\u2019o\u00f9 une agriculture future \u00e9cologique, \u00e9conome et de haute pr\u00e9cision.</p>"},{"location":"projects/big%20data%20for%20iot/#gestion-de-transport-amelioree","title":"Gestion de transport am\u00e9lior\u00e9e","text":"<p>L\u2019IOT et le Big Data jouent un r\u00f4le important pour les diff\u00e9rents types de syst\u00e8mes de transport : maritime, a\u00e9rien, ferroviaire et routier. Ils permettront de garantir un transport de services et biens s\u00e9curis\u00e9, de coordonner efficacement l\u2019exp\u00e9dition et d\u2019assurer en permanence la connectivit\u00e9 r\u00e9seau sur les routes. De plus, ils serviront \u00e0 anticiper la maintenance et l\u2019entretien des \u00e9quipements, \u00e0 contr\u00f4ler toute pollution d\u00e9gag\u00e9e des moyens de transport et \u00e0 r\u00e9duire le recrutement des chauffeurs \u00e0 cause des v\u00e9hicules autonomes. Ainsi, la gestion du transport de demain serait plus simple, efficace et s\u00e9curis\u00e9e.</p>"},{"location":"projects/big%20data%20for%20iot/#consommation-energetique-optimisee","title":"Consommation \u00e9nerg\u00e9tique optimis\u00e9e","text":"<p>Gr\u00e2ce \u00e0 la collecte instantan\u00e9e en temps r\u00e9el des donn\u00e9es li\u00e9es \u00e0 la consommation et aux pertes \u00e9nerg\u00e9tiques, il serait possible d\u2019identifier l\u2019ensemble des comportements \u00e0 optimiser et \u00e9viter le gaspillage des ressources. De plus, les consommateurs particuliers ou entreprises disposeront d\u2019algorithmes leur permettant de pr\u00e9dire leur consommation \u00e9nerg\u00e9tique d\u00e9pendamment d\u2019appareils ou machines utilis\u00e9es, de r\u00e9duire leurs d\u00e9penses et d\u2019am\u00e9liorer le confort logement. Ainsi, les comportements \u00e9nerg\u00e9tiques futurs seraient plus sobres et r\u00e9pondent \u00e0 la neutralit\u00e9 carbone et aux enjeux \u00e9nerg\u00e9tiques les plus complexes. </p>"},{"location":"projects/big%20data%20for%20iot/#metiers-nouveaux","title":"M\u00e9tiers nouveaux","text":"<p>Gr\u00e2ce \u00e0 l\u2019\u00e9volution remarquable de l\u2019impl\u00e9mentation de l\u2019IOT et de l\u2019exploitation du Big Data, les m\u00e9tiers d\u2019avenir seront focalis\u00e9s sur tout ce qui est digitalisation et intelligence artificielle. Voici quelques exemples des m\u00e9tiers les plus incontournables dans le futur proche : Data Engineer, ing\u00e9nieur DevOps/Cloud, architecte Big Data, Data Analyst, Data Scientist, Tech Lead Big Data\u2026</p>"},{"location":"projects/big%20data%20for%20iot/#conclusion","title":"Conclusion","text":"<p>Info</p> <p>Synth\u00e8se des principaux points abord\u00e9s dans l'expos\u00e9 et \u00e9ventuelles r\u00e9flexions sur l'avenir du Big Data et de l'IoT.</p> <p>En conclusion, il est clair que le Big Data et l'IoT ont un impact significatif sur les entreprises et la soci\u00e9t\u00e9 en g\u00e9n\u00e9ral. Les avanc\u00e9es technologiques en cours permettront de collecter et de traiter des volumes encore plus importants de donn\u00e9es, offrant ainsi de nouvelles opportunit\u00e9s pour optimiser les processus d'analyse et de pr\u00e9diction. Cependant, il est important de noter que ces technologies posent \u00e9galement des d\u00e9fis en mati\u00e8re de s\u00e9curit\u00e9 et de confidentialit\u00e9 des donn\u00e9es. Il est donc crucial de continuer \u00e0 d\u00e9velopper des approches et des outils pour g\u00e9rer efficacement ces donn\u00e9es massives tout en prot\u00e9geant les int\u00e9r\u00eats des utilisateurs.</p>"},{"location":"projects/boston%20datasets/","title":"Boston Dataset","text":""},{"location":"projects/boston%20datasets/#bibliotheques","title":"Biblioth\u00e8ques","text":"<p>Tout d'abord, ex\u00e9cutons la cellule ci-dessous pour importer tous les paquets dont vous aurez besoin au cours de cette \u00e9tude.</p> <ul> <li> <p>pandas est une biblioth\u00e8que \u00e9crite pour le langage de programmation Python permettant la manipulation et l'analyse des donn\u00e9es.</p> </li> <li> <p>numpy est une biblioth\u00e8que pour langage de programmation Python, destin\u00e9e \u00e0 manipuler des matrices ou tableaux multidimensionnels ainsi que des fonctions math\u00e9matiques op\u00e9rant sur ces tableaux.</p> </li> <li> <p>matplotlib est une biblioth\u00e8que du langage de programmation Python destin\u00e9e \u00e0 tracer et visualiser des donn\u00e9es sous forme de graphiques.</p> </li> <li> <p>seaborn est une biblioth\u00e8que de visualisation Python bas\u00e9e sur matplotlib. Elle fournit une interface de haut niveau pour dessiner des graphiques statistiques attrayants.</p> </li> <li> <p>keras est l'API de haut niveau de TensorFlow.</p> </li> <li> <p>sklearn est une biblioth\u00e8que libre Python destin\u00e9e \u00e0 l'apprentissage automatique. </p> </li> <li>pickle est principalement utilis\u00e9 pour s\u00e9rialiser et d\u00e9s\u00e9rialiser une structure objet Python. En d'autres termes, c'est le processus de conversion d'un objet Python en un flux d'octets pour le stocker dans un fichier/base de donn\u00e9es, maintenir l'\u00e9tat du programme entre les sessions ou transporter des donn\u00e9es sur le r\u00e9seau.</li> </ul> <pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom keras import layers\nimport seaborn as sns\nimport pickle\nfrom sklearn import svm\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n</code></pre>"},{"location":"projects/boston%20datasets/#etude-exploratoire-des-donnees","title":"Etude exploratoire des donn\u00e9es","text":""},{"location":"projects/boston%20datasets/#definition-des-colonnes","title":"D\u00e9finition des colonnes","text":"<p>Dans le domaine de la science des donn\u00e9es, la premi\u00e8re chose \u00e0 faire est de bien comprendre les donn\u00e9es, ainsi et dans ce m\u00eame sens, nous avons d\u00e9fini les colonnes comme suit :</p> <ul> <li> <p><code>CRIM</code>: per capita crime rate by town.</p> </li> <li> <p><code>ZN</code>: proportion of residential land zoned for lots over 25,000 sq.ft.</p> </li> <li> <p><code>INDUS</code>: proportion of non-retail business acres per town.</p> </li> <li> <p><code>CHAS</code>: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).</p> </li> <li> <p><code>NOX</code>: nitric oxides concentration (parts per 10 million).</p> </li> <li> <p><code>RM</code>: average number of rooms per dwelling.</p> </li> <li> <p><code>AGE</code>: proportion of owner-occupied units built prior to 1940.</p> </li> <li> <p><code>DIS</code>: weighted distances to five Boston employment centres.</p> </li> <li> <p><code>RAD</code>: index of accessibility to radial highways.</p> </li> <li> <p><code>TAX</code>: full-value property-tax rate per $10,000.</p> </li> <li> <p><code>PTRATIO</code>: pupil-teacher ratio by town.</p> </li> <li> <p><code>B</code>: 1000(Bk - 0.63)^2 where Bk is the proportion of black people by town.</p> </li> <li> <p><code>LSTAT</code>: % lower status of the population.</p> </li> <li> <p><code>MEDV</code>: our Target, Median value of owner-occupied homes in $1000's</p> </li> </ul>"},{"location":"projects/boston%20datasets/#feature-engineering","title":"Feature engineering","text":"<p><pre><code># Importer le dataset\nfrom sklearn.datasets import load_boston\nboston = load_boston()\n</code></pre> <pre><code># Afficher les \u00e9\u00e9ments cl\u00e9s du dataset\nboston.keys()\n</code></pre></p> Output <p>dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename', 'data_module'])</p> <pre><code>## Afficher la description du dataset\nprint(boston.DESCR)\n</code></pre> Output <p>.. _boston_dataset:</p> <p>Boston house prices dataset</p> <p>Data Set Characteristics: </p> <pre><code>:Number of Instances: 506\n\n:Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n\n:Attribute Information (in order):\n    - CRIM     per capita crime rate by town\n    - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n    - INDUS    proportion of non-retail business acres per town\n    - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n    - NOX      nitric oxides concentration (parts per 10 million)\n    - RM       average number of rooms per dwelling\n    - AGE      proportion of owner-occupied units built prior to 1940\n    - DIS      weighted distances to five Boston employment centres\n    - RAD      index of accessibility to radial highways\n    - TAX      full-value property-tax rate per $10,000\n    - PTRATIO  pupil-teacher ratio by town\n    - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\n    - LSTAT    % lower status of the population\n    - MEDV     Median value of owner-occupied homes in $1000's\n\n:Missing Attribute Values: None\n\n:Creator: Harrison, D. and Rubinfeld, D.L.\n</code></pre> <p>This is a copy of UCI ML housing dataset. https://archive.ics.uci.edu/ml/machine-learning-databases/housing/</p> <p>This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.</p> <p>The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic prices and the demand for clean air', J. Environ. Economics &amp; Management, vol.5, 81-102, 1978.   Used in Belsley, Kuh &amp; Welsch, 'Regression diagnostics ...', Wiley, 1980.   N.B. Various transformations are used in the table on pages 244-261 of the latter.</p> <p>The Boston house-price data has been used in many machine learning papers that address regression problems.   </p> <p>.. topic:: References</p> <ul> <li>Belsley, Kuh &amp; Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.</li> <li>Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.</li> </ul> <pre><code># Afficher le contenu des features \nprint(boston.data)\n</code></pre> Output <p>[[6.3200e-03 1.8000e+01 2.3100e+00 ... 1.5300e+01 3.9690e+02 4.9800e+00]</p> <p>[2.7310e-02 0.e+00 7.0700e+00 ... 1.7800e+01 3.9690e+02 9.1400e+00]</p> <p>[2.7290e-02 0.e+00 7.0700e+00 ... 1.7800e+01 3.9283e+02 4.0300e+00]</p> <p>...</p> <p>[6.0760e-02 0.e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 5.6400e+00]</p> <p>[1.0959e-01 0.e+00 1.1930e+01 ... 2.1000e+01 3.9345e+02 6.4800e+00]</p> <p>[4.7410e-02 0.e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 7.8800e+00]]</p> <pre><code># Afficher le contenu du label\nprint(boston.target)\n</code></pre> Output <p>[24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50. 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20. 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2 9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5. 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7. 8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9 22.  11.9]</p> <pre><code># Afficher les noms des features\nprint(boston.feature_names)\n</code></pre> Output <p>['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO' 'B' 'LSTAT']</p> <p><pre><code># Transformer le boston dataset en Data Frame\ndataset = pd.DataFrame(boston.data,columns=boston.feature_names)\n</code></pre> <pre><code># Afficher les 5 premi\u00e8res lignes du dataset\ndataset.head(5)\n</code></pre></p> Output CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT 0 0.00632 18.0 2.31 0.0 0.538 6.575 65.2 4.0900 1.0 296.0 15.3 396.90 4.98 1 0.02731 0.0 7.07 0.0 0.469 6.421 78.9 4.9671 2.0 242.0 17.8 396.90 9.14 2 0.02729 0.0 7.07 0.0 0.469 7.185 61.1 4.9671 2.0 242.0 17.8 392.83 4.03 3 0.03237 0.0 2.18 0.0 0.458 6.998 45.8 6.0622 3.0 222.0 18.7 394.63 2.94 4 0.06905 0.0 2.18 0.0 0.458 7.147 54.2 6.0622 3.0 222.0 18.7 396.90 5.33 <p><pre><code># Ajouter le label au dataset et lui nommer \"Price\"\ndataset['MEDV'] = boston.target\n</code></pre> <pre><code># Afficher quelques informations de la data\ndataset.info()\n</code></pre></p> Output <p><code>&lt;class 'pandas.core.frame.DataFrame'&gt;</code></p> <p>RangeIndex: 506 entries, 0 to 505</p> <p>Data columns (total 14 columns):</p> # Column Non-Null Count Dtype 0 CRIM 506 non-null float64 1 ZN 506 non-null float64 2 INDUS 506 non-null float64 3 CHAS 506 non-null float64 4 NOX 506 non-null float64 5 RM 506 non-null float64 6 AGE 506 non-null float64 7 DIS 506 non-null float64 8 RAD 506 non-null float64 9 TAX 506 non-null float64 10 PTRATIO 506 non-null float64 11 B 506 non-null float64 12 LSTAT 506 non-null float64 13 MEDV 506 non-null float64 <p>dtypes: float64(14)</p> <p>memory usage: 55.5 KB</p> <ul> <li>Le Dataset contient 506 lignes et 14 colonnes.</li> <li>toutes les colonnes sont de type float64.</li> </ul> <pre><code># Afficher une description statistique de la dataset\ndataset.describe()\n</code></pre> Output CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT MEDV count 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 mean 3.61 11.36 11.13 0.06 0.55 6.28 68.57 3.79 9.54 408.23 18.45 356.67 12.65 22.53 std 8.60 23.32 6.86 0.25 0.11 0.70 28.14 2.10 8.70 168.53 2.16 91.29 7.14 9.19 min 0.006 0.00 0.46 0.00 0.38 3.56 2.90 1.12 1.00 187.00 12.60 0.32 1.73 5.00 25% 0.08 0.00 5.19 0.00 0.44 5.88 45.02 2.10 4.00 279.00 17.40 375.37 6.95 17.02 50% 0.25 0.00 9.69 0.00 0.53 6.20 77.50 3.20 5.00 330.00 19.05 391.44 11.36 21.20 75% 3.67 12.50 18.10 0.00 0.62 6.62 94.07 5.18 24.00 666.00 20.20 396.22 16.95 25.00 max 88.97 100.00 27.74 1.00 0.87 8.78 100.00 12.12 24.00 711.00 22.00 396.90 37.97 50.00 <pre><code># Afficher les valeurs NaN\ndataset.isnull().sum()\n</code></pre> Output Column Number of NaN CRIM 0 ZN 0 INDUS 0 CHAS 0 NOX 0 RM 0 AGE 0 DIS 0 RAD 0 TAX 0 PTRATIO 0 B 0 LSTAT 0 MEDV 0 <p>dtype: int64</p> <p>Note</p> <p>Nous notons que le dataset ne contient pas de valeurs <code>NaN</code>.</p>"},{"location":"projects/boston%20datasets/#vizualisation-des-donnees","title":"Vizualisation des donn\u00e9es","text":""},{"location":"projects/boston%20datasets/#matrice-de-correlation","title":"Matrice de corr\u00e9lation","text":"<p>La matrice de corr\u00e9lation indique les valeurs de corr\u00e9lation, qui mesurent le degr\u00e9 de relation lin\u00e9aire entre chaque paire de variables. Les valeurs de corr\u00e9lation peuvent \u00eatre comprises entre -1 et +1. Si les deux variables ont tendance \u00e0 augmenter et \u00e0 diminuer en m\u00eame temps, la valeur de corr\u00e9lation est positive. Lorsqu'une variable augmente alors que l'autre diminue, la valeur de corr\u00e9lation est n\u00e9gative.</p> <pre><code># Afficher la matrice de corr\u00e9lation\nmatriceCorr = data.corr().round(1)\nsns.heatmap(data=matriceCorr, annot = True)\n</code></pre> Output <p></p> <p>Note</p> <p>Nous notons qu'il y a plusieurs correlations entre les colonnes, mais nous n'allons pas prendre en consid\u00e9ration ces corr\u00e9lations pour l'instant parce que les r\u00e9seaux de neuronnes peuvent d\u00e9tecter les corr\u00e9lations ainsi les traiter. </p>"},{"location":"projects/boston%20datasets/#representations-des-colonnes-deux-a-deux","title":"Repr\u00e9sentations des colonnes deux \u00e0 deux","text":"<pre><code># Afficher les repr\u00e9sentations des colonnes deux \u00e0 deux\nsns.pairplot(dataset)\n</code></pre> Output <pre><code># Afficher \"MEDV\" en fonction de \"CRIM\"\nplt.scatter(dataset['CRIM'],dataset['MEDV'])\nplt.xlabel(\"Crime Rate\")\nplt.ylabel(\"Medv\")\n</code></pre> Output <pre><code># Afficher \"RM\" en fonction de \"MEDV\"\nplt.scatter(dataset['RM'],dataset['MEDV'])\nplt.xlabel(\"RM\")\nplt.ylabel(\"Medv\")\n</code></pre> Output <pre><code># Tracer les donn\u00e9es et l'ajustement d'un mod\u00e8le de r\u00e9gression lin\u00e9aire MEDV=f(RM)\nsns.regplot(x=\"RM\",y=\"MEDV\",data=dataset)\n</code></pre> Output <pre><code># Tracer les donn\u00e9es et l'ajustement d'un mod\u00e8le de r\u00e9gression lin\u00e9aire MEDV=f(LSTAT)\nsns.regplot(x=\"LSTAT\",y=\"MEDV\",data=dataset)\n</code></pre> Output <pre><code># Tracer les donn\u00e9es et l'ajustement d'un mod\u00e8le de r\u00e9gression lin\u00e9aire MEDV=f(CHAS)\nsns.regplot(x=\"CHAS\",y=\"MEDV\",data=dataset)\n</code></pre> Output <pre><code># Tracer les donn\u00e9es et l'ajustement d'un mod\u00e8le de r\u00e9gression lin\u00e9aire MEDV=f(PTRATIO)\nsns.regplot(x=\"PTRATIO\",y=\"MEDV\",data=dataset)\n</code></pre> Output"},{"location":"projects/boston%20datasets/#implementation-des-modeles","title":"Impl\u00e9mentation des mod\u00e8les","text":""},{"location":"projects/boston%20datasets/#preparation-des-des-vecteurs-dentrainement","title":"Pr\u00e9paration des des vecteurs d'entrainement","text":"<p>Maintenant nous allons impl\u00e9menter et entrainer plusieurs mod\u00e8les de machine learning afin de choisir le meilleur, mais avant nous devons d\u00e9finir les features, le target et d\u00e9composer le dataset en data d'entrainement et data du test.  </p> <p><pre><code># D\u00e9finir les features\nX = dataset.drop('MEDV', axis=1)\n\n# D\u00e9finir le target\ny = dataset['MEDV']\n</code></pre> <pre><code># D\u00e9composer la data en 80% pour l'entrainement et 20% pour le test\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n</code></pre> <pre><code># Afficher la taille de X_train, X_test, y_train, y_test\nprint(\"la taille de X_train est :\", X_train.shape)\nprint(\"la taille de X_test est :\", X_test.shape)\nprint(\"la taille de y_train est :\", y_train.shape)\nprint(\"la taille de y_test est :\", y_test.shape)\n</code></pre></p> Output <p>la taille de X_train est : (404, 13)</p> <p>la taille de X_test est : (102, 13)</p> <p>la taille de y_train est : (404,)</p> <p>la taille de y_test est : (102,)</p> <pre><code># Norrmalisation des donn\u00e9es en utilisant le StandardScaler (x-mean)/(std)\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n</code></pre>"},{"location":"projects/boston%20datasets/#reseaux-de-neurones-denses-dnn","title":"R\u00e9seaux de neurones denses DNN","text":"<p><pre><code>num_layer1 = 50\nnum_layer2 = 50\n\nmodel = keras.models.Sequential(name='DNN')\nmodel.add(layers.Input((13,), name=\"Couche_in\"))\nmodel.add(layers.Dense(num_layer1, activation='relu', name='Couche_cachee1'))\nmodel.add(layers.Dense(num_layer2, activation='relu', name='Couche_cachee2'))\nmodel.add(layers.Dense(1, name='Couche_out'))\n</code></pre> <pre><code>model.compile(optimizer='adam',\n              loss='mse',\n              metrics=['mae'])\n</code></pre> <pre><code>model.summary()\n</code></pre></p> Output <p>Model: \"DNN\"</p> Layer (type) Output Shape Param # Couche_cachee1 (Dense) (None, 50) 700 Couche_cachee2 (Dense) (None, 50) 2550 Couche_out (Dense) (None, 1) 51 <p>Total params: 3,301</p> <p>Trainable params: 3,301</p> <p>Non-trainable params: 0</p> <pre><code># Lancer l'entrainement du mod\u00e8le\nhist = model.fit(X_train,\n                 y_train,\n                 epochs=400,\n                 batch_size=50)\n</code></pre> Output <p>Epoch 1/400 9/9 [==============================] - 1s 4ms/step - loss: 557.3136 - mae: 21.6968</p> <p>Epoch 2/400 9/9 [==============================] - 0s 3ms/step - loss: 520.2143 - mae: 20.8262</p> <p>Epoch 3/400 9/9 [==============================] - 0s 3ms/step - loss: 475.9985 - mae: 19.7651</p> <p>Epoch 4/400 9/9 [==============================] - 0s 3ms/step - loss: 423.2747 - mae: 18.4109</p> <p>Epoch 5/400 9/9 [==============================] - 0s 3ms/step - loss: 361.1457 - mae: 16.7136</p> <p>Epoch 6/400 9/9 [==============================] - 0s 3ms/step - loss: 289.6600 - mae: 14.6173</p> <p>Epoch 7/400 9/9 [==============================] - 0s 3ms/step - loss: 219.4651 - mae: 12.2325</p> <p>Epoch 8/400 9/9 [==============================] - 0s 3ms/step - loss: 158.8683 - mae: 10.0692</p> <p>Epoch 9/400 9/9 [==============================] - 0s 3ms/step - loss: 116.7818 - mae: 8.3857</p> <p>Epoch 10/400 9/9 [==============================] - 0s 3ms/step - loss: 91.9504 - mae: 7.3596</p> <p>Epoch 11/400 9/9 [==============================] - 0s 3ms/step - loss: 76.5844 - mae: 6.6405</p> <p>Epoch 12/400 9/9 [==============================] - 0s 8ms/step - loss: 62.4096 - mae: 5.9445</p> <p>Epoch 13/400 9/9 [==============================] - 0s 3ms/step - loss: 49.9997 - mae: 5.3151</p> <p>Epoch 14/400 9/9 [==============================] - 0s 3ms/step - loss: 40.8705 - mae: 4.8252</p> <p>Epoch 15/400 9/9 [==============================] - 0s 3ms/step - loss: 34.1865 - mae: 4.4059</p> <p>Epoch 16/400 9/9 [==============================] - 0s 3ms/step - loss: 29.6209 - mae: 4.0728</p> <p>Epoch 17/400 9/9 [==============================] - 0s 3ms/step - loss: 26.3418 - mae: 3.8037</p> <p>Epoch 18/400 9/9 [==============================] - 0s 3ms/step - loss: 24.0514 - mae: 3.6174</p> <p>Epoch 19/400 9/9 [==============================] - 0s 3ms/step - loss: 22.3640 - mae: 3.4849</p> <p>Epoch 20/400 9/9 [==============================] - 0s 3ms/step - loss: 21.0404 - mae: 3.3751</p> <p>Epoch 21/400 9/9 [==============================] - 0s 3ms/step - loss: 20.0787 - mae: 3.2945</p> <p>Epoch 22/400 9/9 [==============================] - 0s 4ms/step - loss: 19.1893 - mae: 3.2271</p> <p>Epoch 23/400 9/9 [==============================] - 0s 3ms/step - loss: 18.4744 - mae: 3.1858</p> <p>Epoch 24/400 9/9 [==============================] - 0s 3ms/step - loss: 17.9731 - mae: 3.1562</p> <p>Epoch 25/400 9/9 [==============================] - 0s 3ms/step - loss: 17.4404 - mae: 3.0923</p> <p>Epoch 26/400 9/9 [==============================] - 0s 3ms/step - loss: 16.9731 - mae: 3.0298</p> <p>Epoch 27/400 9/9 [==============================] - 0s 3ms/step - loss: 16.6027 - mae: 2.9926</p> <p>Epoch 28/400 9/9 [==============================] - 0s 3ms/step - loss: 16.2943 - mae: 2.9884</p> <p>Epoch 29/400 9/9 [==============================] - 0s 3ms/step - loss: 16.1183 - mae: 2.9904</p> <p>Epoch 30/400 9/9 [==============================] - 0s 3ms/step - loss: 15.8298 - mae: 2.9535</p> <p>Epoch 31/400 9/9 [==============================] - 0s 3ms/step - loss: 15.4369 - mae: 2.8914</p> <p>Epoch 32/400 9/9 [==============================] - 0s 3ms/step - loss: 15.2457 - mae: 2.8531</p> <p>Epoch 33/400 9/9 [==============================] - 0s 3ms/step - loss: 15.0859 - mae: 2.8292</p> <p>Epoch 34/400 9/9 [==============================] - 0s 3ms/step - loss: 14.8123 - mae: 2.8021</p> <p>Epoch 35/400 9/9 [==============================] - 0s 2ms/step - loss: 14.7016 - mae: 2.8349</p> <p>Epoch 36/400 9/9 [==============================] - 0s 3ms/step - loss: 14.7392 - mae: 2.8583</p> <p>Epoch 37/400 9/9 [==============================] - 0s 3ms/step - loss: 14.4040 - mae: 2.7936</p> <p>Epoch 38/400 9/9 [==============================] - 0s 3ms/step - loss: 14.1673 - mae: 2.7549</p> <p>Epoch 39/400 9/9 [==============================] - 0s 3ms/step - loss: 14.0135 - mae: 2.7394</p> <p>Epoch 40/400 9/9 [==============================] - 0s 3ms/step - loss: 13.7766 - mae: 2.7193</p> <p>Epoch 41/400 9/9 [==============================] - 0s 3ms/step - loss: 13.6497 - mae: 2.7049</p> <p>Epoch 42/400 9/9 [==============================] - 0s 3ms/step - loss: 13.8148 - mae: 2.7279</p> <p>Epoch 43/400 9/9 [==============================] - 0s 3ms/step - loss: 13.5806 - mae: 2.7368</p> <p>Epoch 44/400 9/9 [==============================] - 0s 4ms/step - loss: 13.3692 - mae: 2.6903</p> <p>Epoch 45/400 9/9 [==============================] - 0s 3ms/step - loss: 13.1967 - mae: 2.6587</p> <p>Epoch 46/400 9/9 [==============================] - 0s 3ms/step - loss: 13.0199 - mae: 2.6454</p> <p>Epoch 47/400 9/9 [==============================] - 0s 3ms/step - loss: 13.0109 - mae: 2.6521</p> <p>Epoch 48/400 9/9 [==============================] - 0s 3ms/step - loss: 12.9398 - mae: 2.6408</p> <p>Epoch 49/400 9/9 [==============================] - 0s 3ms/step - loss: 12.8580 - mae: 2.6236</p> <p>Epoch 50/400 9/9 [==============================] - 0s 3ms/step - loss: 12.8581 - mae: 2.6218</p> <p>Epoch 51/400 9/9 [==============================] - 0s 3ms/step - loss: 12.7277 - mae: 2.6095</p> <p>Epoch 52/400 9/9 [==============================] - 0s 3ms/step - loss: 12.5262 - mae: 2.5825</p> <p>Epoch 53/400 9/9 [==============================] - 0s 3ms/step - loss: 12.5404 - mae: 2.5921</p> <p>Epoch 54/400 9/9 [==============================] - 0s 3ms/step - loss: 12.3580 - mae: 2.5644</p> <p>Epoch 55/400 9/9 [==============================] - 0s 3ms/step - loss: 12.2630 - mae: 2.5534</p> <p>Epoch 56/400 9/9 [==============================] - 0s 3ms/step - loss: 12.1893 - mae: 2.5394</p> <p>Epoch 57/400 9/9 [==============================] - 0s 4ms/step - loss: 12.0945 - mae: 2.5230</p> <p>Epoch 58/400 9/9 [==============================] - 0s 3ms/step - loss: 12.1561 - mae: 2.5299</p> <p>Epoch 59/400 9/9 [==============================] - 0s 3ms/step - loss: 12.0405 - mae: 2.5175</p> <p>Epoch 60/400 9/9 [==============================] - 0s 3ms/step - loss: 12.0079 - mae: 2.4976</p> <p>Epoch 61/400 9/9 [==============================] - 0s 3ms/step - loss: 11.8621 - mae: 2.4903</p> <p>Epoch 62/400 9/9 [==============================] - 0s 3ms/step - loss: 11.7536 - mae: 2.4790</p> <p>Epoch 63/400 9/9 [==============================] - 0s 3ms/step - loss: 11.8308 - mae: 2.4806</p> <p>Epoch 64/400 9/9 [==============================] - 0s 3ms/step - loss: 11.8091 - mae: 2.4820</p> <p>Epoch 65/400 9/9 [==============================] - 0s 3ms/step - loss: 11.6384 - mae: 2.4957</p> <p>Epoch 66/400 9/9 [==============================] - 0s 3ms/step - loss: 11.8385 - mae: 2.5424</p> <p>Epoch 67/400 9/9 [==============================] - 0s 4ms/step - loss: 11.7600 - mae: 2.5212</p> <p>Epoch 68/400 9/9 [==============================] - 0s 3ms/step - loss: 11.4665 - mae: 2.4539</p> <p>Epoch 69/400 9/9 [==============================] - 0s 3ms/step - loss: 11.4085 - mae: 2.4327</p> <p>Epoch 70/400 9/9 [==============================] - 0s 3ms/step - loss: 11.3790 - mae: 2.4286</p> <p>Epoch 71/400 9/9 [==============================] - 0s 4ms/step - loss: 11.2816 - mae: 2.4209</p> <p>Epoch 72/400 9/9 [==============================] - 0s 4ms/step - loss: 11.2071 - mae: 2.4173</p> <p>Epoch 73/400 9/9 [==============================] - 0s 3ms/step - loss: 11.1422 - mae: 2.4088</p> <p>Epoch 74/400 9/9 [==============================] - 0s 3ms/step - loss: 11.0773 - mae: 2.4023</p> <p>Epoch 75/400 9/9 [==============================] - 0s 3ms/step - loss: 11.0161 - mae: 2.3964</p> <p>Epoch 76/400 9/9 [==============================] - 0s 4ms/step - loss: 11.0054 - mae: 2.3888</p> <p>Epoch 77/400 9/9 [==============================] - 0s 3ms/step - loss: 10.8978 - mae: 2.3807</p> <p>Epoch 78/400 9/9 [==============================] - 0s 3ms/step - loss: 10.8926 - mae: 2.3930</p> <p>Epoch 79/400 9/9 [==============================] - 0s 3ms/step - loss: 10.9182 - mae: 2.3996</p> <p>Epoch 80/400 9/9 [==============================] - 0s 3ms/step - loss: 10.9850 - mae: 2.4115</p> <p>Epoch 81/400 9/9 [==============================] - 0s 3ms/step - loss: 11.0064 - mae: 2.3867</p> <p>Epoch 82/400 9/9 [==============================] - 0s 3ms/step - loss: 11.1898 - mae: 2.3889</p> <p>Epoch 83/400 9/9 [==============================] - 0s 3ms/step - loss: 10.7470 - mae: 2.3746</p> <p>Epoch 84/400 9/9 [==============================] - 0s 3ms/step - loss: 10.8092 - mae: 2.4083</p> <p>Epoch 85/400 9/9 [==============================] - 0s 3ms/step - loss: 10.5877 - mae: 2.3942</p> <p>Epoch 86/400 9/9 [==============================] - 0s 4ms/step - loss: 10.5039 - mae: 2.3632</p> <p>Epoch 87/400 9/9 [==============================] - 0s 3ms/step - loss: 10.5263 - mae: 2.3636</p> <p>Epoch 88/400 9/9 [==============================] - 0s 3ms/step - loss: 10.4007 - mae: 2.3452</p> <p>Epoch 89/400 9/9 [==============================] - 0s 3ms/step - loss: 10.3052 - mae: 2.3390</p> <p>Epoch 90/400 9/9 [==============================] - 0s 3ms/step - loss: 10.2830 - mae: 2.3430</p> <p>Epoch 91/400 9/9 [==============================] - 0s 3ms/step - loss: 10.2626 - mae: 2.3305</p> <p>Epoch 92/400 9/9 [==============================] - 0s 3ms/step - loss: 10.2998 - mae: 2.3301</p> <p>Epoch 93/400 9/9 [==============================] - 0s 3ms/step - loss: 10.3857 - mae: 2.3660</p> <p>Epoch 94/400 9/9 [==============================] - 0s 3ms/step - loss: 10.2242 - mae: 2.3430</p> <p>Epoch 95/400 9/9 [==============================] - 0s 3ms/step - loss: 10.0685 - mae: 2.3185</p> <p>Epoch 96/400 9/9 [==============================] - 0s 3ms/step - loss: 10.0650 - mae: 2.3192</p> <p>Epoch 97/400 9/9 [==============================] - 0s 3ms/step - loss: 10.0117 - mae: 2.3269</p> <p>Epoch 98/400 9/9 [==============================] - 0s 3ms/step - loss: 10.0123 - mae: 2.3178</p> <p>Epoch 99/400 9/9 [==============================] - 0s 3ms/step - loss: 9.9383 - mae: 2.3025</p> <p>Epoch 100/400 9/9 [==============================] - 0s 4ms/step - loss: 9.8653 - mae: 2.2933</p> <p>Epoch 101/400 9/9 [==============================] - 0s 3ms/step - loss: 9.9191 - mae: 2.3033</p> <p>Epoch 102/400 9/9 [==============================] - 0s 3ms/step - loss: 9.8622 - mae: 2.2823</p> <p>Epoch 103/400 9/9 [==============================] - 0s 3ms/step - loss: 9.7497 - mae: 2.2569</p> <p>Epoch 104/400 9/9 [==============================] - 0s 3ms/step - loss: 9.6942 - mae: 2.2639</p> <p>Epoch 105/400 9/9 [==============================] - 0s 4ms/step - loss: 9.6776 - mae: 2.2588</p> <p>Epoch 106/400 9/9 [==============================] - 0s 3ms/step - loss: 9.7455 - mae: 2.2674</p> <p>Epoch 107/400 9/9 [==============================] - 0s 3ms/step - loss: 9.5815 - mae: 2.2458</p> <p>Epoch 108/400 9/9 [==============================] - 0s 3ms/step - loss: 9.5837 - mae: 2.2518</p> <p>Epoch 109/400 9/9 [==============================] - 0s 3ms/step - loss: 9.4691 - mae: 2.2334</p> <p>Epoch 110/400 9/9 [==============================] - 0s 3ms/step - loss: 9.4230 - mae: 2.2271</p> <p>Epoch 111/400 9/9 [==============================] - 0s 3ms/step - loss: 9.4083 - mae: 2.2276</p> <p>Epoch 112/400 9/9 [==============================] - 0s 3ms/step - loss: 9.3655 - mae: 2.2257</p> <p>Epoch 113/400 9/9 [==============================] - 0s 3ms/step - loss: 9.3588 - mae: 2.2105</p> <p>Epoch 114/400 9/9 [==============================] - 0s 3ms/step - loss: 9.6419 - mae: 2.2598</p> <p>Epoch 115/400 9/9 [==============================] - 0s 3ms/step - loss: 9.5963 - mae: 2.2624</p> <p>Epoch 116/400 9/9 [==============================] - 0s 3ms/step - loss: 9.4118 - mae: 2.2251</p> <p>Epoch 117/400 9/9 [==============================] - 0s 3ms/step - loss: 9.2462 - mae: 2.2159</p> <p>Epoch 118/400 9/9 [==============================] - 0s 3ms/step - loss: 9.2559 - mae: 2.2230</p> <p>Epoch 119/400 9/9 [==============================] - 0s 3ms/step - loss: 9.1834 - mae: 2.2073</p> <p>Epoch 120/400 9/9 [==============================] - 0s 3ms/step - loss: 9.1216 - mae: 2.1961</p> <p>Epoch 121/400 9/9 [==============================] - 0s 4ms/step - loss: 9.1227 - mae: 2.1902</p> <p>Epoch 122/400 9/9 [==============================] - 0s 3ms/step - loss: 9.1087 - mae: 2.1876</p> <p>Epoch 123/400 9/9 [==============================] - 0s 4ms/step - loss: 9.1089 - mae: 2.1849</p> <p>Epoch 124/400 9/9 [==============================] - 0s 3ms/step - loss: 9.0926 - mae: 2.1861</p> <p>Epoch 125/400 9/9 [==============================] - 0s 3ms/step - loss: 9.2096 - mae: 2.2124</p> <p>Epoch 126/400 9/9 [==============================] - 0s 4ms/step - loss: 9.0495 - mae: 2.1710</p> <p>Epoch 127/400 9/9 [==============================] - 0s 3ms/step - loss: 8.9340 - mae: 2.1624</p> <p>Epoch 128/400 9/9 [==============================] - 0s 4ms/step - loss: 8.8782 - mae: 2.1619</p> <p>Epoch 129/400 9/9 [==============================] - 0s 3ms/step - loss: 8.8453 - mae: 2.1571</p> <p>Epoch 130/400 9/9 [==============================] - 0s 4ms/step - loss: 8.9253 - mae: 2.1674</p> <p>Epoch 131/400 9/9 [==============================] - 0s 5ms/step - loss: 8.8694 - mae: 2.1647</p> <p>Epoch 132/400 9/9 [==============================] - 0s 4ms/step - loss: 8.7110 - mae: 2.1455</p> <p>Epoch 133/400 9/9 [==============================] - 0s 4ms/step - loss: 8.7117 - mae: 2.1463</p> <p>Epoch 134/400 9/9 [==============================] - 0s 3ms/step - loss: 8.7079 - mae: 2.1490</p> <p>Epoch 135/400 9/9 [==============================] - 0s 4ms/step - loss: 8.6802 - mae: 2.1438</p> <p>Epoch 136/400 9/9 [==============================] - 0s 3ms/step - loss: 8.6549 - mae: 2.1312</p> <p>Epoch 137/400 9/9 [==============================] - 0s 3ms/step - loss: 8.5795 - mae: 2.1202</p> <p>Epoch 138/400 9/9 [==============================] - 0s 3ms/step - loss: 8.5459 - mae: 2.1143</p> <p>Epoch 139/400 9/9 [==============================] - 0s 3ms/step - loss: 8.5602 - mae: 2.1233</p> <p>Epoch 140/400 9/9 [==============================] - 0s 3ms/step - loss: 8.4806 - mae: 2.1126</p> <p>Epoch 141/400 9/9 [==============================] - 0s 3ms/step - loss: 8.4711 - mae: 2.1127</p> <p>Epoch 142/400 9/9 [==============================] - 0s 3ms/step - loss: 8.4310 - mae: 2.1130</p> <p>Epoch 143/400 9/9 [==============================] - 0s 3ms/step - loss: 8.3803 - mae: 2.1100</p> <p>Epoch 144/400 9/9 [==============================] - 0s 3ms/step - loss: 8.4019 - mae: 2.1182</p> <p>Epoch 145/400 9/9 [==============================] - 0s 3ms/step - loss: 8.5072 - mae: 2.1415</p> <p>Epoch 146/400 9/9 [==============================] - 0s 3ms/step - loss: 8.4077 - mae: 2.1234</p> <p>Epoch 147/400 9/9 [==============================] - 0s 3ms/step - loss: 8.3219 - mae: 2.1120</p> <p>Epoch 148/400 9/9 [==============================] - 0s 3ms/step - loss: 8.2850 - mae: 2.1045</p> <p>Epoch 149/400 9/9 [==============================] - 0s 3ms/step - loss: 8.2003 - mae: 2.0864</p> <p>Epoch 150/400 9/9 [==============================] - 0s 3ms/step - loss: 8.3044 - mae: 2.1012</p> <p>Epoch 151/400 9/9 [==============================] - 0s 3ms/step - loss: 8.1278 - mae: 2.0764</p> <p>Epoch 152/400 9/9 [==============================] - 0s 3ms/step - loss: 8.1840 - mae: 2.0984</p> <p>Epoch 153/400 9/9 [==============================] - 0s 3ms/step - loss: 8.0466 - mae: 2.0698</p> <p>Epoch 154/400 9/9 [==============================] - 0s 3ms/step - loss: 8.0476 - mae: 2.0702</p> <p>Epoch 155/400 9/9 [==============================] - 0s 3ms/step - loss: 8.0402 - mae: 2.0748</p> <p>Epoch 156/400 9/9 [==============================] - 0s 3ms/step - loss: 7.9566 - mae: 2.0641</p> <p>Epoch 157/400 9/9 [==============================] - 0s 3ms/step - loss: 7.9516 - mae: 2.0667</p> <p>Epoch 158/400 9/9 [==============================] - 0s 3ms/step - loss: 7.9795 - mae: 2.0733</p> <p>Epoch 159/400 9/9 [==============================] - 0s 4ms/step - loss: 7.8663 - mae: 2.0591</p> <p>Epoch 160/400 9/9 [==============================] - 0s 3ms/step - loss: 7.8300 - mae: 2.0529</p> <p>Epoch 161/400 9/9 [==============================] - 0s 3ms/step - loss: 7.8782 - mae: 2.0532</p> <p>Epoch 162/400 9/9 [==============================] - 0s 3ms/step - loss: 7.7560 - mae: 2.0371</p> <p>Epoch 163/400 9/9 [==============================] - 0s 3ms/step - loss: 7.9327 - mae: 2.0501</p> <p>Epoch 164/400 9/9 [==============================] - 0s 3ms/step - loss: 8.0039 - mae: 2.0472</p> <p>Epoch 165/400 9/9 [==============================] - 0s 4ms/step - loss: 7.8326 - mae: 2.0383</p> <p>Epoch 166/400 9/9 [==============================] - 0s 3ms/step - loss: 7.7433 - mae: 2.0366</p> <p>Epoch 167/400 9/9 [==============================] - 0s 3ms/step - loss: 7.7063 - mae: 2.0403</p> <p>Epoch 168/400 9/9 [==============================] - 0s 4ms/step - loss: 7.6165 - mae: 2.0247</p> <p>Epoch 169/400 9/9 [==============================] - 0s 3ms/step - loss: 7.6203 - mae: 2.0237</p> <p>Epoch 170/400 9/9 [==============================] - 0s 4ms/step - loss: 7.7583 - mae: 2.0332</p> <p>Epoch 171/400 9/9 [==============================] - 0s 4ms/step - loss: 7.7060 - mae: 2.0474</p> <p>Epoch 172/400 9/9 [==============================] - 0s 4ms/step - loss: 7.7214 - mae: 2.0453</p> <p>Epoch 173/400 9/9 [==============================] - 0s 4ms/step - loss: 7.5782 - mae: 2.0151</p> <p>Epoch 174/400 9/9 [==============================] - 0s 3ms/step - loss: 7.4870 - mae: 1.9941</p> <p>Epoch 175/400 9/9 [==============================] - 0s 3ms/step - loss: 7.4292 - mae: 1.9942</p> <p>Epoch 176/400 9/9 [==============================] - 0s 3ms/step - loss: 7.4034 - mae: 1.9908</p> <p>Epoch 177/400 9/9 [==============================] - 0s 3ms/step - loss: 7.3374 - mae: 1.9794</p> <p>Epoch 178/400 9/9 [==============================] - 0s 3ms/step - loss: 7.3651 - mae: 1.9837</p> <p>Epoch 179/400 9/9 [==============================] - 0s 3ms/step - loss: 7.3334 - mae: 1.9801</p> <p>Epoch 180/400 9/9 [==============================] - 0s 3ms/step - loss: 7.2986 - mae: 1.9715</p> <p>Epoch 181/400 9/9 [==============================] - 0s 3ms/step - loss: 7.3080 - mae: 1.9842</p> <p>Epoch 182/400 9/9 [==============================] - 0s 3ms/step - loss: 7.2384 - mae: 1.9710</p> <p>Epoch 183/400 9/9 [==============================] - 0s 3ms/step - loss: 7.2382 - mae: 1.9695</p> <p>Epoch 184/400 9/9 [==============================] - 0s 4ms/step - loss: 7.1499 - mae: 1.9672</p> <p>Epoch 185/400 9/9 [==============================] - 0s 4ms/step - loss: 7.2522 - mae: 1.9746</p> <p>Epoch 186/400 9/9 [==============================] - 0s 3ms/step - loss: 7.1246 - mae: 1.9721</p> <p>Epoch 187/400 9/9 [==============================] - 0s 3ms/step - loss: 7.0991 - mae: 1.9624</p> <p>Epoch 188/400 9/9 [==============================] - 0s 4ms/step - loss: 7.0756 - mae: 1.9483</p> <p>Epoch 189/400 9/9 [==============================] - 0s 3ms/step - loss: 7.1697 - mae: 1.9584</p> <p>Epoch 190/400 9/9 [==============================] - 0s 4ms/step - loss: 6.9426 - mae: 1.9408</p> <p>Epoch 191/400 9/9 [==============================] - 0s 3ms/step - loss: 7.0492 - mae: 1.9498</p> <p>Epoch 192/400 9/9 [==============================] - 0s 3ms/step - loss: 6.9617 - mae: 1.9392</p> <p>Epoch 193/400 9/9 [==============================] - 0s 3ms/step - loss: 6.9713 - mae: 1.9391</p> <p>Epoch 194/400 9/9 [==============================] - 0s 3ms/step - loss: 6.9681 - mae: 1.9466</p> <p>Epoch 195/400 9/9 [==============================] - 0s 3ms/step - loss: 7.0815 - mae: 1.9378</p> <p>Epoch 196/400 9/9 [==============================] - 0s 3ms/step - loss: 6.9769 - mae: 1.9339</p> <p>Epoch 197/400 9/9 [==============================] - 0s 4ms/step - loss: 6.8727 - mae: 1.9210</p> <p>Epoch 198/400 9/9 [==============================] - 0s 3ms/step - loss: 6.8014 - mae: 1.9227</p> <p>Epoch 199/400 9/9 [==============================] - 0s 3ms/step - loss: 6.7703 - mae: 1.9244</p> <p>Epoch 200/400 9/9 [==============================] - 0s 3ms/step - loss: 6.8127 - mae: 1.9195</p> <p>Epoch 201/400 9/9 [==============================] - 0s 3ms/step - loss: 6.7469 - mae: 1.9105</p> <p>Epoch 202/400 9/9 [==============================] - 0s 3ms/step - loss: 6.7515 - mae: 1.9144</p> <p>Epoch 203/400 9/9 [==============================] - 0s 3ms/step - loss: 6.6946 - mae: 1.9044</p> <p>Epoch 204/400 9/9 [==============================] - 0s 4ms/step - loss: 6.6362 - mae: 1.8985</p> <p>Epoch 205/400 9/9 [==============================] - 0s 4ms/step - loss: 6.6175 - mae: 1.8955</p> <p>Epoch 206/400 9/9 [==============================] - 0s 3ms/step - loss: 6.5702 - mae: 1.8874</p> <p>Epoch 207/400 9/9 [==============================] - 0s 3ms/step - loss: 6.5716 - mae: 1.8900</p> <p>Epoch 208/400 9/9 [==============================] - 0s 4ms/step - loss: 6.5384 - mae: 1.8846</p> <p>Epoch 209/400 9/9 [==============================] - 0s 3ms/step - loss: 6.5449 - mae: 1.8830</p> <p>Epoch 210/400 9/9 [==============================] - 0s 3ms/step - loss: 6.5513 - mae: 1.8749</p> <p>Epoch 211/400 9/9 [==============================] - 0s 4ms/step - loss: 6.4929 - mae: 1.8735</p> <p>Epoch 212/400 9/9 [==============================] - 0s 3ms/step - loss: 6.5068 - mae: 1.8747</p> <p>Epoch 213/400 9/9 [==============================] - 0s 3ms/step - loss: 6.5305 - mae: 1.8740</p> <p>Epoch 214/400 9/9 [==============================] - 0s 6ms/step - loss: 6.5346 - mae: 1.8997</p> <p>Epoch 215/400 9/9 [==============================] - 0s 5ms/step - loss: 6.4906 - mae: 1.8849</p> <p>Epoch 216/400 9/9 [==============================] - 0s 4ms/step - loss: 6.4162 - mae: 1.8608</p> <p>Epoch 217/400 9/9 [==============================] - 0s 3ms/step - loss: 6.3261 - mae: 1.8522</p> <p>Epoch 218/400 9/9 [==============================] - 0s 3ms/step - loss: 6.2750 - mae: 1.8420</p> <p>Epoch 219/400 9/9 [==============================] - 0s 3ms/step - loss: 6.2780 - mae: 1.8364</p> <p>Epoch 220/400 9/9 [==============================] - 0s 2ms/step - loss: 6.2991 - mae: 1.8530</p> <p>Epoch 221/400 9/9 [==============================] - 0s 2ms/step - loss: 6.2668 - mae: 1.8361</p> <p>Epoch 222/400 9/9 [==============================] - 0s 2ms/step - loss: 6.2077 - mae: 1.8355</p> <p>Epoch 223/400 9/9 [==============================] - 0s 3ms/step - loss: 6.1889 - mae: 1.8245</p> <p>Epoch 224/400 9/9 [==============================] - 0s 2ms/step - loss: 6.2081 - mae: 1.8289</p> <p>Epoch 225/400 9/9 [==============================] - 0s 2ms/step - loss: 6.1629 - mae: 1.8108</p> <p>Epoch 226/400 9/9 [==============================] - 0s 2ms/step - loss: 6.1450 - mae: 1.8226</p> <p>Epoch 227/400 9/9 [==============================] - 0s 2ms/step - loss: 6.1505 - mae: 1.8359</p> <p>Epoch 228/400 9/9 [==============================] - 0s 2ms/step - loss: 6.1221 - mae: 1.8270</p> <p>Epoch 229/400 9/9 [==============================] - 0s 3ms/step - loss: 6.1809 - mae: 1.8272</p> <p>Epoch 230/400 9/9 [==============================] - 0s 3ms/step - loss: 6.0162 - mae: 1.8011</p> <p>Epoch 231/400 9/9 [==============================] - 0s 3ms/step - loss: 6.1452 - mae: 1.8393</p> <p>Epoch 232/400 9/9 [==============================] - 0s 3ms/step - loss: 6.0985 - mae: 1.8124</p> <p>Epoch 233/400 9/9 [==============================] - 0s 2ms/step - loss: 6.4570 - mae: 1.8844</p> <p>Epoch 234/400 9/9 [==============================] - 0s 1ms/step - loss: 6.2272 - mae: 1.8489</p> <p>Epoch 235/400 9/9 [==============================] - 0s 2ms/step - loss: 6.0741 - mae: 1.8166</p> <p>Epoch 236/400 9/9 [==============================] - 0s 4ms/step - loss: 6.0031 - mae: 1.8197</p> <p>Epoch 237/400 9/9 [==============================] - 0s 2ms/step - loss: 5.9739 - mae: 1.8037</p> <p>Epoch 238/400 9/9 [==============================] - 0s 2ms/step - loss: 6.0253 - mae: 1.8145</p> <p>Epoch 239/400 9/9 [==============================] - 0s 2ms/step - loss: 5.9134 - mae: 1.7873</p> <p>Epoch 240/400 9/9 [==============================] - 0s 4ms/step - loss: 5.8683 - mae: 1.7957</p> <p>Epoch 241/400 9/9 [==============================] - 0s 2ms/step - loss: 5.8370 - mae: 1.7853</p> <p>Epoch 242/400 9/9 [==============================] - 0s 2ms/step - loss: 5.6954 - mae: 1.7598</p> <p>Epoch 243/400 9/9 [==============================] - 0s 3ms/step - loss: 5.7053 - mae: 1.7696</p> <p>Epoch 244/400 9/9 [==============================] - 0s 2ms/step - loss: 5.6565 - mae: 1.7627</p> <p>Epoch 245/400 9/9 [==============================] - 0s 2ms/step - loss: 5.7158 - mae: 1.7734</p> <p>Epoch 246/400 9/9 [==============================] - 0s 3ms/step - loss: 5.6415 - mae: 1.7482</p> <p>Epoch 247/400 9/9 [==============================] - 0s 2ms/step - loss: 5.6077 - mae: 1.7508</p> <p>Epoch 248/400 9/9 [==============================] - 0s 2ms/step - loss: 5.7397 - mae: 1.7653</p> <p>Epoch 249/400 9/9 [==============================] - 0s 3ms/step - loss: 5.6152 - mae: 1.7499</p> <p>Epoch 250/400 9/9 [==============================] - 0s 2ms/step - loss: 5.6300 - mae: 1.7422</p> <p>Epoch 251/400 9/9 [==============================] - 0s 3ms/step - loss: 5.5146 - mae: 1.7228</p> <p>Epoch 252/400 9/9 [==============================] - 0s 2ms/step - loss: 5.5786 - mae: 1.7403</p> <p>Epoch 253/400 9/9 [==============================] - 0s 4ms/step - loss: 5.5123 - mae: 1.7385</p> <p>Epoch 254/400 9/9 [==============================] - 0s 3ms/step - loss: 5.4784 - mae: 1.7380</p> <p>Epoch 255/400 9/9 [==============================] - 0s 2ms/step - loss: 5.5062 - mae: 1.7488</p> <p>Epoch 256/400 9/9 [==============================] - 0s 2ms/step - loss: 5.5507 - mae: 1.7410</p> <p>Epoch 257/400 9/9 [==============================] - 0s 3ms/step - loss: 5.4626 - mae: 1.7239</p> <p>Epoch 258/400 9/9 [==============================] - 0s 2ms/step - loss: 5.4174 - mae: 1.7266</p> <p>Epoch 259/400 9/9 [==============================] - 0s 2ms/step - loss: 5.4086 - mae: 1.7221</p> <p>Epoch 260/400 9/9 [==============================] - 0s 2ms/step - loss: 5.4384 - mae: 1.7349</p> <p>Epoch 261/400 9/9 [==============================] - 0s 2ms/step - loss: 5.3345 - mae: 1.7105</p> <p>Epoch 262/400 9/9 [==============================] - 0s 2ms/step - loss: 5.4374 - mae: 1.7372</p> <p>Epoch 263/400 9/9 [==============================] - 0s 2ms/step - loss: 5.3719 - mae: 1.7141</p> <p>Epoch 264/400 9/9 [==============================] - 0s 3ms/step - loss: 5.3888 - mae: 1.7084</p> <p>Epoch 265/400 9/9 [==============================] - 0s 2ms/step - loss: 5.3843 - mae: 1.7203</p> <p>Epoch 266/400 9/9 [==============================] - 0s 3ms/step - loss: 5.2937 - mae: 1.6940</p> <p>Epoch 267/400 9/9 [==============================] - 0s 3ms/step - loss: 5.4328 - mae: 1.7181</p> <p>Epoch 268/400 9/9 [==============================] - 0s 3ms/step - loss: 5.4531 - mae: 1.7435</p> <p>Epoch 269/400 9/9 [==============================] - 0s 3ms/step - loss: 5.3654 - mae: 1.7205</p> <p>Epoch 270/400 9/9 [==============================] - 0s 3ms/step - loss: 5.2651 - mae: 1.6883</p> <p>Epoch 271/400 9/9 [==============================] - 0s 3ms/step - loss: 5.2156 - mae: 1.6878</p> <p>Epoch 272/400 9/9 [==============================] - 0s 3ms/step - loss: 5.1566 - mae: 1.6785</p> <p>Epoch 273/400 9/9 [==============================] - 0s 2ms/step - loss: 5.1215 - mae: 1.6799</p> <p>Epoch 274/400 9/9 [==============================] - 0s 2ms/step - loss: 5.2469 - mae: 1.7029</p> <p>Epoch 275/400 9/9 [==============================] - 0s 2ms/step - loss: 5.2710 - mae: 1.7097</p> <p>Epoch 276/400 9/9 [==============================] - 0s 3ms/step - loss: 5.2278 - mae: 1.7117</p> <p>Epoch 277/400 9/9 [==============================] - 0s 3ms/step - loss: 5.2271 - mae: 1.6952</p> <p>Epoch 278/400 9/9 [==============================] - 0s 4ms/step - loss: 5.2615 - mae: 1.6881</p> <p>Epoch 279/400 9/9 [==============================] - 0s 3ms/step - loss: 5.0883 - mae: 1.6659</p> <p>Epoch 280/400 9/9 [==============================] - 0s 3ms/step - loss: 5.0631 - mae: 1.6695</p> <p>Epoch 281/400 9/9 [==============================] - 0s 2ms/step - loss: 5.0413 - mae: 1.6467</p> <p>Epoch 282/400 9/9 [==============================] - 0s 2ms/step - loss: 5.0614 - mae: 1.6541</p> <p>Epoch 283/400 9/9 [==============================] - 0s 3ms/step - loss: 5.2651 - mae: 1.6999</p> <p>Epoch 284/400 9/9 [==============================] - 0s 3ms/step - loss: 5.0937 - mae: 1.6658</p> <p>Epoch 285/400 9/9 [==============================] - 0s 3ms/step - loss: 4.9900 - mae: 1.6483</p> <p>Epoch 286/400 9/9 [==============================] - 0s 3ms/step - loss: 4.9686 - mae: 1.6482</p> <p>Epoch 287/400 9/9 [==============================] - 0s 2ms/step - loss: 4.9377 - mae: 1.6493</p> <p>Epoch 288/400 9/9 [==============================] - 0s 3ms/step - loss: 4.9239 - mae: 1.6397</p> <p>Epoch 289/400 9/9 [==============================] - 0s 4ms/step - loss: 5.0049 - mae: 1.6458</p> <p>Epoch 290/400 9/9 [==============================] - 0s 3ms/step - loss: 5.0257 - mae: 1.6677</p> <p>Epoch 291/400 9/9 [==============================] - 0s 3ms/step - loss: 4.9595 - mae: 1.6502</p> <p>Epoch 292/400 9/9 [==============================] - 0s 3ms/step - loss: 4.8937 - mae: 1.6199</p> <p>Epoch 293/400 9/9 [==============================] - 0s 3ms/step - loss: 4.8048 - mae: 1.6054</p> <p>Epoch 294/400 9/9 [==============================] - 0s 3ms/step - loss: 4.8538 - mae: 1.6189</p> <p>Epoch 295/400 9/9 [==============================] - 0s 3ms/step - loss: 4.8086 - mae: 1.6214</p> <p>Epoch 296/400 9/9 [==============================] - 0s 3ms/step - loss: 4.9100 - mae: 1.6228</p> <p>Epoch 297/400 9/9 [==============================] - 0s 4ms/step - loss: 4.7689 - mae: 1.6057</p> <p>Epoch 298/400 9/9 [==============================] - 0s 3ms/step - loss: 4.7895 - mae: 1.6120</p> <p>Epoch 299/400 9/9 [==============================] - 0s 3ms/step - loss: 4.7679 - mae: 1.6074</p> <p>Epoch 300/400 9/9 [==============================] - 0s 3ms/step - loss: 4.9302 - mae: 1.6508</p> <p>Epoch 301/400 9/9 [==============================] - 0s 4ms/step - loss: 4.8806 - mae: 1.6316</p> <p>Epoch 302/400 9/9 [==============================] - 0s 4ms/step - loss: 4.7871 - mae: 1.6054</p> <p>Epoch 303/400 9/9 [==============================] - 0s 4ms/step - loss: 4.7296 - mae: 1.6088</p> <p>Epoch 304/400 9/9 [==============================] - 0s 3ms/step - loss: 4.8593 - mae: 1.6316</p> <p>Epoch 305/400 9/9 [==============================] - 0s 3ms/step - loss: 4.8702 - mae: 1.6265</p> <p>Epoch 306/400 9/9 [==============================] - 0s 4ms/step - loss: 4.9289 - mae: 1.6436</p> <p>Epoch 307/400 9/9 [==============================] - 0s 3ms/step - loss: 4.8258 - mae: 1.6364</p> <p>Epoch 308/400 9/9 [==============================] - 0s 3ms/step - loss: 4.7715 - mae: 1.6131</p> <p>Epoch 309/400 9/9 [==============================] - 0s 3ms/step - loss: 4.7257 - mae: 1.5808</p> <p>Epoch 310/400 9/9 [==============================] - 0s 3ms/step - loss: 4.9713 - mae: 1.6622</p> <p>Epoch 311/400 9/9 [==============================] - 0s 3ms/step - loss: 4.7670 - mae: 1.6311</p> <p>Epoch 312/400 9/9 [==============================] - 0s 3ms/step - loss: 4.7790 - mae: 1.6104</p> <p>Epoch 313/400 9/9 [==============================] - 0s 3ms/step - loss: 4.6748 - mae: 1.6186</p> <p>Epoch 314/400 9/9 [==============================] - 0s 3ms/step - loss: 4.7386 - mae: 1.6191</p> <p>Epoch 315/400 9/9 [==============================] - 0s 3ms/step - loss: 4.5862 - mae: 1.5769</p> <p>Epoch 316/400 9/9 [==============================] - 0s 3ms/step - loss: 4.6310 - mae: 1.5809</p> <p>Epoch 317/400 9/9 [==============================] - 0s 3ms/step - loss: 4.8212 - mae: 1.6367</p> <p>Epoch 318/400 9/9 [==============================] - 0s 3ms/step - loss: 4.4685 - mae: 1.5482</p> <p>Epoch 319/400 9/9 [==============================] - 0s 3ms/step - loss: 4.6965 - mae: 1.5876</p> <p>Epoch 320/400 9/9 [==============================] - 0s 3ms/step - loss: 4.7098 - mae: 1.5959</p> <p>Epoch 321/400 9/9 [==============================] - 0s 3ms/step - loss: 4.8441 - mae: 1.6635</p> <p>Epoch 322/400 9/9 [==============================] - 0s 3ms/step - loss: 4.5366 - mae: 1.5945</p> <p>Epoch 323/400 9/9 [==============================] - 0s 3ms/step - loss: 4.7188 - mae: 1.5974</p> <p>Epoch 324/400 9/9 [==============================] - 0s 3ms/step - loss: 4.5682 - mae: 1.5611</p> <p>Epoch 325/400 9/9 [==============================] - 0s 3ms/step - loss: 4.5609 - mae: 1.5801</p> <p>Epoch 326/400 9/9 [==============================] - 0s 3ms/step - loss: 4.5395 - mae: 1.5852</p> <p>Epoch 327/400 9/9 [==============================] - 0s 3ms/step - loss: 4.4885 - mae: 1.5625</p> <p>Epoch 328/400 9/9 [==============================] - 0s 3ms/step - loss: 4.3885 - mae: 1.5423</p> <p>Epoch 329/400 9/9 [==============================] - 0s 4ms/step - loss: 4.5206 - mae: 1.5739</p> <p>Epoch 330/400 9/9 [==============================] - 0s 7ms/step - loss: 4.4114 - mae: 1.5382</p> <p>Epoch 331/400 9/9 [==============================] - 0s 3ms/step - loss: 4.3323 - mae: 1.5197</p> <p>Epoch 332/400 9/9 [==============================] - 0s 3ms/step - loss: 4.3240 - mae: 1.5208</p> <p>Epoch 333/400 9/9 [==============================] - 0s 3ms/step - loss: 4.4238 - mae: 1.5322</p> <p>Epoch 334/400 9/9 [==============================] - 0s 3ms/step - loss: 4.3662 - mae: 1.5501</p> <p>Epoch 335/400 9/9 [==============================] - 0s 3ms/step - loss: 4.3211 - mae: 1.5324</p> <p>Epoch 336/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2283 - mae: 1.5031</p> <p>Epoch 337/400 9/9 [==============================] - 0s 4ms/step - loss: 4.2960 - mae: 1.5352</p> <p>Epoch 338/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2662 - mae: 1.5223</p> <p>Epoch 339/400 9/9 [==============================] - 0s 3ms/step - loss: 4.3856 - mae: 1.5406</p> <p>Epoch 340/400 9/9 [==============================] - 0s 3ms/step - loss: 4.3143 - mae: 1.5513</p> <p>Epoch 341/400 9/9 [==============================] - 0s 3ms/step - loss: 4.3948 - mae: 1.5666</p> <p>Epoch 342/400 9/9 [==============================] - 0s 3ms/step - loss: 4.3177 - mae: 1.5356</p> <p>Epoch 343/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2848 - mae: 1.5331</p> <p>Epoch 344/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2723 - mae: 1.5274</p> <p>Epoch 345/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2018 - mae: 1.5079</p> <p>Epoch 346/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2182 - mae: 1.5171</p> <p>Epoch 347/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2083 - mae: 1.5251</p> <p>Epoch 348/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2829 - mae: 1.5318</p> <p>Epoch 349/400 9/9 [==============================] - 0s 3ms/step - loss: 4.1793 - mae: 1.4975</p> <p>Epoch 350/400 9/9 [==============================] - 0s 3ms/step - loss: 4.1535 - mae: 1.5021</p> <p>Epoch 351/400 9/9 [==============================] - 0s 3ms/step - loss: 4.1689 - mae: 1.4901</p> <p>Epoch 352/400 9/9 [==============================] - 0s 3ms/step - loss: 4.1737 - mae: 1.5091</p> <p>Epoch 353/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2916 - mae: 1.5423</p> <p>Epoch 354/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2486 - mae: 1.5089</p> <p>Epoch 355/400 9/9 [==============================] - 0s 3ms/step - loss: 4.5061 - mae: 1.5545</p> <p>Epoch 356/400 9/9 [==============================] - 0s 4ms/step - loss: 4.1563 - mae: 1.5199</p> <p>Epoch 357/400 9/9 [==============================] - 0s 3ms/step - loss: 4.1927 - mae: 1.5353</p> <p>Epoch 358/400 9/9 [==============================] - 0s 3ms/step - loss: 4.0238 - mae: 1.4803</p> <p>Epoch 359/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2785 - mae: 1.5282</p> <p>Epoch 360/400 9/9 [==============================] - 0s 3ms/step - loss: 4.1957 - mae: 1.5044</p> <p>Epoch 361/400 9/9 [==============================] - 0s 3ms/step - loss: 4.0877 - mae: 1.5101</p> <p>Epoch 362/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9776 - mae: 1.4631</p> <p>Epoch 363/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9758 - mae: 1.4540</p> <p>Epoch 364/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9303 - mae: 1.4430</p> <p>Epoch 365/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9630 - mae: 1.4558</p> <p>Epoch 366/400 9/9 [==============================] - 0s 3ms/step - loss: 3.8929 - mae: 1.4350</p> <p>Epoch 367/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9009 - mae: 1.4355</p> <p>Epoch 368/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9361 - mae: 1.4656</p> <p>Epoch 369/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9120 - mae: 1.4496</p> <p>Epoch 370/400 9/9 [==============================] - 0s 3ms/step - loss: 3.8926 - mae: 1.4374</p> <p>Epoch 371/400 9/9 [==============================] - 0s 3ms/step - loss: 3.8675 - mae: 1.4317</p> <p>Epoch 372/400 9/9 [==============================] - 0s 4ms/step - loss: 3.8442 - mae: 1.4272</p> <p>Epoch 373/400 9/9 [==============================] - 0s 3ms/step - loss: 3.8265 - mae: 1.4365</p> <p>Epoch 374/400 9/9 [==============================] - 0s 3ms/step - loss: 3.7951 - mae: 1.4227</p> <p>Epoch 375/400 9/9 [==============================] - 0s 3ms/step - loss: 3.8109 - mae: 1.4185</p> <p>Epoch 376/400 9/9 [==============================] - 0s 4ms/step - loss: 3.8171 - mae: 1.4315</p> <p>Epoch 377/400 9/9 [==============================] - 0s 3ms/step - loss: 3.8079 - mae: 1.4224</p> <p>Epoch 378/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9359 - mae: 1.4343</p> <p>Epoch 379/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9052 - mae: 1.4712</p> <p>Epoch 380/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9682 - mae: 1.4686</p> <p>Epoch 381/400 9/9 [==============================] - 0s 4ms/step - loss: 3.8712 - mae: 1.4372</p> <p>Epoch 382/400 9/9 [==============================] - 0s 10ms/step - loss: 3.7983 - mae: 1.4193</p> <p>Epoch 383/400 9/9 [==============================] - 0s 16ms/step - loss: 3.7823 - mae: 1.4226</p> <p>Epoch 384/400 9/9 [==============================] - 0s 5ms/step - loss: 3.7303 - mae: 1.4140</p> <p>Epoch 385/400 9/9 [==============================] - 0s 4ms/step - loss: 3.7204 - mae: 1.4044</p> <p>Epoch 386/400 9/9 [==============================] - 0s 3ms/step - loss: 3.7432 - mae: 1.4152</p> <p>Epoch 387/400 9/9 [==============================] - 0s 3ms/step - loss: 3.7204 - mae: 1.4045</p> <p>Epoch 388/400 9/9 [==============================] - 0s 3ms/step - loss: 3.7163 - mae: 1.3980</p> <p>Epoch 389/400 9/9 [==============================] - 0s 3ms/step - loss: 3.6538 - mae: 1.3896</p> <p>Epoch 390/400 9/9 [==============================] - 0s 3ms/step - loss: 3.6510 - mae: 1.3874</p> <p>Epoch 391/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9399 - mae: 1.4741</p> <p>Epoch 392/400 9/9 [==============================] - 0s 3ms/step - loss: 3.8155 - mae: 1.4265</p> <p>Epoch 393/400 9/9 [==============================] - 0s 3ms/step - loss: 3.6893 - mae: 1.3884</p> <p>Epoch 394/400 9/9 [==============================] - 0s 3ms/step - loss: 3.6876 - mae: 1.4176</p> <p>Epoch 395/400 9/9 [==============================] - 0s 3ms/step - loss: 3.6896 - mae: 1.3905</p> <p>Epoch 396/400 9/9 [==============================] - 0s 3ms/step - loss: 3.6180 - mae: 1.3828</p> <p>Epoch 397/400 9/9 [==============================] - 0s 3ms/step - loss: 3.5933 - mae: 1.3773</p> <p>Epoch 398/400 9/9 [==============================] - 0s 3ms/step - loss: 3.5719 - mae: 1.3750</p> <p>Epoch 399/400 9/9 [==============================] - 0s 3ms/step - loss: 3.5381 - mae: 1.3641</p> <p>Epoch 400/400 9/9 [==============================] - 0s 3ms/step - loss: 3.6085 - mae: 1.3688</p> <p><pre><code># Applique le mod\u00e8le sur la data du test\npred_test = model.predict(X_test)\npred_test.shape\n</code></pre> <pre><code># Evaluation du mod\u00e8le\nresult_test = model.evaluate(X_test, y_test, verbose=0)\nprint('MSE test', round(result_test[0],2))\nprint('MAE test', round(result_test[1],2))\n</code></pre></p> Output <p>MSE test 10.72</p> <p>MAE test 2.11</p>"},{"location":"projects/boston%20datasets/#support-vector-regression-svr","title":"Support Vector Regression SVR","text":"<pre><code># D\u00e9finir le mod\u00e8le\nmodel_SVR = svm.SVR()\n\n# Lancer l\u2019apprentissage\nmodel_SVR.fit(X_train,y_train)\n</code></pre>"},{"location":"projects/boston%20datasets/#regression-lineaire-lr","title":"R\u00e9gression Lin\u00e9aire LR","text":"<p><pre><code># D\u00e9finir le mod\u00e8le\nregression=LinearRegression()\n\n# Lancer l\u2019apprentissage\nregression.fit(X_train,y_train)\n</code></pre> <pre><code># Afficher les coefficients \nprint(regression.coef_)\n</code></pre></p> Output <p>[-1.00213533  0.69626862  0.27806485  0.7187384  -2.0223194   3.14523956 -0.17604788 -3.0819076   2.25140666 -1.76701378 -2.03775151  1.12956831 -3.61165842]</p> <pre><code># Afficher the intercept\nprint(regression.intercept_)\n</code></pre> Output <p>23.023938223938224</p> <pre><code># Sur quels param\u00e8tres le mod\u00e8le a entrainn\u00e9\nregression.get_params()\n</code></pre> Output <p>{'copy_X': True,</p> <p>'fit_intercept': True,</p> <p>'n_jobs': None,</p> <p>'normalize': 'deprecated',</p> <p>'positive': False}</p>"},{"location":"projects/ozone%20datasets/","title":"Ozone Dataset","text":""},{"location":"projects/ozone%20datasets/#introduction","title":"Introduction","text":"<p>Le jeu de donn\u00e9es contient 1464 observations (journali\u00e8res, du 01/04/1995 au 30/09/2002, \u00e0 Rennes).</p>"},{"location":"projects/ozone%20datasets/#preparation-des-donnees","title":"Pr\u00e9paration des donn\u00e9es","text":"<pre><code># Importer les biblioth\u00e8ques\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom tensorflow import keras\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dropout\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras.layers import Dense\nfrom sklearn.metrics import mean_squared_error\n</code></pre> <p>Lors de l'importation des donn\u00e9es, j'ai remplac\u00e9 la colonne index par la colonne des dates.</p> <p><pre><code># Importer le datasets + remplacer la colonne des indexes par celle des dates\nozone = pd.read_csv(\"ozone_complet.csv\", sep=\";\", index_col='Unnamed: 0')\n</code></pre> <pre><code># Lire les 5 premi\u00e8re lignes\nozone.head()\n</code></pre></p>"},{"location":"projects/ozone%20datasets/#etude-exploratoire-des-donnees","title":"\u00c9tude exploratoire des donn\u00e9es","text":"<p><pre><code># Afficher quelques informations du dataset\nozone.info()\n</code></pre> <pre><code># Afficher quelques statistiques du dataset\nozone.describe()\n</code></pre> <pre><code># Analyse les distributions des donn\u00e9es\nozone.hist(bins=50, figsize=(20,15))\nplt.show()\n</code></pre></p> Output <p></p> <pre><code># Analyse des corr\u00e9lations\n\nmatriceCorr = ozone.corr().round(1)\nsns.heatmap(data=matriceCorr, annot = True)\n</code></pre> Output <p></p> <pre><code># Afficher le nombre des valeurs manquantes dans chaque colonne\nozone.isnull().sum()\n</code></pre> <p>J'ai ensuite remarqu\u00e9 qu'il y avait des valeurs manquantes dans l'ensemble de donn\u00e9es. Pour r\u00e9soudre ce probl\u00e8me, j'ai remplac\u00e9 ces valeurs par la moyenne en utilisant \u00ab SimpleImputer \u00bb.</p> <p><pre><code># Remplir les valeurs manquentes par la mayenne\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy=\"median\")\n</code></pre> <pre><code># Lancer l'entrainement de Imputer\nimputer.fit(ozone)\n</code></pre> <pre><code># Appliquer le mod\u00e8le Imputer sur le dataset ozone (la sortie est de type array)\nozone_complet = imputer.transform(ozone)\n</code></pre> <pre><code># Transformer le dataset (sortie de Imputer de type array) en data frame\nozone_complet = pd.DataFrame(ozone_complet, columns=ozone.columns)\n</code></pre> <pre><code># V\u00e9rifier qu'il n'ya plus de valeurs manquantes\nozone_complet.isnull().sum()\n</code></pre></p>"},{"location":"projects/ozone%20datasets/#implementation-dun-modele-de-reseau-de-neurones","title":"Impl\u00e9mentation d\u2019un mod\u00e8le de r\u00e9seau de neurones","text":"<p><pre><code># Division de donn\u00e9es en donn\u00e9es d'entrainement, du test et de validation\n\nozone_complet = ozone_complet.sample(frac=1, axis=0)\n\ndata_train_valid = ozone_complet.sample(frac=0.85, axis=0)\ndata_test = ozone_complet.drop(data_train_valid.index)\ndata_train = data_train_valid.sample(frac=0.8, axis=0)\ndata_valid = data_train_valid.drop(data_train.index)\n\nx_train = data_train.drop('maxO3', axis=1)\ny_train = data_train['maxO3']\nprint('Dimensions de X train :', x_train.shape)\nprint('Dimensions de Y train :', y_train.shape)\n\nx_valid = data_valid.drop('maxO3', axis=1)\ny_valid = data_valid['maxO3']\nprint('Dimensions de X valid :', x_valid.shape)\nprint('Dimensions de Y valid :', y_valid.shape)\n\nx_test = data_test.drop('maxO3', axis=1)\ny_test = data_test['maxO3']\nprint('Dimensions de X test :', x_test.shape)\nprint('Dimensions de Y test :', y_test.shape)\n</code></pre> <pre><code># Normalisation des donn\u00e9es\n\nmin_x_train = x_train.min()\nmax_x_train = x_train.max()\n\nprint(\"Min de x_train :\", min_x_train)\nprint(\"Max de x_train :\", max_x_train)\n\nx_train_norm = (x_train-min_x_train)/(max_x_train-min_x_train)\nx_test_norm = (x_test-min_x_train)/(max_x_train-min_x_train)\nx_val_norm = (x_valid-min_x_train)/(max_x_train-min_x_train)\n</code></pre></p> <p>La structure du perceptron se compose d'une couche d'entr\u00e9e avec 22 neurones correspondant \u00e0 chacune des 22 features, de deux couches cach\u00e9es avec 5 neurones par chacune et d'une couche de sortie avec un seul neurone qui donnera la valeur pr\u00e9dite de <code>maxO3</code>. La <code>fonction ReLu</code> a \u00e9t\u00e9 choisie comme fonction d'activation pour chacune des trois couches, <code>mean square error</code> comme loss function, et l'algorithme <code>Adam optimizer</code> pour son adaptative learning rate and momentum.</p> <p><pre><code>## Impl\u00e9mentation de mod\u00e8le DNN\n\nmodel = Sequential()\nmodel.add(Dense(22, input_dim=np.shape(x_train)[1], activation = 'relu'))\nmodel.add(Dropout(.5))\nmodel.add(Dense(5, activation = 'relu'))\nmodel.add(Dropout(.5))\nmodel.add(Dense(5, activation = 'relu'))\nmodel.add(Dropout(.5))\nmodel.add(Dense(1, activation = 'relu'))\n\nmodel.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics=['mean_squared_error'])\n\nmodel.summary()\n</code></pre> <pre><code>callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=100)\n\nhist = model.fit(x_train_norm, y_train, epochs = 1000, batch_size = 9999, callbacks = callback)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es du test\n\npred_train= model.predict(x_train_norm)\nprint(np.sqrt(mean_squared_error(y_train,pred_train)))\n\npred= model.predict(x_test_norm)\nprint(np.sqrt(mean_squared_error(y_test,pred)))\n</code></pre></p>"},{"location":"projects/ozone%20datasets/#implementation-dune-regression-lineaire","title":"Impl\u00e9mentation d'une R\u00e9gression Lin\u00e9aire","text":"<p>J'ai \u00e9galement mis en \u0153uvre une r\u00e9gression lin\u00e9aire et j\u2019ai obtenu un score de 0,625 pour les donn\u00e9es de test et un score de 0,646 pour les donn\u00e9es de validation.</p> <p><pre><code>from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(x_train_norm, y_train)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es du test\n\nscore_test_lin_reg = lin_reg.score(x_test_norm, y_test)\nprint(\"Test Accuracy Score\", score_test_lin_reg)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es de validation\n\nscore_valid_lin_reg = lin_reg.score(x_val_norm, y_valid)\nprint(\"Test Accuracy Score\", score_valid_lin_reg)\n</code></pre></p>"},{"location":"projects/ozone%20datasets/#implementation-dun-svr","title":"Impl\u00e9mentation d\u2019un SVR","text":"<p>Un SVR a \u00e9galement \u00e9t\u00e9 mis en place et a donn\u00e9 un score de 0,489 pour les donn\u00e9es de test et un score de 0,519 pour les donn\u00e9es de validation.</p> <p><pre><code>from sklearn.svm import SVR\n\nsvr = SVR()\nsvr.fit(x_train_norm, y_train)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es du test\n\nscore_test_svr = svr.score(x_test_norm, y_test)\nprint(\"Test Accuracy Score\", score_test_svr)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es de validation\n\nscore_valid_svr = svr.score(x_val_norm, y_valid)\nprint(\"Test Accuracy Score\", score_valid_svr)\n</code></pre></p>"},{"location":"projects/ozone%20datasets/#conclusion","title":"Conclusion","text":"<p>Pour conclure, voici un tableau qui r\u00e9sume les diff\u00e9rents scores de tous les mod\u00e8les que j'ai mis en place :</p> Mod\u00e8le Score (test dataset) Score (validation dataset) R\u00e9seau de neurones (DNN) mean square error : 36.827398008235775 R\u00e9gression Lin\u00e9aire 0.6250066102296177 0.6463044934834267 SVM (SVR) 0.4895962389393179 0.5192747605192083"},{"location":"projects/projet%20R/","title":"Profilage des chauffeurs","text":"<p>Membres du groupe</p> <ul> <li>Abdellatif BELMADY</li> <li>Fatine BOUSSATTINE</li> <li>Hamza HAJJINI</li> <li>Hamza Dribine</li> <li>Mohamed Ait Hajjoub</li> </ul>"},{"location":"projects/projet%20R/#importer-les-packages","title":"Importer les packages","text":"<pre><code>library(sf)           # manipulation des donn\u00e9es spatiales\nlibrary(osmdata)      # extraction des donn\u00e9es OpenStreetMap\nlibrary(leaflet)      # visualisation interactive avec leaflet\nlibrary(mapsf)        # cartographie statistique\nlibrary(lubridate)    # manipulation des dates\nlibrary(tidyverse)    # m\u00e9ta-package d'Hadley Wickham\n</code></pre> <p><code>getwd()</code> est une fonction qui permet de r\u00e9cup\u00e9rer le chemin absolu du r\u00e9pertoire de travail actuel.</p> <pre><code>getwd()\n</code></pre> Output <p>[1] \"C:/Users/abdel/Documents\"</p>"},{"location":"projects/projet%20R/#importer-la-data","title":"Importer la data","text":"<ul> <li> <p>Le premier fichier, <code>casabound.geojson</code>, est lu \u00e0 l'aide de la fonction st_read() de la biblioth\u00e8que sf. Cette fonction est utilis\u00e9e pour lire des fichiers de donn\u00e9es spatiales tels que des fichiers shapefile, des fichiers GeoJSON, etc. Ici, il lit un fichier GeoJSON nomm\u00e9 \"casabound.geojson\" et stocke les donn\u00e9es dans un objet nomm\u00e9 casaBound.</p> </li> <li> <p>Le deuxi\u00e8me fichier, <code>heetchmarchcrop.Rds</code>, est lu \u00e0 l'aide de la fonction readRDS(). Cette fonction est utilis\u00e9e pour lire des fichiers de donn\u00e9es R sauvegard\u00e9s en utilisant la fonction saveRDS(). Ici, il lit un fichier RDS nomm\u00e9 heetchmarchcrop.Rds et stocke les donn\u00e9es dans un objet nomm\u00e9 heetchPoints.</p> </li> <li> <p>Le troisi\u00e8me fichier, <code>osmfeatures.Rds</code>, est \u00e9galement lu \u00e0 l'aide de la fonction readRDS(). Comme le deuxi\u00e8me fichier, il s'agit d'un fichier RDS et est lu dans un objet nomm\u00e9 osmFeatures.</p> </li> </ul> <pre><code>casaBound &lt;- st_read(\"DATA/casabound.geojson\")\nheetchPoints &lt;- readRDS(\"DATA/heetchmarchcrop.Rds\")\nosmFeatures &lt;- readRDS(\"DATA/osmfeatures.Rds\")\n</code></pre> Output <p></p>"},{"location":"projects/projet%20R/#definir-la-problematique","title":"D\u00e9finir la probl\u00e9matique","text":"<p>A travers ce travail, nous cherchons \u00e0 identifier les conducteurs qui respectent les r\u00e8gles de conduite et \u00e0 \u00e9valuer leur s\u00e9curit\u00e9 sur la route, pour ce faire, nous nous concentrerons sur le calcul de la vitesse moyenne des conducteurs.</p>"},{"location":"projects/projet%20R/#resoudre-la-problematique","title":"R\u00e9soudre la probl\u00e9matique","text":"<p>Ce code R <code>length(unique(heetchPoints$driver_id))</code> calcule le nombre de valeurs uniques dans la colonne driver_id de l'objet heetchPoints.</p> <p>La fonction unique() est utilis\u00e9e pour extraire les valeurs uniques de la colonne driver_id. Ensuite, la fonction length() est utilis\u00e9e pour renvoyer le nombre d'\u00e9l\u00e9ments dans le vecteur r\u00e9sultant.</p> Nombre de chauffeurs<pre><code>length(unique(heetchPoints$driver_id))\n</code></pre> Output <p>[1] 1309</p> <p>Le code R pr\u00e9sent\u00e9 ci-dessous est une fonction appel\u00e9e <code>my_function</code>, qui prend un argument id_driver. La fonction effectue les op\u00e9rations suivantes:</p> <ol> <li> <p>Initialise une variable i \u00e0 z\u00e9ro.</p> </li> <li> <p>Affiche la valeur de i.</p> </li> <li> <p>Filtre la table heetchPoints en fonction de la valeur id_driver.</p> </li> <li> <p>Trier la table driver en fonction de la colonne location_at_local_time.</p> </li> <li> <p>Effectue une projection de la table driver_tri dans une projection cartographique sp\u00e9cifique (crs = 26191).</p> </li> <li> <p>Calcule les distances entre tous les points dans la table driver_tri \u00e0 l'aide de la fonction st_distance.</p> </li> <li> <p>Calcule la diff\u00e9rence de temps entre chaque deux points cons\u00e9cutifs dans la table driver_tri \u00e0 l'aide de la fonction difftime.</p> </li> <li> <p>Filtre la table driver_tri pour conserver uniquement les points ayant une diff\u00e9rence de temps entre 0.016 et 0.025 heures.</p> </li> <li> <p>Calcule la vitesse entre chaque deux points successifs en divisant la distance sur le temps.</p> </li> <li> <p>Filtre la table driver_tri_2 pour ne conserver que les points ayant une vitesse entre 6 et 120 km/h.</p> </li> <li> <p>Retourne la moyenne des vitesses de la table driver_tri_3.</p> </li> </ol> <p>D\u00e9fenir la fonction qui calcul la moyenne des vitesses d'un chauffeur sur un jour<pre><code>i = 0\nmy_function &lt;- function (id_driver){\n\n  i=i+1\n  print(i)\n  driver &lt;- heetchPoints %&gt;% \n    filter(driver_id == id_driver) \n\n  # Prendre le premier jour + classer par location_at_local_time\n#  jour &lt;- driver %&gt;% \n #   filter(substr(driver$location_at_local_time, start = 9, stop = 10) == \"01\")\n\n  #plot(driver$geometry, border = \"red\", lwd = 2)\n\n#  time_tri &lt;- order(jour$location_at_local_time)\n\n # jour_tri &lt;- jour[time_tri,]\n\n  #Triage temporel de la table driver \n\n  driver_tri_index &lt;- order(driver$location_at_local_time)\n  driver_tri &lt;- driver[driver_tri_index,]\n\n  # Projection des points\n  driver_tri &lt;- st_transform(x = driver_tri, crs = 26191)\n\n\n\n\n  # Calculons les distances entres tous les points\n  n &lt;- nrow(driver_tri)  \n  n\n  list_distance &lt;- list()\n  for( i in 1:(n-1)){\n    distance &lt;- st_distance(x = driver_tri[i, ],\n                            y = driver_tri[i+1, ],\n                            by_element = TRUE)\n    units(distance) &lt;- \"km\"\n    list_distance &lt;- append (list_distance, list(distance))\n  }\n  length (list_distance)\n  list_distance &lt;- c(0, list_distance)\n\n  driver_tri$distdiff &lt;- list_distance\n\n\n\n\n  list_time &lt;- list()\n  for( i in 1:(n-1)){\n    date_point1 &lt;- driver_tri$location_at_local_time[i]\n    date_point2 &lt;- driver_tri$location_at_local_time[i+1]\n    diff?rence &lt;- difftime(date_point2, date_point1, units = \"hours\")\n    list_time &lt;- append (list_time, list(diff?rence))\n  }\n\n  list_time &lt;- c(0, list_time)\n  driver_tri$timediff &lt;- list_time\n  #Calculons la liste des vitesse entre chaque deux points successifs en divisant la distance sur le temps\n\n  driver_tri_2 &lt;- driver_tri[driver_tri$timediff &gt; 0.016 &amp; driver_tri$timediff &lt; 0.025, ]\n\n\n  class(driver_tri_2$distdiff)\n  class(driver_tri_2$timediff)\n\n  driver_tri_2$distdiff &lt;- as.numeric(driver_tri_2$distdiff)\n  driver_tri_2$timediff &lt;- as.numeric(driver_tri_2$timediff)\n\n  driver_tri_2$vitesse &lt;- driver_tri_2$distdiff / driver_tri_2$timediff\n  driver_tri_3 &lt;- driver_tri_2[driver_tri_2$vitesse &gt;= 6 &amp; driver_tri_2$vitesse &lt;= 120, ]\n\n  return (mean(driver_tri_3$vitesse))\n}\n</code></pre> Le code ci-dessous commence par cr\u00e9er un objet de type data.frame appel\u00e9 vitesse_table \u00e0 l'aide de la fonction data.frame().</p> <p>Ensuite, la boucle for est utilis\u00e9e pour it\u00e9rer sur une liste de trois valeurs de l'ID de conducteur driver_id comprises entre 10 et 12 inclusivement.</p> <p>\u00c0 chaque it\u00e9ration, le code cr\u00e9e une liste driver_list avec deux \u00e9l\u00e9ments : le premier est l'ID du conducteur et le deuxi\u00e8me est le r\u00e9sultat de la fonction my_function() avec l'ID du conducteur en argument.</p> <p>Enfin, la fonction rbind() est utilis\u00e9e pour ajouter la liste driver_list en tant que nouvelle ligne \u00e0 la fin du data.frame ***vitesse_table**.</p> <p>Ainsi, \u00e0 la fin de la boucle for, vitesse_table contiendra une liste de conducteurs avec leurs ID et la valeur de la vitesse obtenue \u00e0 l'aide de la fonction my_function().</p> Calculons la moyenne des vitesse de tous les chauffeurs<pre><code>vitesse_table &lt;- data.frame()\n\nfor (driver_id in unique(heetchPoints$driver_id)[10:12]){\n  driver_list &lt;- list(driver_id, my_function (driver_id))\n  vitesse_table &lt;- rbind(vitesse_table, driver_list)\n  }\n</code></pre>"},{"location":"projects/sentiment_analysis/","title":"Advanced Sentiment Analysis with Movie Reviews","text":"<p>This Python script performs an advanced sentiment analysis on movie reviews using the NLTK (Natural Language Toolkit) library and the Scikit-learn machine learning library.</p>"},{"location":"projects/sentiment_analysis/#introduction","title":"Introduction","text":"<p>This script aims to build an advanced sentiment analysis model using the movie reviews dataset from the NLTK corpus. The model is based on the Naive Bayes classification algorithm and is trained on a combination of text features, including bag-of-words (Count Vectorizer) and term frequency-inverse document frequency (TF-IDF Vectorizer). Additionally, the script incorporates sentiment analysis using the VADER (Valence Aware Dictionary and sEntiment Reasoner) library to provide a sentiment score for each review.</p> Code <pre><code>import nltk\nimport pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, classification_report, f1_score, precision_score, recall_score\nfrom nltk.corpus import movie_reviews\nfrom nltk.sentiment import SentimentIntensityAnalyzer\nimport pickle\n\n# Step 1: Setup - Install necessary libraries (if not installed)\n# !pip install nltk pandas scikit-learn\n\n# Step 2: Data Preparation\nnltk.download(\"movie_reviews\")\nnltk.download(\"vader_lexicon\")\n\n# Load the dataset\ndocuments = [(\" \".join(movie_reviews.words(fileid)), category)\n             for category in movie_reviews.categories()\n             for fileid in movie_reviews.fileids(category)]\n\n# Convert to DataFrame\ndf = pd.DataFrame(documents, columns=[\"review\", \"sentiment\"])\n\n# Step 3: Feature Engineering\n# 1. Count Vectorizer\ncount_vectorizer = CountVectorizer(max_features=5000, stop_words='english')\nX_count = count_vectorizer.fit_transform(df[\"review\"])\n\n# 2. TF-IDF Vectorizer\ntfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\nX_tfidf = tfidf_vectorizer.fit_transform(df[\"review\"])\n\n# 3. Sentiment Analysis\nsia = SentimentIntensityAnalyzer()\ndf[\"sentiment_score\"] = df[\"review\"].apply(lambda x: sia.polarity_scores(x)[\"compound\"])\n\n# Step 4: Model Training\n# Split the data into training and testing sets\nX_train_count, X_test_count, y_train, y_test = train_test_split(X_count, df[\"sentiment\"], test_size=0.2, random_state=42)\nX_train_tfidf, X_test_tfidf, _, _ = train_test_split(X_tfidf, df[\"sentiment\"], test_size=0.2, random_state=42)\n\n# Tune the Naive Bayes model using GridSearchCV\nparam_grid = {\"alpha\": [0.1, 1, 10]}\ngrid_search = GridSearchCV(MultinomialNB(), param_grid, cv=5, scoring=\"f1_macro\")\ngrid_search.fit(X_train_count, y_train)\nbest_model = grid_search.best_estimator_\n\n# Evaluate the model\ny_pred_count = best_model.predict(X_test_count)\ny_pred_tfidf = best_model.predict(X_test_tfidf)\n\nprint(\"Count Vectorizer:\")\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred_count)}\")\nprint(f\"F1 Score: {f1_score(y_test, y_pred_count, average='macro')}\")\nprint(f\"Precision: {precision_score(y_test, y_pred_count, average='macro')}\")\nprint(f\"Recall: {recall_score(y_test, y_pred_count, average='macro')}\")\nprint(f\"Classification Report:\\n{classification_report(y_test, y_pred_count)}\")\n\nprint(\"\\nTF-IDF Vectorizer:\")\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred_tfidf)}\")\nprint(f\"F1 Score: {f1_score(y_test, y_pred_tfidf, average='macro')}\")\nprint(f\"Precision: {precision_score(y_test, y_pred_tfidf, average='macro')}\")\nprint(f\"Recall: {recall_score(y_test, y_pred_tfidf, average='macro')}\")\nprint(f\"Classification Report:\\n{classification_report(y_test, y_pred_tfidf)}\")\n\n# Step 5: Sentiment Analysis\ndef predict_sentiment(text):\n    text_vector = tfidf_vectorizer.transform([text])\n    prediction = best_model.predict(text_vector)\n    sentiment_score = sia.polarity_scores(text)[\"compound\"]\n    return prediction[0], sentiment_score\n\n# Save the model and vectorizers\nwith open(\"model.pkl\", \"wb\") as f:\n    pickle.dump(best_model, f)\nwith open(\"count_vectorizer.pkl\", \"wb\") as f:\n    pickle.dump(count_vectorizer, f)\nwith open(\"tfidf_vectorizer.pkl\", \"wb\") as f:\n    pickle.dump(tfidf_vectorizer, f)\n\n# Test the prediction function\nprint(predict_sentiment(\"I absolutely loved this movie! It was fantastic.\"))\nprint(predict_sentiment(\"It was a terrible film. I hated it.\"))\nprint(predict_sentiment(\"The movie was okay, nothing special.\"))\n</code></pre>"},{"location":"projects/sentiment_analysis/#setup","title":"Setup","text":"<ol> <li>Ensure that the necessary libraries are installed:    <pre><code># !pip install nltk pandas scikit-learn\n</code></pre></li> <li>Download the required NLTK resources:    <pre><code>nltk.download(\"movie_reviews\")\nnltk.download(\"vader_lexicon\")\n</code></pre></li> </ol>"},{"location":"projects/sentiment_analysis/#data-preparation","title":"Data Preparation","text":"<ol> <li>Load the movie reviews dataset from the NLTK corpus:    <pre><code>documents = [(\" \".join(movie_reviews.words(fileid)), category)\n             for category in movie_reviews.categories()\n             for fileid in movie_reviews.fileids(category)]\n</code></pre></li> <li>Convert the data to a DataFrame:    <pre><code>df = pd.DataFrame(documents, columns=[\"review\", \"sentiment\"])\n</code></pre></li> </ol>"},{"location":"projects/sentiment_analysis/#feature-engineering","title":"Feature Engineering","text":""},{"location":"projects/sentiment_analysis/#count-vectorizer","title":"Count Vectorizer","text":"<ol> <li>Create a Count Vectorizer with a maximum of 5,000 features and remove English stop words:    <pre><code>count_vectorizer = CountVectorizer(max_features=5000, stop_words='english')\nX_count = count_vectorizer.fit_transform(df[\"review\"])\n</code></pre></li> </ol>"},{"location":"projects/sentiment_analysis/#tf-idf-vectorizer","title":"TF-IDF Vectorizer","text":"<ol> <li>Create a TF-IDF Vectorizer with a maximum of 5,000 features and remove English stop words:    <pre><code>tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\nX_tfidf = tfidf_vectorizer.fit_transform(df[\"review\"])\n</code></pre></li> </ol>"},{"location":"projects/sentiment_analysis/#sentiment-analysis","title":"Sentiment Analysis","text":"<ol> <li>Use the VADER (Valence Aware Dictionary and sEntiment Reasoner) library to calculate the sentiment score for each review:    <pre><code>sia = SentimentIntensityAnalyzer()\ndf[\"sentiment_score\"] = df[\"review\"].apply(lambda x: sia.polarity_scores(x)[\"compound\"])\n</code></pre></li> </ol>"},{"location":"projects/sentiment_analysis/#model-training","title":"Model Training","text":""},{"location":"projects/sentiment_analysis/#splitting-the-data","title":"Splitting the Data","text":"<ol> <li>Split the data into training and testing sets:    <pre><code>X_train_count, X_test_count, y_train, y_test = train_test_split(X_count, df[\"sentiment\"], test_size=0.2, random_state=42)\nX_train_tfidf, X_test_tfidf, _, _ = train_test_split(X_tfidf, df[\"sentiment\"], test_size=0.2, random_state=42)\n</code></pre></li> </ol>"},{"location":"projects/sentiment_analysis/#tuning-the-naive-bayes-model","title":"Tuning the Naive Bayes Model","text":"<ol> <li>Perform a grid search to find the best hyperparameters for the Multinomial Naive Bayes model:    <pre><code>param_grid = {\"alpha\": [0.1, 1, 10]}\ngrid_search = GridSearchCV(MultinomialNB(), param_grid, cv=5, scoring=\"f1_macro\")\ngrid_search.fit(X_train_count, y_train)\nbest_model = grid_search.best_estimator_\n</code></pre></li> </ol>"},{"location":"projects/sentiment_analysis/#evaluating-the-model","title":"Evaluating the Model","text":"<ol> <li>Evaluate the model's performance using the test data:    <pre><code>y_pred_count = best_model.predict(X_test_count)\ny_pred_tfidf = best_model.predict(X_test_tfidf)\n\nprint(\"Count Vectorizer:\")\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred_count)}\")\nprint(f\"F1 Score: {f1_score(y_test, y_pred_count, average='macro')}\")\nprint(f\"Precision: {precision_score(y_test, y_pred_count, average='macro')}\")\nprint(f\"Recall: {recall_score(y_test, y_pred_count, average='macro')}\")\nprint(f\"Classification Report:\\n{classification_report(y_test, y_pred_count)}\")\n\nprint(\"\\nTF-IDF Vectorizer:\")\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred_tfidf)}\")\nprint(f\"F1 Score: {f1_score(y_test, y_pred_tfidf, average='macro')}\")\nprint(f\"Precision: {precision_score(y_test, y_pred_tfidf, average='macro')}\")\nprint(f\"Recall: {recall_score(y_test, y_pred_tfidf, average='macro')}\")\nprint(f\"Classification Report:\\n{classification_report(y_test, y_pred_tfidf)}\")\n</code></pre></li> </ol>"},{"location":"projects/sentiment_analysis/#sentiment-prediction","title":"Sentiment Prediction","text":"<ol> <li>Define a function to predict the sentiment of a given text:    <pre><code>def predict_sentiment(text):\n    text_vector = tfidf_vectorizer.transform([text])\n    prediction = best_model.predict(text_vector)\n    sentiment_score = sia.polarity_scores(text)[\"compound\"]\n    return prediction[0], sentiment_score\n</code></pre></li> </ol>"},{"location":"projects/sentiment_analysis/#saving-the-model-and-vectorizers","title":"Saving the Model and Vectorizers","text":"<ol> <li>Save the trained model and vectorizers to disk for future use:    <pre><code>with open(\"model.pkl\", \"wb\") as f:\n    pickle.dump(best_model, f)\nwith open(\"count_vectorizer.pkl\", \"wb\") as f:\n    pickle.dump(count_vectorizer, f)\nwith open(\"tfidf_vectorizer.pkl\", \"wb\") as f:\n    pickle.dump(tfidf_vectorizer, f)\n</code></pre></li> </ol>"},{"location":"projects/sentiment_analysis/#testing-the-prediction-function","title":"Testing the Prediction Function","text":"<ol> <li>Test the <code>predict_sentiment</code> function with some sample text:    <pre><code>print(predict_sentiment(\"I absolutely loved this movie! It was fantastic.\"))\nprint(predict_sentiment(\"It was a terrible film. I hated it.\"))\nprint(predict_sentiment(\"The movie was okay, nothing special.\"))\n</code></pre></li> </ol> <p>The script provides a comprehensive sentiment analysis solution that combines various text feature extraction techniques, sentiment analysis, and model tuning to achieve robust performance on the movie reviews dataset. The saved model and vectorizers can be easily reused for future sentiment analysis tasks.</p>"},{"location":"projects/spam%20datasets/","title":"Spam Dataset","text":""},{"location":"projects/spam%20datasets/#introduction","title":"Introduction","text":"<p>The objective of this project was to train a neural network to classify emails as \"spam\" or \"non-spam.\" This was done using the Spambase dataset provided by the UCI Machine Learning Repository, which contains 57 features representing the word frequencies in 4601 emails.</p> <p>For our label (Spam), \"spam\" was encoded as 1 for the positive class, and \"non-spam\" was encoded as 0 for the negative class.</p>"},{"location":"projects/spam%20datasets/#data-preparation","title":"Data Preparation","text":"<p><pre><code># Import Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom tensorflow import keras\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dropout\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras.layers import Dense\n</code></pre> <pre><code># Import Datasets \nspam = pd.read_csv(\"spam.csv\")\n</code></pre> <pre><code># Read the first 5 lines\nspam.head(5)\n</code></pre></p>"},{"location":"projects/spam%20datasets/#exploratory-data-analysis-eda","title":"Exploratory Data Analysis (EDA)","text":"<pre><code># Display some dataset information\nspam.info()\n</code></pre> <p>According to the <code>info()</code> method results, it appears that all the features are of type float, which will make our subsequent analysis easier (no need for feature engineering).</p> <pre><code># Display some dataset statistics\nspam.describe()\n</code></pre> <p>I have also conducted an analysis of the data distributions to get an idea of the distributions followed by the various features. Below is the obtained result, showing that most features do not follow a Gaussian distribution.</p> <pre><code># Display some dataset statistics\nspam.describe()\n</code></pre> Output <p></p> <pre><code># Correlation Analysis\nmatriceCorr = spam.corr().round(1)\nsns.heatmap(data=matriceCorr, annot = True)\n</code></pre> Output <p></p>"},{"location":"projects/spam%20datasets/#implementation-of-a-neural-network-model","title":"Implementation of a Neural Network Model","text":"<p><pre><code># Splitting data into training, testing, and validation data\n\nspam = spam.sample(frac=1, axis=0)\n\ndata_train_valid = spam.sample(frac=0.85, axis=0)\ndata_test = spam.drop(data_train_valid.index)\ndata_train = data_train_valid.sample(frac=0.8, axis=0)\ndata_valid = data_train_valid.drop(data_train.index)\n\nx_train = data_train.drop('spam', axis=1)\ny_train = data_train['spam']\nprint('X train dimensions :', x_train.shape)\nprint('Y train dimensions :', y_train.shape)\n\nx_valid = data_valid.drop('spam', axis=1)\ny_valid = data_valid['spam']\nprint('X valid dimensions :', x_valid.shape)\nprint('Y valid dimensions :', y_valid.shape)\n\nx_test = data_test.drop('spam', axis=1)\ny_test = data_test['spam']\nprint('X test dimensions :', x_test.shape)\nprint('Y test dimensions :', y_test.shape)\n</code></pre> <pre><code># Data Normalization\n\nmin_x_train = x_train.min()\nmax_x_train = x_train.max()\n\nprint(\"Min of x_train :\", min_x_train)\nprint(\"Max of x_train :\", max_x_train)\n\nx_train_norm = (x_train-min_x_train)/(max_x_train-min_x_train)\nx_test_norm = (x_test-min_x_train)/(max_x_train-min_x_train)\nx_val_norm = (x_valid-min_x_train)/(max_x_train-min_x_train)\n</code></pre></p> <p>The perceptron structure consists of an input layer with 57 neurons corresponding to each of the 57 features, a hidden layer with 12 neurons, and an output layer with 2 neurons: the first one can be interpreted as the probability of an email being \"non-spam,\" and the second one as the probability of \"spam.\" The output neuron with the highest probability determines the email classification.</p> <p>The <code>sigmoid function</code> was chosen as the activation function for each of the three layers, binary cross-entropy as the loss function, and the <code>Adam optimizer</code> algorithm for its adaptive learning rate and momentum.</p> <p></p> <p><pre><code>## Implementation of DNN model\n\nmodel = Sequential()\nmodel.add(Dense(57, input_dim=np.shape(x_train)[1], activation = 'sigmoid'))\nmodel.add(Dropout(.5))\nmodel.add(Dense(12, activation = 'sigmoid'))\nmodel.add(Dropout(.5))\nmodel.add(Dense(1, activation = 'sigmoid'))\n\nmodel.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n\nmodel.summary()\n</code></pre> <pre><code>callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=1000)\n\nhist = model.fit(x_train_norm, y_train, epochs = 10100, batch_size = 99999, callbacks = callback)\n</code></pre> <pre><code># Model Performance on Test Data\n\npreds = model.predict(x_test_norm)\npreds = [1 if x[0] &gt; 0.5 else 0 for x in preds]\nscore_test_dnn = accuracy_score(y_test, preds)\nprint(score_test_dnn)\n</code></pre> <pre><code># Model Performance on Validation Data\n\npreds = model.predict(x_val_norm)\npreds = [1 if x[0] &gt; 0.5 else 0 for x in preds]\nscore_valid_dnn = accuracy_score(y_valid, preds)\nprint(score_valid_dnn)\n</code></pre> <pre><code>figure = plt.gcf()\nfigure.set_size_inches((20, 10))\nplt.title('Error Analysis')\nplt.xlabel('Epoch')\nplt.ylabel('Cross Entropy')\nplt.plot(range(1, len(hist.history['loss']) + 1), hist.history['loss'])\nplt.legend(['Training Cross-Entropy'])\nplt.show()\n</code></pre></p> Output <p></p> <pre><code>figure = plt.gcf()\nfigure.set_size_inches((20, 10))\nplt.title('Error Analysis')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.plot(range(1, len(hist.history['accuracy']) + 1), hist.history['accuracy'])\nplt.legend([\"Training Accuracy\"])\nplt.show()\n</code></pre> Output <p></p> <p>This neural network model achieved a score of 0.924 for the test data and a score of 0.937 for the validation data, which is very satisfactory.</p>"},{"location":"projects/spam%20datasets/#implementation-of-logistic-regression","title":"Implementation of Logistic Regression","text":"<p><pre><code>from sklearn.linear_model import LogisticRegression\n\nlog_reg = LogisticRegression()\nlog_reg.fit(x_train_norm, y_train)\n</code></pre> <pre><code># Model Performance on Test Data\n\nscore_test_log_reg = log_reg.score(x_test_norm, y_test)\nprint(\"Test Accuracy Score\", score_test_log_reg)\n</code></pre> <pre><code># Model Performance on Validation Data\n\nscore_valid_log_reg = log_reg.score(x_val_norm, y_valid)\nprint(\"Test Accuracy Score\", score_valid_log_reg)\n</code></pre></p> <p>I also implemented logistic regression and obtained a score of 0.876 for the test data and a score of 0.895 for the validation data.</p>"},{"location":"projects/spam%20datasets/#implementation-of-svm-support-vector-machine","title":"Implementation of SVM (Support Vector Machine)","text":"<p><pre><code>from sklearn import svm\n\nsvm = svm.SVC()\nsvm.fit(x_train_norm, y_train)\n</code></pre> <pre><code># Model Performance on Test Data\n\nscore_test_svc = svm.score(x_test_norm, y_test)\nprint(\"Test Accuracy Score\", score_test_svc)\n</code></pre> <pre><code># Model Performance on Validation Data\n\nscore_valid_svc = svm.score(x_val_norm, y_valid)\nprint(\"Test Accuracy Score\", score_valid_svc)\n</code></pre></p> <p>An SVC was also implemented and achieved a score of 0.931 for the test data and a score of 0.932 for the validation data.</p>"},{"location":"projects/spam%20datasets/#implementation-of-random-forest","title":"Implementation of Random Forest","text":"<p><pre><code>from sklearn.ensemble import RandomForestClassifier\n\nrdf = RandomForestClassifier(max_depth=2, random_state=0)\nrdf.fit(x_train_norm, y_train)\n</code></pre> <pre><code># Model Performance on Test Data\n\nscore_test_rdf = rdf.score(x_test_norm, y_test)\nprint(\"Test Accuracy Score\", score_test_rdf)\n</code></pre> <pre><code># Model Performance on Validation Data\n\nscore_valid_rdf = rdf.score(x_val_norm, y_valid)\nprint(\"Test Accuracy Score\", score_valid_rdf)\n</code></pre></p> <p>To get an idea of all machine learning models, I also implemented a Random Forest model which achieved a score of 0.884 for the test data and a score of 0.904 for the validation data.</p>"},{"location":"projects/spam%20datasets/#conclusion","title":"Conclusion","text":"<p>In conclusion, here is a table summarizing the different scores of all the models I implemented:</p> Model Score (Test Dataset) Score (Validation Dataset) Deep Neural Network (DNN) 0.9246376811594202 0.9246376811594202 Logistic Regression 0.8768115942028986 0.8951406649616368 Support Vector Machine (SVC) 0.9318840579710145 0.9322250639386189 Random Forest 0.8840579710144928 0.9040920716112532"},{"location":"projects/tp_gnn/","title":"TP: R\u00e9seaux de neurones graphiques","text":"<p>Dans ce TP, on va appliquer les concepts d'extraction de caract\u00e9ristiques et de node embedding sur un dataset classique Karate Club Network.</p>"},{"location":"projects/tp_gnn/#representation-graphique-avec-networkx","title":"Repr\u00e9sentation graphique avec networkx","text":"<pre><code>import networkx as nx\n</code></pre>"},{"location":"projects/tp_gnn/#zacharys-karate-club-network","title":"Zachary's karate club network","text":"<p>Zachary's karate club est un graphe d\u00e9crivant un r\u00e9seau social de 34 membres d'un club de karat\u00e9. Les liens repr\u00e9sentent les interactions entre les membres en dehors du club.</p> <pre><code>G = nx.karate_club_graph()\n\nnx.draw(G, with_labels = True)\n</code></pre> Output <p></p>"},{"location":"projects/tp_gnn/#question-1-quel-est-le-degre-moyen-du-karate-club","title":"Question 1 : quel est le degr\u00e9 moyen du karat\u00e9 club ?","text":"<pre><code>def average_degree(num_edges, num_nodes):\n  # Cette fonction retourne le degr\u00e9 moyen du graphe.\n\n    avg_degree = 0\n\n    avg_degree = round(2 * num_edges/num_nodes)\n\n    return avg_degree\n\nnum_edges = G.number_of_edges()\nnum_nodes = G.number_of_nodes()\nprint(\"Nombre d'ar\u00eates :\", num_edges, \"Nombre de noeuds :\", num_nodes)\navg_degree = average_degree(num_edges, num_nodes)\nprint(\"Le degr\u00e9 moyen du karat\u00e9 club est : {}\".format(avg_degree))\n</code></pre> Output <p>Nombre d'ar\u00eates : 78 Nombre de noeuds : 34 Le degr\u00e9 moyen du karat\u00e9 club est : 5</p>"},{"location":"projects/tp_gnn/#question-2-quel-est-le-coefficient-de-clustering-moyen-du-karate-club","title":"Question 2 : quel est le coefficient de clustering moyen du karat\u00e9 club ?","text":"<pre><code>def average_clust_coef(G):\n  # Cette fonction retourne le coefficient de clustring moyen du caract\u00e9 club \n\n  ####### Code ########\n    avg_cluster_coef = nx.algorithms.cluster.average_clustering(G)\n  #####################\n\n    return avg_cluster_coef\n\navg_cluster_coef = average_clust_coef(G)\nprint(\"Le coefficient de clustering moyen du karat\u00e9 club est : {}\".format(avg_cluster_coef))\n</code></pre> Output <p>Le coefficient de clustering moyen du karat\u00e9 club est : 0.5706384782076823</p>"},{"location":"projects/tp_gnn/#question-3-quelle-est-la-centralite-de-proximite-du-noeud-numero-5","title":"Question 3 : quelle est la centralit\u00e9 de proximit\u00e9 du noeud num\u00e9ro 5 ?","text":"Output <p>La centralit\u00e9 de proximit\u00e9 est d\u00e9finie par :  c(v) = \\frac{1}{\\sum_{u \\neq v}\\text{le chemin le plus court entre } u \\text{ and } v}</p> <pre><code>def closeness_centrality(G, node = 5):\n  # Cette fonction retourne la centralit\u00e9 de proximit\u00e9 d'un noeud donn\u00e9\n\n  ###### Code #######\n    degree_centrality = nx.algorithms.centrality.closeness_centrality(G)\n    closeness = degree_centrality[node]\n  ###################\n\n    return closeness\n\nnode = 5\ncloseness = closeness_centrality(G, node=node)\nprint(\"La centralit\u00e9 de proximit\u00e9 du noeud num\u00e9ro 5 est : {}\".format(closeness))\n</code></pre> Output <p>La centralit\u00e9 de proximit\u00e9 du noeud num\u00e9ro 5 est : 0.38372093023255816</p>"},{"location":"projects/tp_gnn/#question-4-quelle-est-la-centralite-intermediaire-associee-a-un-noeud-donne-du-karacte-club","title":"Question 4 : quelle est la centralit\u00e9 interm\u00e9diaire associ\u00e9e \u00e0 un noeud donn\u00e9 du karact\u00e9 club ?","text":"<pre><code>def betweeness_centrality(G, node = 5):\n  # Cette fonction retourne la centralit\u00e9 interm\u00e9diaire d'un noeud donn\u00e9\n\n  ####### Code ########\n    btw_centrality = nx.algorithms.centrality.betweenness_centrality(G)\n    betweeness = btw_centrality[node]\n  #####################\n\n    return betweeness\nnode = 5\nbetweeness = betweeness_centrality(G, node=node)\nprint(\"La centralit\u00e9 interm\u00e9diaire du noeud num\u00e9ro 5 est : {}\".format(closeness))\n</code></pre> Output <p>La centralit\u00e9 interm\u00e9diaire du noeud num\u00e9ro 5 est : 0.38372093023255816</p>"},{"location":"projects/tp_gnn/#graphe-en-tenseur","title":"Graphe en Tenseur","text":"<p>Nous allons transformer le graphe  G  en tenseur Pytorch.</p> <pre><code>import torch\n</code></pre>"},{"location":"projects/tp_gnn/#question-5-liste-des-aretes-du-karate-club-en-format-torchlongtensor-quel-le-nombe-daretes-positives","title":"Question 5 : Liste des ar\u00eates du Karat\u00e9 club en format torch.LongTensor. Quel le nombe d'ar\u00eates positives ?","text":"<pre><code>def graph_to_edge_list(G):\n\n  # Cette fonction retourne la liste des ar\u00eates d'un graphe sous forme\n  # de couplet compos\u00e9 de deux noeuds.\n\n    edge_list = []\n    lst1 = []\n    lst2 = []\n\n  ############# Code ############\n    edge_list = list(G.edges())\n  #########################################\n\n    return edge_list\n\ndef edge_list_to_tensor(edge_list):\n\n  # Cette fonction transforme un liste d'ar\u00eates en Tenseur Pytorch\n  # de dimension [2 x len(edge_list)]\n\n    edge_index = torch.tensor([])\n\n  ############# Code ############\n    edge_index = torch.tensor(edge_list, dtype = torch.long).permute((1,0))\n  #########################################\n\n    return edge_index\n\npos_edge_list = graph_to_edge_list(G)\n# print(pos_edge_list)\npos_edge_index = edge_list_to_tensor(pos_edge_list)\nprint(\"La dimension de pos_edge_index est : {}\".format(pos_edge_index.shape))\nprint(\"La somme des valeurs de pos_edge_index : {}\".format(torch.sum(pos_edge_index)))\n</code></pre> Output <p>La dimension de pos_edge_index est : torch.Size([2, 78]) La somme des valeurs de pos_edge_index : 2535</p>"},{"location":"projects/tp_gnn/#question-6-ecrire-une-fonction-qui-retourne-les-aretes-negatives","title":"Question 6 : Ecrire une fonction qui retourne les ar\u00eates n\u00e9gatives.","text":"<pre><code>import random\n\ndef sample_negative_edges(G, num_neg_samples):\n\n  # Cette fonction retourne la liste des ar\u00eates n\u00e9gatives. \n\n    neg_edge_list = []\n    pos_set = set(G.edges())\n    visited_set = set()\n\n\n  ############# Code ############\n    for n_i in G.nodes():\n        for n_j in G.nodes():\n            if n_i == n_j or (n_i,n_j) in pos_set or (n_j,n_i) in pos_set or (n_i,n_j) in visited_set or (n_j, n_i) is visited_set:\n                continue\n            neg_edge_list.append((n_i,n_j))\n            visited_set.add((n_i,n_j))\n            visited_set.add((n_j,n_i))\n            if len(neg_edge_list) == num_neg_samples:\n                break\n\n  ###############################\n\n    return neg_edge_list\n\n# Echantillon de 78 ar\u00eates n\u00e9gatives\nneg_edge_list = sample_negative_edges(G, len(pos_edge_list))\n\n# Convertir la liste des ar\u00eates n\u00e9gatives en tenseur\nneg_edge_index = edge_list_to_tensor(neg_edge_list)\nprint(\"Le tenseur neg_edge_index est de dimension {}\".format(neg_edge_index.shape))\n\n# Quelles sont les ar\u00eates n\u00e9gatives parmi les ar\u00eates suivantes ?\nedge_1 = (7, 1)\nedge_2 = (1, 33)\nedge_3 = (33, 22)\nedge_4 = (0, 4)\nedge_5 = (4, 2)\n</code></pre> Output <p>Le tenseur neg_edge_index est de dimension torch.Size([2, 483])</p> <pre><code>a = nx.negative_edge_cycle(G)\nprint(a)\n</code></pre> Output <p>False</p>"},{"location":"projects/tp_gnn/#node-embeddings","title":"Node Embeddings","text":"<pre><code>import torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n</code></pre> <p>On va utiliser ici le module nn.Embedding de PyTorch.</p> <pre><code># Initialisation de la couche d'embeddings\n# avec, par exemple, 4 objets de dimension 8 chacun\n\nemb_sample = nn.Embedding(num_embeddings=4, embedding_dim=8)\nprint('Embedding layer: {}'.format(emb_sample))\n</code></pre> Output <p>Embedding layer: Embedding(4, 8)</p> <p>Info</p> <p>On peut s\u00e9lectionner l'embedding d'un objet en utilisant l'indice correspondant.</p> <pre><code># S\u00e9lectionner un seul embedding\nid = torch.LongTensor([1])\nprint(emb_sample(id))\n\n# S\u00e9lectionner plusieurs embeddings\nids = torch.LongTensor([1, 3])\nprint(emb_sample(ids))\n\n# Obtenir la dimension de la mtrice de poids de l'embedding\nshape = emb_sample.weight.data.shape\nprint(shape)\n\n# Affecter de nouvelles valeurs \u00e0 la matrice de poids (ici des 1)\nemb_sample.weight.data = torch.ones(shape)\n\n# V\u00e9rifier la nouvelle affectation\nids = torch.LongTensor([0, 3])\nprint(emb_sample(ids))\n</code></pre> Output <p>tensor([[-0.6316,  0.5919,  0.3717, -0.0679, -1.0768,  0.7879, -0.3337,  1.6544]],        grad_fn=) tensor([[-0.6316,  0.5919,  0.3717, -0.0679, -1.0768,  0.7879, -0.3337,  1.6544],         [ 1.4465,  0.5489, -0.5271, -1.6461,  0.5401, -0.8992,  0.6385,  0.8055]],        grad_fn=) torch.Size([4, 8]) tensor([[1., 1., 1., 1., 1., 1., 1., 1.],         [1., 1., 1., 1., 1., 1., 1., 1.]], grad_fn=) <p>On va appliquer \u00e0 cela au jeu de donn\u00e9es Zachary's karat\u00e9 club. On va associer un vecteur de dimension 16 \u00e0 chaque noeud du graphe. on va initialiser la matrice avec une distribution uniforme dans  [0,1]  en utilisant torch.rand.</p> <pre><code>torch.manual_seed(1)\n\ndef create_node_emb(num_node=34, embedding_dim=16):\n\n  # Ecrire une fonction qui impl\u00e9mente la matrice d'embeddings pour les noeuds.\n  # La fonction doit retourner un embedding de format torch.nn initalis\u00e9 selon\n  # une loi uniforme dans [0,1].\n\n    emb = None\n\n  ############# Code ############\n    emb = nn.Embedding(num_embeddings=num_nodes, embedding_dim=embedding_dim)\n    shape = emb.weight.data.shape\n    emb.weight.data = torch.rand(shape)\n  ###############################\n\n    return emb\n\nemb = create_node_emb()\nids = torch.LongTensor([0, 3])\n\nprint(\"Embedding: {}\".format(emb))\n\nprint(emb(ids))\n</code></pre> Output <p>Embedding: Embedding(34, 16) tensor([[0.2114, 0.7335, 0.1433, 0.9647, 0.2933, 0.7951, 0.5170, 0.2801, 0.8339,          0.1185, 0.2355, 0.5599, 0.8966, 0.2858, 0.1955, 0.1808],         [0.7486, 0.6546, 0.3843, 0.9820, 0.6012, 0.3710, 0.4929, 0.9915, 0.8358,          0.4629, 0.9902, 0.7196, 0.2338, 0.0450, 0.7906, 0.9689]],     grad_fn=)"},{"location":"projects/tp_gnn/#visualisation-des-embeddings","title":"Visualisation des embeddings","text":"<p>Nous allons projet les embeddings inialis\u00e9s ci-dessous en deux dimensions afin de les visualiser.</p> <pre><code>def visualize_emb(emb):\n    X = emb.weight.data.numpy()\n    pca = PCA(n_components=2)\n    components = pca.fit_transform(X)\n    plt.figure(figsize=(6, 6))\n    club1_x = []\n    club1_y = []\n    club2_x = []\n    club2_y = []\n    for node in G.nodes(data=True):\n        if node[1]['club'] == 'Mr. Hi':\n            club1_x.append(components[node[0]][0])\n            club1_y.append(components[node[0]][1])\n        else:\n            club2_x.append(components[node[0]][0])\n            club2_y.append(components[node[0]][1])\n    plt.scatter(club1_x, club1_y, color=\"red\", label=\"Mr. Hi\")\n    plt.scatter(club2_x, club2_y, color=\"blue\", label=\"Officer\")\n    plt.legend()\n    plt.show()\n\n# Visualize the initial random embeddding\nvisualize_emb(emb)\n</code></pre> Output <p></p>"},{"location":"projects/tp_gnn/#question-7-calcul-des-embeddings-par-descente-du-gradient","title":"Question 7 : calcul des embeddings par descente du gradient.","text":"<pre><code>from torch.optim import SGD\n\ndef accuracy(pred, label):\n  # Cette fonction prend les pr\u00e9dictions r\u00e9alis\u00e9es, \n  # les arrondit et calcul la pr\u00e9cision du mod\u00e8le.\n\n    accu = 0.0\n    accu = torch.sum(torch.round(pred) == label) / pred.shape[0]\n\n    return accu\n\ndef train(emb, loss_fn, sigmoid, train_label, train_edge):\n  # Cette fonction entra\u00eene les embeddings par SGD.\n  # A faire :\n  # 1 : r\u00e9cup\u00e9rer les embeddings respectifs des noeuds \u00e0 partir de train_edge\n  # 2 : Calculer le produit scalaire des embeddings de chaque paire de noeuds\n  # 3 : Appliquer une fonction sigmo\u00efde au produit scalaire calcul\u00e9\n  # 4 : Appliquer la loss_fn au r\u00e9sultat de la fonction sigmo\u00efde\n  # 5 : Imprimer la fonction loss et la pr\u00e9cision \u00e0 chaque epoch. \n  # (as a sanity check, the loss should decrease during training)\n\n\n\n    epochs = 500\n    learning_rate = 0.1\n\n    optimizer = SGD(emb.parameters(), lr=learning_rate, momentum=0.9)\n\n    for i in range(epochs):\n\n\n    ############# Code ###########\n        optimizer.zero_grad()  # Clear gradients.\n\n        product = torch.sum(torch.mul(emb(train_edge[0]),emb(train_edge[1])), axis = 1)\n        pred = torch.sigmoid(product)\n        loss = loss_fn(pred, train_label)\n        loss.backward()  # Derive gradients.\n        optimizer.step()  # Update parameters based on gradients.\n\n\n        with torch.no_grad():\n            accu = accuracy(pred, train_label)\n            if i % 100 == 0:\n                visualize_emb(emb)\n            print(\"loss: {}, accuracy: {}\".format(loss.item(), accu))\n\n    ##############################\n\nloss_fn = nn.BCELoss()\nsigmoid = nn.Sigmoid()\n\n# G\u00e9n\u00e9rer les labels positifs et n\u00e9gatifs\npos_label = torch.ones(pos_edge_index.shape[1], )\nneg_label = torch.zeros(neg_edge_index.shape[1], )\n\n# Concat\u00e9ner les labels positifs and n\u00e9gatifs dans le m\u00eame tenseur\ntrain_label = torch.cat([pos_label, neg_label], dim=0)\n\n\ntrain_edge = torch.cat([pos_edge_index, neg_edge_index], dim=1)\n\ntrain(emb, loss_fn, sigmoid, train_label, train_edge)\n</code></pre> Output <p>loss: 3.468411684036255, accuracy: 0.13903743028640747 loss: 3.43456768989563, accuracy: 0.13903743028640747 loss: 3.371028184890747, accuracy: 0.13903743028640747 loss: 3.282146453857422, accuracy: 0.13903743028640747 loss: 3.1723263263702393, accuracy: 0.13903743028640747 loss: 3.045901298522949, accuracy: 0.13903743028640747 loss: 2.907038450241089, accuracy: 0.13903743028640747 loss: 2.7596638202667236, accuracy: 0.13903743028640747 loss: 2.6074018478393555, accuracy: 0.13903743028640747 loss: 2.4535279273986816, accuracy: 0.13903743028640747 loss: 2.3009305000305176, accuracy: 0.13903743028640747 loss: 2.152082920074463, accuracy: 0.13903743028640747 loss: 2.009026050567627, accuracy: 0.13903743028640747 loss: 1.8733632564544678, accuracy: 0.13903743028640747 loss: 1.7462693452835083, accuracy: 0.13903743028640747 loss: 1.6285123825073242, accuracy: 0.13903743028640747 loss: 1.5204927921295166, accuracy: 0.14260248839855194 loss: 1.4222900867462158, accuracy: 0.14438502490520477 loss: 1.3337185382843018, accuracy: 0.14973261952400208 loss: 1.254386305809021, accuracy: 0.15508021414279938 loss: 1.183752417564392, accuracy: 0.16399286687374115 loss: 1.1211791038513184, accuracy: 0.17290551960468292 loss: 1.0659770965576172, accuracy: 0.18538324534893036 loss: 1.0174411535263062, accuracy: 0.20677362382411957 loss: 0.9748789668083191, accuracy: 0.22281639277935028 loss: 0.937629222869873, accuracy: 0.2442067712545395 loss: 0.9050756096839905, accuracy: 0.2549019753932953 loss: 0.8766528964042664, accuracy: 0.27807486057281494 loss: 0.8518502116203308, accuracy: 0.3030303120613098 loss: 0.8302105069160461, accuracy: 0.3333333432674408 loss: 0.8113287091255188, accuracy: 0.35650622844696045 loss: 0.7948473691940308, accuracy: 0.38324421644210815 loss: 0.7804537415504456, accuracy: 0.40463459491729736 loss: 0.7678741216659546, accuracy: 0.4153297543525696 loss: 0.7568702101707458, accuracy: 0.4367201328277588 loss: 0.7472350597381592, accuracy: 0.4474153220653534 loss: 0.7387885451316833, accuracy: 0.45989304780960083 loss: 0.731374979019165, accuracy: 0.4777183532714844 loss: 0.7248587012290955, accuracy: 0.48663100600242615 loss: 0.7191224098205566, accuracy: 0.5080214142799377 loss: 0.714064359664917, accuracy: 0.5222816467285156 loss: 0.7095963358879089, accuracy: 0.5204991102218628 loss: 0.7056415677070618, accuracy: 0.531194269657135 loss: 0.7021337151527405, accuracy: 0.5347593426704407 loss: 0.6990148425102234, accuracy: 0.5436720252037048 loss: 0.6962348818778992, accuracy: 0.5472370982170105 loss: 0.6937502026557922, accuracy: 0.5490196347236633 loss: 0.6915227174758911, accuracy: 0.554367184638977 loss: 0.689519464969635, accuracy: 0.5561497211456299 loss: 0.6877117156982422, accuracy: 0.5561497211456299 loss: 0.686074435710907, accuracy: 0.565062403678894 loss: 0.6845855712890625, accuracy: 0.5704099535942078 loss: 0.683226466178894, accuracy: 0.5739750266075134 loss: 0.6819803714752197, accuracy: 0.5757575631141663 loss: 0.68083256483078, accuracy: 0.5739750266075134 loss: 0.6797709465026855, accuracy: 0.5739750266075134 loss: 0.6787840723991394, accuracy: 0.5757575631141663 loss: 0.6778624653816223, accuracy: 0.5793226361274719 loss: 0.6769978404045105, accuracy: 0.5793226361274719 loss: 0.6761825680732727, accuracy: 0.5828877091407776 loss: 0.6754106283187866, accuracy: 0.5846702456474304 loss: 0.6746761202812195, accuracy: 0.5846702456474304 loss: 0.6739742159843445, accuracy: 0.5882353186607361 loss: 0.6733008027076721, accuracy: 0.5900177955627441 loss: 0.672652006149292, accuracy: 0.591800332069397 loss: 0.6720245480537415, accuracy: 0.5900177955627441 loss: 0.6714155673980713, accuracy: 0.5900177955627441 loss: 0.6708226799964905, accuracy: 0.5900177955627441 loss: 0.670243501663208, accuracy: 0.5900177955627441 loss: 0.6696761846542358, accuracy: 0.5935828685760498 loss: 0.6691192388534546, accuracy: 0.591800332069397 loss: 0.6685709357261658, accuracy: 0.5900177955627441 loss: 0.6680300831794739, accuracy: 0.5900177955627441 loss: 0.6674955487251282, accuracy: 0.5900177955627441 loss: 0.6669663190841675, accuracy: 0.591800332069397 loss: 0.6664415597915649, accuracy: 0.591800332069397 loss: 0.6659204363822937, accuracy: 0.5935828685760498 loss: 0.6654024720191956, accuracy: 0.5935828685760498 loss: 0.6648867726325989, accuracy: 0.5935828685760498 loss: 0.664372980594635, accuracy: 0.5971479415893555 loss: 0.6638606786727905, accuracy: 0.5989304780960083 loss: 0.6633493900299072, accuracy: 0.602495551109314 loss: 0.6628386974334717, accuracy: 0.6042780876159668 loss: 0.6623283624649048, accuracy: 0.6078431606292725 loss: 0.6618180274963379, accuracy: 0.6114081740379333 loss: 0.6613075137138367, accuracy: 0.6131907105445862 loss: 0.6607966423034668, accuracy: 0.614973247051239 loss: 0.6602851748466492, accuracy: 0.6167557835578918 loss: 0.6597728729248047, accuracy: 0.6167557835578918 loss: 0.6592594981193542, accuracy: 0.614973247051239 loss: 0.6587451696395874, accuracy: 0.6167557835578918 loss: 0.6582295298576355, accuracy: 0.6167557835578918 loss: 0.6577125191688538, accuracy: 0.6185383200645447 loss: 0.6571941375732422, accuracy: 0.6185383200645447 loss: 0.6566741466522217, accuracy: 0.6185383200645447 loss: 0.6561526656150818, accuracy: 0.6221033930778503 loss: 0.6556293368339539, accuracy: 0.6238859295845032 loss: 0.6551043391227722, accuracy: 0.625668466091156 loss: 0.6545774936676025, accuracy: 0.625668466091156 loss: 0.6540487408638, accuracy: 0.6274510025978088</p> <p></p> <p>loss: 0.65351802110672, accuracy: 0.6274510025978088 loss: 0.6529853940010071, accuracy: 0.6274510025978088 loss: 0.6524505615234375, accuracy: 0.6292335391044617 loss: 0.6519137620925903, accuracy: 0.6292335391044617 loss: 0.6513748168945312, accuracy: 0.6310160160064697 loss: 0.650833785533905, accuracy: 0.6345810890197754 loss: 0.6502905488014221, accuracy: 0.6327985525131226 loss: 0.6497451663017273, accuracy: 0.6345810890197754 loss: 0.6491974592208862, accuracy: 0.638146162033081 loss: 0.6486475467681885, accuracy: 0.638146162033081 loss: 0.6480953693389893, accuracy: 0.6434937715530396 loss: 0.6475409865379333, accuracy: 0.6434937715530396 loss: 0.6469841599464417, accuracy: 0.6417112350463867 loss: 0.6464250683784485, accuracy: 0.6434937715530396 loss: 0.6458637714385986, accuracy: 0.6452763080596924 loss: 0.645300030708313, accuracy: 0.6452763080596924 loss: 0.6447339057922363, accuracy: 0.6452763080596924 loss: 0.6441654562950134, accuracy: 0.6452763080596924 loss: 0.6435947418212891, accuracy: 0.6452763080596924 loss: 0.6430215835571289, accuracy: 0.6452763080596924 loss: 0.6424461603164673, accuracy: 0.648841381072998 loss: 0.6418682932853699, accuracy: 0.6524063944816589 loss: 0.6412880420684814, accuracy: 0.6541889309883118 loss: 0.6407055258750916, accuracy: 0.6541889309883118 loss: 0.6401206254959106, accuracy: 0.6524063944816589 loss: 0.6395334601402283, accuracy: 0.6524063944816589 loss: 0.6389438509941101, accuracy: 0.6524063944816589 loss: 0.6383520364761353, accuracy: 0.6559714674949646 loss: 0.6377577781677246, accuracy: 0.6559714674949646 loss: 0.6371612548828125, accuracy: 0.6559714674949646 loss: 0.6365625858306885, accuracy: 0.6559714674949646 loss: 0.6359614133834839, accuracy: 0.6595365405082703 loss: 0.6353582143783569, accuracy: 0.6595365405082703 loss: 0.6347528100013733, accuracy: 0.6595365405082703 loss: 0.6341450214385986, accuracy: 0.6595365405082703 loss: 0.6335352063179016, accuracy: 0.6613190770149231 loss: 0.6329231262207031, accuracy: 0.6631016135215759 loss: 0.6323089599609375, accuracy: 0.6613190770149231 loss: 0.6316927075386047, accuracy: 0.6631016135215759 loss: 0.6310743093490601, accuracy: 0.6631016135215759 loss: 0.6304540038108826, accuracy: 0.6648841500282288 loss: 0.6298316717147827, accuracy: 0.6666666865348816 loss: 0.6292073130607605, accuracy: 0.6648841500282288 loss: 0.6285809278488159, accuracy: 0.6648841500282288 loss: 0.6279527544975281, accuracy: 0.6648841500282288 loss: 0.6273227334022522, accuracy: 0.6648841500282288 loss: 0.6266907453536987, accuracy: 0.6666666865348816 loss: 0.6260570287704468, accuracy: 0.6666666865348816 loss: 0.6254215836524963, accuracy: 0.6702316999435425 loss: 0.624784529209137, accuracy: 0.6720142364501953 loss: 0.6241457462310791, accuracy: 0.6702316999435425 loss: 0.6235052347183228, accuracy: 0.6737967729568481 loss: 0.6228633522987366, accuracy: 0.675579309463501 loss: 0.6222198009490967, accuracy: 0.6773618459701538 loss: 0.6215748190879822, accuracy: 0.6809269189834595 loss: 0.6209284067153931, accuracy: 0.6809269189834595 loss: 0.6202806830406189, accuracy: 0.6809269189834595 loss: 0.6196316480636597, accuracy: 0.6827094554901123 loss: 0.6189813613891602, accuracy: 0.6827094554901123 loss: 0.6183297634124756, accuracy: 0.6827094554901123 loss: 0.6176772117614746, accuracy: 0.6844919919967651 loss: 0.6170234680175781, accuracy: 0.686274528503418 loss: 0.6163687109947205, accuracy: 0.6880570650100708 loss: 0.6157130002975464, accuracy: 0.6898396015167236 loss: 0.6150563955307007, accuracy: 0.6916220784187317 loss: 0.6143988966941833, accuracy: 0.6916220784187317 loss: 0.6137406826019287, accuracy: 0.6934046149253845 loss: 0.6130816340446472, accuracy: 0.6951871514320374 loss: 0.6124221086502075, accuracy: 0.6951871514320374 loss: 0.6117619276046753, accuracy: 0.6951871514320374 loss: 0.6111010909080505, accuracy: 0.6969696879386902 loss: 0.6104399561882019, accuracy: 0.6969696879386902 loss: 0.6097782850265503, accuracy: 0.7005347609519958 loss: 0.6091163754463196, accuracy: 0.698752224445343 loss: 0.6084542870521545, accuracy: 0.7005347609519958 loss: 0.6077919602394104, accuracy: 0.698752224445343 loss: 0.6071293950080872, accuracy: 0.7005347609519958 loss: 0.6064668297767639, accuracy: 0.7005347609519958 loss: 0.6058043241500854, accuracy: 0.7040998339653015 loss: 0.6051419377326965, accuracy: 0.7040998339653015 loss: 0.6044796109199524, accuracy: 0.7040998339653015 loss: 0.6038175225257874, accuracy: 0.7040998339653015 loss: 0.6031557321548462, accuracy: 0.7058823704719543 loss: 0.6024941802024841, accuracy: 0.7076649069786072 loss: 0.601833164691925, accuracy: 0.70944744348526 loss: 0.601172685623169, accuracy: 0.70944744348526 loss: 0.6005127429962158, accuracy: 0.7112299203872681 loss: 0.5998533368110657, accuracy: 0.70944744348526 loss: 0.5991947054862976, accuracy: 0.70944744348526 loss: 0.5985367298126221, accuracy: 0.70944744348526 loss: 0.5978797078132629, accuracy: 0.7112299203872681 loss: 0.5972235202789307, accuracy: 0.7112299203872681 loss: 0.5965683460235596, accuracy: 0.7112299203872681 loss: 0.5959141254425049, accuracy: 0.70944744348526 loss: 0.5952609777450562, accuracy: 0.7147949934005737 loss: 0.5946089625358582, accuracy: 0.7147949934005737 loss: 0.5939582586288452, accuracy: 0.7112299203872681 loss: 0.593308687210083, accuracy: 0.7147949934005737 loss: 0.5926604866981506, accuracy: 0.7130124568939209 loss: 0.5920137763023376, accuracy: 0.7130124568939209</p> <p></p> <p>loss: 0.5913684368133545, accuracy: 0.7130124568939209 loss: 0.5907245874404907, accuracy: 0.7130124568939209 loss: 0.5900822281837463, accuracy: 0.7147949934005737 loss: 0.58944171667099, accuracy: 0.7183600664138794 loss: 0.5888026356697083, accuracy: 0.7147949934005737 loss: 0.5881654024124146, accuracy: 0.7147949934005737 loss: 0.5875298976898193, accuracy: 0.7147949934005737 loss: 0.5868962407112122, accuracy: 0.7147949934005737 loss: 0.5862644910812378, accuracy: 0.7147949934005737 loss: 0.5856345891952515, accuracy: 0.7147949934005737 loss: 0.5850067138671875, accuracy: 0.7147949934005737 loss: 0.5843808054924011, accuracy: 0.7147949934005737 loss: 0.5837571024894714, accuracy: 0.7147949934005737 loss: 0.5831353068351746, accuracy: 0.7147949934005737 loss: 0.5825158357620239, accuracy: 0.7165775299072266 loss: 0.5818983912467957, accuracy: 0.7147949934005737 loss: 0.5812832713127136, accuracy: 0.7147949934005737 loss: 0.5806704163551331, accuracy: 0.7147949934005737 loss: 0.5800597667694092, accuracy: 0.7165775299072266 loss: 0.5794515609741211, accuracy: 0.7165775299072266 loss: 0.5788455605506897, accuracy: 0.7165775299072266 loss: 0.5782421231269836, accuracy: 0.7165775299072266 loss: 0.577640950679779, accuracy: 0.7147949934005737 loss: 0.577042281627655, accuracy: 0.7147949934005737 loss: 0.5764461755752563, accuracy: 0.7130124568939209 loss: 0.5758525133132935, accuracy: 0.7147949934005737 loss: 0.5752614140510559, accuracy: 0.7147949934005737 loss: 0.5746727585792542, accuracy: 0.7147949934005737 loss: 0.5740866661071777, accuracy: 0.7165775299072266 loss: 0.5735033750534058, accuracy: 0.7165775299072266 loss: 0.5729224681854248, accuracy: 0.7165775299072266 loss: 0.5723443031311035, accuracy: 0.7183600664138794 loss: 0.5717687606811523, accuracy: 0.7183600664138794 loss: 0.5711959004402161, accuracy: 0.7165775299072266 loss: 0.5706256031990051, accuracy: 0.7147949934005737 loss: 0.5700580477714539, accuracy: 0.7147949934005737 loss: 0.5694931745529175, accuracy: 0.7147949934005737 loss: 0.568930983543396, accuracy: 0.7147949934005737 loss: 0.5683714747428894, accuracy: 0.7147949934005737 loss: 0.5678147077560425, accuracy: 0.7130124568939209 loss: 0.5672606229782104, accuracy: 0.7130124568939209 loss: 0.5667092204093933, accuracy: 0.7130124568939209 loss: 0.5661605596542358, accuracy: 0.7183600664138794 loss: 0.5656147003173828, accuracy: 0.7183600664138794 loss: 0.5650715231895447, accuracy: 0.7183600664138794 loss: 0.5645310282707214, accuracy: 0.7183600664138794 loss: 0.5639932155609131, accuracy: 0.7165775299072266 loss: 0.5634582042694092, accuracy: 0.7165775299072266 loss: 0.5629258155822754, accuracy: 0.7165775299072266 loss: 0.562396228313446, accuracy: 0.7165775299072266 loss: 0.5618692636489868, accuracy: 0.7147949934005737 loss: 0.5613449811935425, accuracy: 0.7147949934005737 loss: 0.5608234405517578, accuracy: 0.7147949934005737 loss: 0.5603045225143433, accuracy: 0.7147949934005737 loss: 0.5597882866859436, accuracy: 0.7165775299072266 loss: 0.5592747330665588, accuracy: 0.7165775299072266 loss: 0.5587638020515442, accuracy: 0.7147949934005737 loss: 0.5582554936408997, accuracy: 0.7165775299072266 loss: 0.5577497482299805, accuracy: 0.7165775299072266 loss: 0.5572466850280762, accuracy: 0.7165775299072266 loss: 0.5567461848258972, accuracy: 0.7147949934005737 loss: 0.5562481880187988, accuracy: 0.7147949934005737 loss: 0.5557528138160706, accuracy: 0.7147949934005737 loss: 0.5552600026130676, accuracy: 0.7147949934005737 loss: 0.55476975440979, accuracy: 0.7147949934005737 loss: 0.5542818903923035, accuracy: 0.7183600664138794 loss: 0.5537965893745422, accuracy: 0.7165775299072266 loss: 0.5533138513565063, accuracy: 0.7201426029205322 loss: 0.5528334975242615, accuracy: 0.7201426029205322 loss: 0.5523555874824524, accuracy: 0.7254902124404907 loss: 0.5518800020217896, accuracy: 0.7254902124404907 loss: 0.551406979560852, accuracy: 0.7254902124404907 loss: 0.5509361624717712, accuracy: 0.7272727489471436 loss: 0.5504679083824158, accuracy: 0.7254902124404907 loss: 0.550001859664917, accuracy: 0.7254902124404907 loss: 0.5495381951332092, accuracy: 0.7254902124404907 loss: 0.5490767955780029, accuracy: 0.7254902124404907 loss: 0.5486176609992981, accuracy: 0.7254902124404907 loss: 0.5481607913970947, accuracy: 0.7272727489471436 loss: 0.5477061867713928, accuracy: 0.7272727489471436 loss: 0.5472538471221924, accuracy: 0.7272727489471436 loss: 0.5468035936355591, accuracy: 0.7272727489471436 loss: 0.5463555455207825, accuracy: 0.7272727489471436 loss: 0.5459097027778625, accuracy: 0.7272727489471436 loss: 0.545465886592865, accuracy: 0.7272727489471436 loss: 0.5450242757797241, accuracy: 0.7272727489471436 loss: 0.5445848107337952, accuracy: 0.7272727489471436 loss: 0.544147253036499, accuracy: 0.7272727489471436 loss: 0.54371178150177, accuracy: 0.7272727489471436 loss: 0.5432783365249634, accuracy: 0.7272727489471436 loss: 0.5428469777107239, accuracy: 0.7290552854537964 loss: 0.5424174666404724, accuracy: 0.7290552854537964 loss: 0.5419899821281433, accuracy: 0.7290552854537964 loss: 0.541564404964447, accuracy: 0.7308377623558044 loss: 0.5411407351493835, accuracy: 0.7326202988624573 loss: 0.5407189726829529, accuracy: 0.7326202988624573 loss: 0.5402990579605103, accuracy: 0.7326202988624573 loss: 0.5398810505867004, accuracy: 0.7326202988624573 loss: 0.5394647121429443, accuracy: 0.7326202988624573 loss: 0.5390503406524658, accuracy: 0.7326202988624573</p> <p></p> <p>loss: 0.5386376976966858, accuracy: 0.7344028353691101 loss: 0.538226842880249, accuracy: 0.7344028353691101 loss: 0.5378177165985107, accuracy: 0.7344028353691101 loss: 0.537410318851471, accuracy: 0.7344028353691101 loss: 0.5370044708251953, accuracy: 0.7344028353691101 loss: 0.5366004705429077, accuracy: 0.7344028353691101 loss: 0.536198079586029, accuracy: 0.7344028353691101 loss: 0.5357974171638489, accuracy: 0.7344028353691101 loss: 0.5353982448577881, accuracy: 0.7361853718757629 loss: 0.535000741481781, accuracy: 0.7361853718757629 loss: 0.5346047878265381, accuracy: 0.7361853718757629 loss: 0.5342103838920593, accuracy: 0.7361853718757629 loss: 0.5338175296783447, accuracy: 0.7361853718757629 loss: 0.5334262251853943, accuracy: 0.7361853718757629 loss: 0.5330364108085632, accuracy: 0.7361853718757629 loss: 0.532647967338562, accuracy: 0.7379679083824158 loss: 0.5322611331939697, accuracy: 0.7379679083824158 loss: 0.5318756699562073, accuracy: 0.7344028353691101 loss: 0.5314916968345642, accuracy: 0.7361853718757629 loss: 0.531109094619751, accuracy: 0.7361853718757629 loss: 0.5307279229164124, accuracy: 0.7361853718757629 loss: 0.5303480625152588, accuracy: 0.7361853718757629 loss: 0.5299695730209351, accuracy: 0.7361853718757629 loss: 0.5295924544334412, accuracy: 0.7361853718757629 loss: 0.5292166471481323, accuracy: 0.7361853718757629 loss: 0.5288420915603638, accuracy: 0.7361853718757629 loss: 0.528468906879425, accuracy: 0.7361853718757629 loss: 0.5280970335006714, accuracy: 0.7361853718757629 loss: 0.5277262926101685, accuracy: 0.7361853718757629 loss: 0.5273568630218506, accuracy: 0.7344028353691101 loss: 0.5269885659217834, accuracy: 0.7344028353691101 loss: 0.5266215801239014, accuracy: 0.7361853718757629 loss: 0.5262557864189148, accuracy: 0.7361853718757629 loss: 0.5258911848068237, accuracy: 0.7361853718757629 loss: 0.5255276560783386, accuracy: 0.7379679083824158 loss: 0.5251653790473938, accuracy: 0.7397504448890686 loss: 0.5248041749000549, accuracy: 0.7379679083824158 loss: 0.524444043636322, accuracy: 0.7379679083824158 loss: 0.5240850448608398, accuracy: 0.7379679083824158 loss: 0.5237272381782532, accuracy: 0.7379679083824158 loss: 0.5233704447746277, accuracy: 0.7379679083824158 loss: 0.5230147242546082, accuracy: 0.7379679083824158 loss: 0.5226598978042603, accuracy: 0.7397504448890686 loss: 0.5223063230514526, accuracy: 0.7397504448890686 loss: 0.5219537019729614, accuracy: 0.7397504448890686 loss: 0.5216020941734314, accuracy: 0.7397504448890686 loss: 0.5212514996528625, accuracy: 0.7397504448890686 loss: 0.5209018588066101, accuracy: 0.7397504448890686 loss: 0.5205531716346741, accuracy: 0.7397504448890686 loss: 0.5202054381370544, accuracy: 0.7397504448890686 loss: 0.519858717918396, accuracy: 0.7397504448890686 loss: 0.5195128917694092, accuracy: 0.7397504448890686 loss: 0.5191680192947388, accuracy: 0.7415329813957214 loss: 0.51882404088974, accuracy: 0.7450980544090271 loss: 0.5184809565544128, accuracy: 0.7433155179023743 loss: 0.5181388258934021, accuracy: 0.7433155179023743 loss: 0.5177974700927734, accuracy: 0.7433155179023743 loss: 0.5174570083618164, accuracy: 0.7433155179023743 loss: 0.5171175003051758, accuracy: 0.7433155179023743 loss: 0.5167787671089172, accuracy: 0.7433155179023743 loss: 0.5164408683776855, accuracy: 0.7433155179023743 loss: 0.5161037445068359, accuracy: 0.7433155179023743 loss: 0.515767514705658, accuracy: 0.7433155179023743 loss: 0.5154321193695068, accuracy: 0.7450980544090271 loss: 0.515097439289093, accuracy: 0.7468805909156799 loss: 0.5147635340690613, accuracy: 0.7486631274223328 loss: 0.514430582523346, accuracy: 0.7504456043243408 loss: 0.5140981674194336, accuracy: 0.7504456043243408 loss: 0.5137667059898376, accuracy: 0.7504456043243408 loss: 0.5134359002113342, accuracy: 0.7504456043243408 loss: 0.5131058096885681, accuracy: 0.7504456043243408 loss: 0.5127764940261841, accuracy: 0.7504456043243408 loss: 0.5124478936195374, accuracy: 0.7486631274223328 loss: 0.5121200680732727, accuracy: 0.7486631274223328 loss: 0.5117928385734558, accuracy: 0.7486631274223328 loss: 0.5114663243293762, accuracy: 0.7486631274223328 loss: 0.5111406445503235, accuracy: 0.7504456043243408 loss: 0.5108155012130737, accuracy: 0.7486631274223328 loss: 0.5104910731315613, accuracy: 0.7468805909156799 loss: 0.5101673603057861, accuracy: 0.7468805909156799 loss: 0.5098442435264587, accuracy: 0.7468805909156799 loss: 0.5095217823982239, accuracy: 0.7486631274223328 loss: 0.5092000365257263, accuracy: 0.7486631274223328 loss: 0.5088788866996765, accuracy: 0.7486631274223328 loss: 0.5085583329200745, accuracy: 0.7504456043243408 loss: 0.5082384943962097, accuracy: 0.7504456043243408 loss: 0.5079192519187927, accuracy: 0.7504456043243408 loss: 0.5076005458831787, accuracy: 0.7504456043243408 loss: 0.5072824954986572, accuracy: 0.7504456043243408 loss: 0.5069650411605835, accuracy: 0.7504456043243408 loss: 0.5066481828689575, accuracy: 0.7504456043243408 loss: 0.5063318610191345, accuracy: 0.7504456043243408 loss: 0.506016194820404, accuracy: 0.7504456043243408 loss: 0.5057010650634766, accuracy: 0.7504456043243408 loss: 0.505386471748352, accuracy: 0.7504456043243408 loss: 0.5050725340843201, accuracy: 0.7522281408309937 loss: 0.5047590732574463, accuracy: 0.7540106773376465 loss: 0.5044461488723755, accuracy: 0.7557932138442993 loss: 0.5041337609291077, accuracy: 0.7557932138442993 loss: 0.5038220286369324, accuracy: 0.7557932138442993</p> <p></p> <p>loss: 0.5035106539726257, accuracy: 0.7557932138442993 loss: 0.5031999349594116, accuracy: 0.7557932138442993 loss: 0.5028897523880005, accuracy: 0.7557932138442993 loss: 0.5025800466537476, accuracy: 0.7557932138442993 loss: 0.5022708773612976, accuracy: 0.7540106773376465 loss: 0.5019621849060059, accuracy: 0.7540106773376465 loss: 0.5016539096832275, accuracy: 0.7540106773376465 loss: 0.501346230506897, accuracy: 0.7522281408309937 loss: 0.5010391473770142, accuracy: 0.7522281408309937 loss: 0.5007324814796448, accuracy: 0.7522281408309937 loss: 0.5004262328147888, accuracy: 0.7522281408309937 loss: 0.5001205205917358, accuracy: 0.7522281408309937 loss: 0.4998152554035187, accuracy: 0.7540106773376465 loss: 0.4995104670524597, accuracy: 0.7540106773376465 loss: 0.49920615553855896, accuracy: 0.7540106773376465 loss: 0.498902291059494, accuracy: 0.7540106773376465 loss: 0.4985989034175873, accuracy: 0.7540106773376465 loss: 0.49829596281051636, accuracy: 0.7540106773376465 loss: 0.49799349904060364, accuracy: 0.7522281408309937 loss: 0.49769142270088196, accuracy: 0.7522281408309937 loss: 0.49738985300064087, accuracy: 0.7522281408309937 loss: 0.4970887005329132, accuracy: 0.7522281408309937 loss: 0.49678799510002136, accuracy: 0.7540106773376465 loss: 0.49648764729499817, accuracy: 0.7540106773376465 loss: 0.49618786573410034, accuracy: 0.7540106773376465 loss: 0.49588844180107117, accuracy: 0.7540106773376465 loss: 0.4955894351005554, accuracy: 0.7540106773376465 loss: 0.4952908158302307, accuracy: 0.7540106773376465 loss: 0.494992733001709, accuracy: 0.7540106773376465 loss: 0.49469494819641113, accuracy: 0.7540106773376465 loss: 0.4943976104259491, accuracy: 0.7540106773376465 loss: 0.4941006302833557, accuracy: 0.7540106773376465 loss: 0.4938041567802429, accuracy: 0.7540106773376465 loss: 0.493507981300354, accuracy: 0.7557932138442993 loss: 0.4932122528553009, accuracy: 0.7557932138442993 loss: 0.49291694164276123, accuracy: 0.7575757503509521 loss: 0.49262192845344543, accuracy: 0.7575757503509521 loss: 0.49232742190361023, accuracy: 0.7575757503509521 loss: 0.4920332133769989, accuracy: 0.7575757503509521 loss: 0.491739422082901, accuracy: 0.7575757503509521 loss: 0.49144604802131653, accuracy: 0.759358286857605 loss: 0.4911530017852783, accuracy: 0.759358286857605 loss: 0.49086034297943115, accuracy: 0.759358286857605 loss: 0.4905681610107422, accuracy: 0.759358286857605 loss: 0.49027615785598755, accuracy: 0.759358286857605 loss: 0.4899846315383911, accuracy: 0.7611408233642578 loss: 0.4896934926509857, accuracy: 0.7611408233642578 loss: 0.4894026219844818, accuracy: 0.7611408233642578 loss: 0.4891121983528137, accuracy: 0.7611408233642578 loss: 0.4888221323490143, accuracy: 0.7611408233642578 loss: 0.4885323941707611, accuracy: 0.7611408233642578 loss: 0.48824307322502136, accuracy: 0.7611408233642578 loss: 0.4879539906978607, accuracy: 0.759358286857605 loss: 0.4876653552055359, accuracy: 0.759358286857605 loss: 0.4873770475387573, accuracy: 0.759358286857605 loss: 0.48708903789520264, accuracy: 0.7629233598709106 loss: 0.48680150508880615, accuracy: 0.7629233598709106 loss: 0.4865141212940216, accuracy: 0.7647058963775635 loss: 0.4862271547317505, accuracy: 0.7647058963775635 loss: 0.4859405755996704, accuracy: 0.7647058963775635 loss: 0.485654354095459, accuracy: 0.7647058963775635 loss: 0.48536837100982666, accuracy: 0.7647058963775635 loss: 0.4850827753543854, accuracy: 0.7647058963775635 loss: 0.48479750752449036, accuracy: 0.7647058963775635 loss: 0.4845125079154968, accuracy: 0.7664884328842163 loss: 0.4842279553413391, accuracy: 0.7647058963775635 loss: 0.4839436113834381, accuracy: 0.7647058963775635 loss: 0.48365965485572815, accuracy: 0.7664884328842163 loss: 0.48337602615356445, accuracy: 0.7664884328842163 loss: 0.483092725276947, accuracy: 0.7664884328842163 loss: 0.48280972242355347, accuracy: 0.7664884328842163 loss: 0.4825270175933838, accuracy: 0.7664884328842163 loss: 0.48224470019340515, accuracy: 0.7682709693908691 loss: 0.481962651014328, accuracy: 0.7682709693908691 loss: 0.48168089985847473, accuracy: 0.7682709693908691 loss: 0.4813995063304901, accuracy: 0.7700534462928772 loss: 0.481118381023407, accuracy: 0.7700534462928772 loss: 0.4808375835418701, accuracy: 0.7682709693908691 loss: 0.48055708408355713, accuracy: 0.7682709693908691 loss: 0.48027682304382324, accuracy: 0.7700534462928772 loss: 0.4799969494342804, accuracy: 0.7700534462928772 loss: 0.47971734404563904, accuracy: 0.77183598279953 loss: 0.4794381260871887, accuracy: 0.7736185193061829 loss: 0.4791591167449951, accuracy: 0.7736185193061829 loss: 0.4788804352283478, accuracy: 0.7736185193061829 loss: 0.4786020517349243, accuracy: 0.7736185193061829 loss: 0.47832396626472473, accuracy: 0.7754010558128357 loss: 0.478046178817749, accuracy: 0.7754010558128357 loss: 0.4777686893939972, accuracy: 0.7754010558128357 loss: 0.4774914085865021, accuracy: 0.7754010558128357 loss: 0.4772144556045532, accuracy: 0.7754010558128357 loss: 0.4769378900527954, accuracy: 0.7736185193061829 loss: 0.4766616225242615, accuracy: 0.7754010558128357 loss: 0.4763854742050171, accuracy: 0.7754010558128357 loss: 0.4761098027229309, accuracy: 0.7754010558128357 loss: 0.47583428025245667, accuracy: 0.7754010558128357 loss: 0.4755590558052063, accuracy: 0.7754010558128357 loss: 0.4752841889858246, accuracy: 0.7754010558128357 loss: 0.47500959038734436, accuracy: 0.7754010558128357 loss: 0.4747351408004761, accuracy: 0.7754010558128357</p>"},{"location":"projects/tp_gnn/#visualisation-des-embeddings-calcules","title":"Visualisation des embeddings calcul\u00e9s","text":"<pre><code>visualize_emb(emb)\n</code></pre> Output"},{"location":"services/documentation/","title":"Documentation","text":"Creation of professional documentation <p>If you are a PhD student, researcher or scientist and you want to document your projects in a professional way then I congratulate you because you are in the right place, you just need to contact me and your documentations will be ready in 2 days :</p> <ul> <li>abdellatif.belmady@gmail.com</li> <li>My phone number : (+212)6 41 49 86 81</li> </ul> Smart Correction <p>Welcome to Smart Correction: Your Intelligent Assistant for Academic Success.</p> <p>At Smart Correction, we are committed to revolutionizing your educational experience. Our intelligent assistant is specially designed to meet the needs of students in France and Morocco, providing personalized assistance across a variety of subjects and academic levels.</p> <p>Join Smart Correction today and transform your study experience!</p> <p>Try It Now Documentation</p>"}]}